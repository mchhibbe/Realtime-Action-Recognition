{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MajorProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6c0d77874e04761a0eb2c4b443b7fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bab3c51c2a5f4cb49da4bd4680f47dfe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2bdf51f485d348d2a6f9227f08efd898",
              "IPY_MODEL_d2e4c71f5072422998c16bad0bdb2f26"
            ]
          }
        },
        "bab3c51c2a5f4cb49da4bd4680f47dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bdf51f485d348d2a6f9227f08efd898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89b9dc38ea4c4db295e0ede3ec1ffadf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 423,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 423,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0186bd3f42bb4e16beaa45488f772825"
          }
        },
        "d2e4c71f5072422998c16bad0bdb2f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d78dcb37e0d49548c3c9d66c478f6da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 423/423 [01:29&lt;00:00,  4.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e082504dc7a41b6abcacd91093de82d"
          }
        },
        "89b9dc38ea4c4db295e0ede3ec1ffadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0186bd3f42bb4e16beaa45488f772825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d78dcb37e0d49548c3c9d66c478f6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e082504dc7a41b6abcacd91093de82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b947a3e939a04c9b9e28bdb70161081e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a5fe15f5a0a4af3a77ead24c8df8ed8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25a931196b7c4af5bae1dfaf4c8c5fd1",
              "IPY_MODEL_b6b3219a54c749b4b2f21879198a1075"
            ]
          }
        },
        "1a5fe15f5a0a4af3a77ead24c8df8ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25a931196b7c4af5bae1dfaf4c8c5fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e1fb82aa1854f3c99e2bc74a69a6a34",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 423,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 423,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9de7640215a48cb819ef0bfc53a2c8b"
          }
        },
        "b6b3219a54c749b4b2f21879198a1075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37619077d284499b8aa0bd49ef464f09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 423/423 [1:49:13&lt;00:00, 15.49s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0220e8eb4f8b4e1ea91c65658da015e2"
          }
        },
        "6e1fb82aa1854f3c99e2bc74a69a6a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9de7640215a48cb819ef0bfc53a2c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37619077d284499b8aa0bd49ef464f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0220e8eb4f8b4e1ea91c65658da015e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3HR8gMNK1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9fb416-0bab-4b8c-9515-2789a784bad8"
      },
      "source": [
        "# use this for loading pretrained model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "4c45583d-c30e-40bd-a4b6-4d5b5cdd4755"
      },
      "source": [
        "! apt-get install libavformat-dev libavdevice-dev\n",
        "! pip install av==6.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libavformat-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavformat-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libavfilter-dev libpostproc-dev\n",
            "The following NEW packages will be installed:\n",
            "  libavdevice-dev libavfilter-dev libpostproc-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,154 kB of archives.\n",
            "After this operation, 5,444 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc-dev amd64 7:3.4.8-0ubuntu0.2 [51.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter-dev amd64 7:3.4.8-0ubuntu0.2 [1,016 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice-dev amd64 7:3.4.8-0ubuntu0.2 [87.2 kB]\n",
            "Fetched 1,154 kB in 1s (1,539 kB/s)\n",
            "Selecting previously unselected package libpostproc-dev:amd64.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../libpostproc-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Selecting previously unselected package libavfilter-dev:amd64.\n",
            "Preparing to unpack .../libavfilter-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Selecting previously unselected package libavdevice-dev:amd64.\n",
            "Preparing to unpack .../libavdevice-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Collecting av==6.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/77/0be0fdaa3b7912c184705a4545ae6f1e9e47ab9e3834a3ef5caf2d7ca1e7/av-6.2.0.tar.gz (2.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 19.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: av\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaG_V9027o0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d662ff8-4275-4c43-8b78-b2fa47d1a1ed"
      },
      "source": [
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-30 04:29:15--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
            "--2021-04-30 04:29:15--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2124008126 (2.0G)\n",
            "Saving to: â€˜hmdb51_org.rarâ€™\n",
            "\n",
            "hmdb51_org.rar      100%[===================>]   1.98G  42.2MB/s    in 55s     \n",
            "\n",
            "2021-04-30 04:30:11 (36.5 MB/s) - â€˜hmdb51_org.rarâ€™ saved [2124008126/2124008126]\n",
            "\n",
            "--2021-04-30 04:30:11--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar [following]\n",
            "--2021-04-30 04:30:12--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199521 (195K)\n",
            "Saving to: â€˜test_train_splits.rarâ€™\n",
            "\n",
            "test_train_splits.r 100%[===================>] 194.84K   727KB/s    in 0.3s    \n",
            "\n",
            "2021-04-30 04:30:12 (727 KB/s) - â€˜test_train_splits.rarâ€™ saved [199521/199521]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVdTbC_6NYCA",
        "outputId": "8d8da45b-c551-4f0c-8fb5-5d9684e0f7ca"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision\n",
        "from torchvision import get_video_backend\n",
        "from torchvision.models.video import r3d_18 \n",
        "from torchvision import transforms\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "import av\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "SEED = 491\n",
        "torch.manual_seed(SEED)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f79fd74bc30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUZD1ZX8Nl-V",
        "outputId": "b23c02f8-381e-4c8c-d11e-8567676fe85b"
      },
      "source": [
        "! mkdir -p video_data test_train_splits\n",
        "! unrar e test_train_splits.rar test_train_splits\n",
        "! rm test_train_splits.rar\n",
        "! unrar e hmdb51_org.rar \n",
        "! rm hmdb51_org.rar\n",
        "! mv *.rar video_data\n",
        "for files in os.listdir('video_data'):\n",
        "    foldername = files.split('.')[0]\n",
        "    os.system(\"mkdir -p video_data/\" + foldername)\n",
        "    os.system(\"unrar e video_data/\"+ files + \" video_data/\"+foldername)\n",
        "\n",
        "! rm video_data/*.rar "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from test_train_splits.rar\n",
            "\n",
            "Extracting  test_train_splits/brush_hair_test_split1.txt                 \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/brush_hair_test_split2.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/brush_hair_test_split3.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split1.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split2.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split3.txt                  \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split1.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split2.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split3.txt                      \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split1.txt                       \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split2.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split3.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split1.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split2.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split3.txt                       \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split1.txt               \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split2.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split3.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split1.txt                      \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split2.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split3.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split1.txt                       \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split2.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split3.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split1.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split2.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split3.txt                 \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split1.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split2.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split3.txt                    \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split1.txt                      \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split2.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split3.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split1.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split2.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split3.txt                        \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split1.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split2.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split3.txt                 \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split1.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split2.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split3.txt                    \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split1.txt                  \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split2.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split3.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split1.txt                       \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split2.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split3.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split1.txt                  \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split2.txt                  \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split3.txt                  \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split1.txt                        \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split2.txt                        \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split3.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split1.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split2.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split3.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split1.txt                       \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split2.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split3.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split1.txt                  \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split2.txt                  \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split3.txt                  \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split1.txt                       \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split2.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split3.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split1.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split2.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split3.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split1.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split2.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split3.txt                      \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split1.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split2.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split3.txt                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split1.txt                       \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split2.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split3.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split1.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split2.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split3.txt                     \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split1.txt                      \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split2.txt                      \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split3.txt                      \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split1.txt                     \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split2.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split3.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split1.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split2.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split3.txt                       \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split1.txt                  \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split2.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split3.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split1.txt                 \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split2.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split3.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split1.txt                        \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split2.txt                        \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split3.txt                        \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split1.txt                \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split2.txt                \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split3.txt                \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split1.txt                 \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split2.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split3.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split1.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split2.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split3.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split1.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split2.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split3.txt                  \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split1.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split2.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split3.txt                      \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split1.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split2.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split3.txt                        \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split1.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split2.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split3.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split1.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split2.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split3.txt                      \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split1.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split2.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split3.txt                 \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split1.txt                      \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split2.txt                      \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split3.txt                      \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split1.txt             \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split2.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split3.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split1.txt             \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split2.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split3.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split1.txt                      \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split2.txt                      \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split3.txt                      \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split1.txt                       \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split2.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split3.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split1.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split2.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split3.txt                      \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split1.txt                       \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split2.txt                       \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split3.txt                       \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split1.txt                       \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split2.txt                       \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split3.txt                       \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split1.txt                       \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split2.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split3.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from hmdb51_org.rar\n",
            "\n",
            "Extracting  shoot_gun.rar                                                \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  sit.rar                                                      \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  situp.rar                                                    \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  smile.rar                                                    \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  smoke.rar                                                    \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  somersault.rar                                               \b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  stand.rar                                                    \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  swing_baseball.rar                                           \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  sword.rar                                                    \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  sword_exercise.rar                                           \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  talk.rar                                                     \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  throw.rar                                                    \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  turn.rar                                                     \b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  walk.rar                                                     \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  wave.rar                                                     \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  brush_hair.rar                                               \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  cartwheel.rar                                                \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  catch.rar                                                    \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  chew.rar                                                     \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  clap.rar                                                     \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  climb.rar                                                    \b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  climb_stairs.rar                                             \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  dive.rar                                                     \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  draw_sword.rar                                               \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  dribble.rar                                                  \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  drink.rar                                                    \b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  eat.rar                                                      \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  fall_floor.rar                                               \b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  fencing.rar                                                  \b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  flic_flac.rar                                                \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  golf.rar                                                     \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  handstand.rar                                                \b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  hit.rar                                                      \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  hug.rar                                                      \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  jump.rar                                                     \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  kick.rar                                                     \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  kick_ball.rar                                                \b\b\b\b 68%\b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  kiss.rar                                                     \b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  laugh.rar                                                    \b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  pick.rar                                                     \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  pour.rar                                                     \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  pullup.rar                                                   \b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  punch.rar                                                    \b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  push.rar                                                     \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  pushup.rar                                                   \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  ride_bike.rar                                                \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  ride_horse.rar                                               \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  run.rar                                                      \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  shake_hands.rar                                              \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  shoot_ball.rar                                               \b\b\b\b 95%\b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  shoot_bow.rar                                                \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPxhGJWoNqMa",
        "outputId": "995fc56f-dd29-4162-f23b-ba1da785e35d"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "print(len(GPUs))\n",
        "gpu = GPUs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=5a2361cfe3775876df4869d66b98dd8d344ec545296d02c676e147e9b1777b3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT4Cd9za6lUl",
        "outputId": "929f7027-a1c6-4b5b-cbb9-7079d053b00e"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
        "import transforms as T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 05:19:16--  https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3102 (3.0K) [text/plain]\n",
            "Saving to: â€˜transforms.pyâ€™\n",
            "\n",
            "transforms.py       100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-28 05:19:16 (53.3 MB/s) - â€˜transforms.pyâ€™ saved [3102/3102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "d6c0d77874e04761a0eb2c4b443b7fbf",
            "bab3c51c2a5f4cb49da4bd4680f47dfe",
            "2bdf51f485d348d2a6f9227f08efd898",
            "d2e4c71f5072422998c16bad0bdb2f26",
            "89b9dc38ea4c4db295e0ede3ec1ffadf",
            "0186bd3f42bb4e16beaa45488f772825",
            "2d78dcb37e0d49548c3c9d66c478f6da",
            "8e082504dc7a41b6abcacd91093de82d",
            "b947a3e939a04c9b9e28bdb70161081e",
            "1a5fe15f5a0a4af3a77ead24c8df8ed8",
            "25a931196b7c4af5bae1dfaf4c8c5fd1",
            "b6b3219a54c749b4b2f21879198a1075",
            "6e1fb82aa1854f3c99e2bc74a69a6a34",
            "d9de7640215a48cb819ef0bfc53a2c8b",
            "37619077d284499b8aa0bd49ef464f09",
            "0220e8eb4f8b4e1ea91c65658da015e2"
          ]
        },
        "id": "UcgRFQsCN9Pr",
        "outputId": "7550f3f8-c7cb-4638-ec66-8e844700c66f"
      },
      "source": [
        "val_split = 0.05\n",
        "num_frames = 16 # 16\n",
        "clip_steps = 50\n",
        "num_workers = 2\n",
        "pin_memory = True\n",
        "train_tfms = torchvision.transforms.Compose([\n",
        "                                 T.ToFloatTensorInZeroOne(),\n",
        "                                 T.Resize((128, 128)),\n",
        "                                 T.RandomHorizontalFlip(),\n",
        "                                 T.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
        "                                 T.RandomCrop((112, 112))\n",
        "                               ])  \n",
        "test_tfms =  torchvision.transforms.Compose([\n",
        "                                             T.ToFloatTensorInZeroOne(),\n",
        "                                             T.Resize((128, 128)),\n",
        "                                              T.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
        "                                             T.CenterCrop((112, 112))\n",
        "                                             ])\n",
        "hmdb51_train = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=True,\n",
        "                                                transform=train_tfms, num_workers=num_workers)\n",
        "\n",
        "\n",
        "hmdb51_test = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=False,\n",
        "                                                transform=test_tfms, num_workers=num_workers)\n",
        "      \n",
        "total_train_samples = len(hmdb51_train)\n",
        "total_val_samples = round(val_split * total_train_samples)\n",
        "\n",
        "print(f\"number of train samples {total_train_samples}\")\n",
        "print(f\"number of validation samples {total_val_samples}\")\n",
        "print(f\"number of test samples {len(hmdb51_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6c0d77874e04761a0eb2c4b443b7fbf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=423.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b947a3e939a04c9b9e28bdb70161081e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=423.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "number of train samples 7754\n",
            "number of validation samples 388\n",
            "number of test samples 3234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu_Jn-EwRriG"
      },
      "source": [
        "bs = 4\n",
        "lr = 1e-2\n",
        "gamma = 0.1\n",
        "step_size = 5\n",
        "total_epochs = 10\n",
        "config = {}\n",
        "\n",
        "kwargs = {'num_workers':num_workers, 'pin_memory':True} if torch.cuda.is_available() else {'num_workers':num_workers}\n",
        "#kwargs = {'num_workers':num_workers}\n",
        "#kwargs = {}\n",
        "\n",
        "hmdb51_train_v1, hmdb51_val_v1 = random_split(hmdb51_train, [total_train_samples - total_val_samples,\n",
        "                                                                       total_val_samples])\n",
        "\n",
        "#hmdb51_train_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "#hmdb51_val_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "#hmdb51_test.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "\n",
        "#train_sampler = RandomClipSampler(hmdb51_train_v1.video_clips, 5)\n",
        "#test_sampler = UniformClipSampler(hmdb51_test.video_clips, 5)\n",
        "  \n",
        "train_loader = DataLoader(hmdb51_train_v1, batch_size=32, shuffle=True, **kwargs)\n",
        "val_loader   = DataLoader(hmdb51_val_v1, batch_size=16, shuffle=True, **kwargs)\n",
        "test_loader  = DataLoader(hmdb51_test, batch_size=16, shuffle=False, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpCNF36v1kMA"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def conv_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(inp, oup, kernel_size=3, stride=stride, padding=(1, 1, 1), bias=False),\n",
        "        nn.BatchNorm3d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm3d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == (1, 1, 1) and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv3d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm3d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv3d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm3d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv3d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm3d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # dw\n",
        "                nn.Conv3d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm3d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv3d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm3d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=1000, sample_size=224, width_mult=1.):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "        inverted_residual_setting = [\n",
        "            # t, c, n, s\n",
        "            [1,  16, 1, (1,1,1)],\n",
        "            [6,  24, 2, (2,2,2)],\n",
        "            [6,  32, 3, (2,2,2)],\n",
        "            [6,  64, 4, (2,2,2)],\n",
        "            [6,  96, 3, (1,1,1)],\n",
        "            [6, 160, 3, (2,2,2)],\n",
        "            [6, 320, 1, (1,1,1)],\n",
        "        ]\n",
        "\n",
        "        # building first layer\n",
        "        assert sample_size % 16 == 0.\n",
        "        input_channel = int(input_channel * width_mult)\n",
        "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
        "        self.features = [conv_bn(3, input_channel, (1,2,2))]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = int(c * width_mult)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else (1,1,1)\n",
        "                self.features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        self.features.append(conv_1x1x1_bn(input_channel, self.last_channel))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = F.avg_pool3d(x, x.data.size()[-3:])\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                n = m.weight.size(1)\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def get_fine_tuning_parameters(model, ft_portion):\n",
        "    if ft_portion == \"complete\":\n",
        "        return model.parameters()\n",
        "\n",
        "    elif ft_portion == \"last_layer\":\n",
        "        ft_module_names = []\n",
        "        ft_module_names.append('classifier')\n",
        "\n",
        "        parameters = []\n",
        "        for k, v in model.named_parameters():\n",
        "            for ft_module in ft_module_names:\n",
        "                if ft_module in k:\n",
        "                    parameters.append({'params': v})\n",
        "                    break\n",
        "            else:\n",
        "                parameters.append({'params': v, 'lr': 0.0})\n",
        "        return parameters\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported ft_portion: 'complete' or 'last_layer' expected\")\n",
        "\n",
        "    \n",
        "def get_model(**kwargs):\n",
        "    \"\"\"\n",
        "    Returns the model.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(**kwargs)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdhy4hsv2I85"
      },
      "source": [
        "# model = get_model(num_classes=51, sample_size=112, width_mult=1.)\n",
        "# if (torch.cuda.is_available()):\n",
        "#   model = model.cuda()\n",
        "# model = nn.DataParallel(model, device_ids=None)\n",
        "# # print(model)\n",
        "# input_var = Variable(torch.randn(8, 3, 16, 112, 112))\n",
        "# output = model(input_var)\n",
        "# print(output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0enYk7pw6gXN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiiSedO46X-"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def update_acc(self, val, n=1):\n",
        "        self.val = val/n\n",
        "        self.sum += val\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def calculate_accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best,path):\n",
        "    torch.save(state, '%s' % (path))\n",
        "    if is_best:\n",
        "        shutil.copyfile('%s' % (path),'HAR_best.pth')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io8mTc9Q2kqP"
      },
      "source": [
        "def train_epoch(epoch, data_loader, model, optimizer):\n",
        "    print('train at epoch {}'.format(epoch))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    end_time = time.time()\n",
        "    for i, data in enumerate(data_loader):\n",
        "        inputs, targets = data[0], data[-1]\n",
        "        data_time.update(time.time() - end_time)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          targets = targets.cuda()\n",
        "          inputs = inputs.cuda()\n",
        "        inputs = Variable(inputs)\n",
        "        targets = Variable(targets)\n",
        "        outputs = model(inputs)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        losses.update(loss.data, inputs.size(0))\n",
        "        prec1, prec5 = calculate_accuracy(outputs.data, targets.data, topk=(1,5))\n",
        "        top1.update(prec1, inputs.size(0))\n",
        "        top5.update(prec5, inputs.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end_time)\n",
        "        end_time = time.time()\n",
        "\n",
        "        if i % 10 ==0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t lr: {lr:.5f}\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.5f} ({top1.avg:.5f})\\t'\n",
        "                  'Prec@5 {top5.val:.5f} ({top5.avg:.5f})'.format(\n",
        "                  epoch,\n",
        "                  i,\n",
        "                  len(data_loader),\n",
        "                  batch_time=batch_time,\n",
        "                  data_time=data_time,\n",
        "                  loss=losses,\n",
        "                  top1=top1,\n",
        "                  top5=top5,\n",
        "                  lr=optimizer.param_groups[0]['lr']))\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzzWuznm9CRv"
      },
      "source": [
        "def val_epoch(epoch, data_loader, model):\n",
        "  print('validation at epoch {}'.format(epoch))\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  batch_time = AverageMeter()\n",
        "  data_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "  top1 = AverageMeter()\n",
        "  top5 = AverageMeter()\n",
        "\n",
        "  end_time = time.time()\n",
        "  for i, data in enumerate(data_loader):\n",
        "      inputs, targets = data[0], data[-1]\n",
        "      data_time.update(time.time() - end_time)\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "          targets = targets.cuda()\n",
        "          inputs = inputs.cuda()\n",
        "      with torch.no_grad():\n",
        "          inputs = Variable(inputs)\n",
        "          targets = Variable(targets)\n",
        "      outputs = model(inputs)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      loss = criterion(outputs, targets)\n",
        "      prec1, prec5 = calculate_accuracy(outputs.data, targets.data, topk=(1,5))\n",
        "      top1.update(prec1, inputs.size(0))\n",
        "      top5.update(prec5, inputs.size(0))\n",
        "\n",
        "      losses.update(loss.data, inputs.size(0))\n",
        "\n",
        "      batch_time.update(time.time() - end_time)\n",
        "      end_time = time.time()\n",
        "\n",
        "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "            'Time {batch_time.val:.5f} ({batch_time.avg:.5f})\\t'\n",
        "            'Data {data_time.val:.5f} ({data_time.avg:.5f})\\t'\n",
        "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "            'Prec@1 {top1.val:.5f} ({top1.avg:.5f})\\t'\n",
        "            'Prec@5 {top5.val:.5f} ({top5.avg:.5f})'.format(\n",
        "            epoch,\n",
        "            i + 1,\n",
        "            len(data_loader),\n",
        "            batch_time=batch_time,\n",
        "            data_time=data_time,\n",
        "            loss=losses,\n",
        "            top1=top1,\n",
        "            top5=top5))\n",
        "  return losses.avg.item(), top1.avg.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYwWqHCOOQLJ"
      },
      "source": [
        "def test(data_loader, model):\n",
        "    print('test')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            inputs, targets = data[0], data[-1]\n",
        "            data_time.update(time.time() - end_time)\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda()\n",
        "                inputs = inputs.cuda()\n",
        "           \n",
        "            inputs = Variable(inputs)\n",
        "            targets = Variable(targets)\n",
        "            outputs = model(inputs)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(outputs, targets)\n",
        "            prec1, prec5 = calculate_accuracy(outputs.data, targets.data, topk=(1,5))\n",
        "            top1.update(prec1, inputs.size(0))\n",
        "            top5.update(prec5, inputs.size(0))\n",
        "\n",
        "            losses.update(loss.data, inputs.size(0))\n",
        "\n",
        "            batch_time.update(time.time() - end_time)\n",
        "            end_time = time.time()\n",
        "\n",
        "            print('[{0}/{1}]\\t'\n",
        "            'Time {batch_time.val:.5f} ({batch_time.avg:.5f})\\t'\n",
        "            'Data {data_time.val:.5f} ({data_time.avg:.5f})\\t'\n",
        "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "            'Prec@1 {top1.val:.5f} ({top1.avg:.5f})\\t'\n",
        "            'Prec@5 {top5.val:.5f} ({top5.avg:.5f})'.format(\n",
        "            i + 1,\n",
        "            len(data_loader),\n",
        "            batch_time=batch_time,\n",
        "            data_time=data_time,\n",
        "            loss=losses,\n",
        "            top1=top1,\n",
        "            top5=top5))\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyHJ1yBpE3I6"
      },
      "source": [
        "path = '/content/drive/MyDrive/HAR.pth'\n",
        "\n",
        "model = get_model(num_classes=51, sample_size=112, width_mult=1.)\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=lr,\n",
        "            momentum=0.9,\n",
        "            dampening=0.9,\n",
        "            weight_decay=1e-3)\n",
        "scheduler = ReduceLROnPlateau(\n",
        "            optimizer, 'min', patience=7)\n",
        "\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "best_prec1 = checkpoint['best_prec1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4SR9V_tuEiv",
        "outputId": "c7db5809-f6e4-439f-e9a8-068487e948c4"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for i in range(18, 19):\n",
        "    for param in model.features[i].parameters():\n",
        "      param.requires_grad = True\n",
        "for param in model.classifier.parameters():\n",
        "     param.requires_grad = True\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.477491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpqyIzKxv96e",
        "outputId": "716858a7-5913-4fab-a2a5-8565c0c30643"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmyilSGB35UJ",
        "outputId": "0a8fb244-f1cd-42e6-fd9e-b36dc901b7f3"
      },
      "source": [
        "\n",
        "print(\"Launching Action Recognition Model training\")\n",
        "for i in range(30):\n",
        "  train_epoch(i, train_loader, model, optimizer)\n",
        "  state = {\n",
        "      'state_dict': model.state_dict(),\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'best_prec1': best_prec1\n",
        "      }\n",
        "  save_checkpoint(state, False, path)\n",
        "  validation_loss, prec1 = val_epoch(i, val_loader, model)\n",
        "  is_best = prec1 > best_prec1\n",
        "  best_prec1 = max(prec1, best_prec1)\n",
        "  state = {\n",
        "  'state_dict': model.state_dict(),\n",
        "  'optimizer': optimizer.state_dict(),\n",
        "  'best_prec1': best_prec1\n",
        "  }\n",
        "  save_checkpoint(state, is_best, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Launching Action Recognition Model training\n",
            "train at epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/231]\t lr: 0.00100\tTime 3.951 (3.951)\tData 3.505 (3.505)\tLoss 1.0564 (1.0564)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [0][10/231]\t lr: 0.00100\tTime 2.436 (1.860)\tData 2.089 (1.534)\tLoss 0.9747 (1.0657)\tPrec@1 71.87500 (71.59091)\tPrec@5 96.87500 (92.32955)\n",
            "Epoch: [0][20/231]\t lr: 0.00100\tTime 1.794 (1.758)\tData 1.530 (1.463)\tLoss 1.1200 (1.0888)\tPrec@1 68.75000 (70.23810)\tPrec@5 93.75000 (91.66667)\n",
            "Epoch: [0][30/231]\t lr: 0.00100\tTime 2.219 (1.747)\tData 1.920 (1.462)\tLoss 1.1291 (1.1202)\tPrec@1 71.87500 (68.75000)\tPrec@5 87.50000 (91.83467)\n",
            "Epoch: [0][40/231]\t lr: 0.00100\tTime 1.958 (1.728)\tData 1.692 (1.443)\tLoss 1.2424 (1.1500)\tPrec@1 62.50000 (68.21646)\tPrec@5 90.62500 (91.31097)\n",
            "Epoch: [0][50/231]\t lr: 0.00100\tTime 1.443 (1.712)\tData 1.188 (1.431)\tLoss 1.2577 (1.1638)\tPrec@1 68.75000 (68.07598)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [0][60/231]\t lr: 0.00100\tTime 1.989 (1.713)\tData 1.763 (1.434)\tLoss 1.2781 (1.1462)\tPrec@1 62.50000 (68.74999)\tPrec@5 84.37500 (90.67622)\n",
            "Epoch: [0][70/231]\t lr: 0.00100\tTime 2.017 (1.710)\tData 1.776 (1.433)\tLoss 1.1502 (1.1386)\tPrec@1 65.62500 (68.79401)\tPrec@5 87.50000 (90.84507)\n",
            "Epoch: [0][80/231]\t lr: 0.00100\tTime 1.692 (1.704)\tData 1.499 (1.424)\tLoss 1.0851 (1.1433)\tPrec@1 65.62500 (68.44136)\tPrec@5 96.87500 (90.93364)\n",
            "Epoch: [0][90/231]\t lr: 0.00100\tTime 2.438 (1.705)\tData 2.109 (1.425)\tLoss 0.9071 (1.1503)\tPrec@1 75.00000 (68.40659)\tPrec@5 93.75000 (90.76237)\n",
            "Epoch: [0][100/231]\t lr: 0.00100\tTime 2.647 (1.706)\tData 2.268 (1.423)\tLoss 1.0587 (1.1515)\tPrec@1 59.37500 (68.10025)\tPrec@5 96.87500 (90.96535)\n",
            "Epoch: [0][110/231]\t lr: 0.00100\tTime 2.629 (1.706)\tData 2.288 (1.420)\tLoss 1.2332 (1.1544)\tPrec@1 59.37500 (67.79279)\tPrec@5 90.62500 (90.90653)\n",
            "Epoch: [0][120/231]\t lr: 0.00100\tTime 2.573 (1.703)\tData 2.222 (1.417)\tLoss 1.3803 (1.1587)\tPrec@1 62.50000 (67.69112)\tPrec@5 84.37500 (90.80578)\n",
            "Epoch: [0][130/231]\t lr: 0.00100\tTime 3.012 (1.702)\tData 2.708 (1.415)\tLoss 1.1340 (1.1592)\tPrec@1 68.75000 (67.62881)\tPrec@5 93.75000 (90.88741)\n",
            "Epoch: [0][140/231]\t lr: 0.00100\tTime 2.818 (1.701)\tData 2.502 (1.414)\tLoss 1.4358 (1.1597)\tPrec@1 56.25000 (67.77482)\tPrec@5 81.25000 (90.75797)\n",
            "Epoch: [0][150/231]\t lr: 0.00100\tTime 1.948 (1.694)\tData 1.652 (1.405)\tLoss 1.0570 (1.1644)\tPrec@1 65.62500 (67.65314)\tPrec@5 90.62500 (90.76987)\n",
            "Epoch: [0][160/231]\t lr: 0.00100\tTime 1.892 (1.695)\tData 1.650 (1.408)\tLoss 1.2296 (1.1662)\tPrec@1 65.62500 (67.62422)\tPrec@5 90.62500 (90.66382)\n",
            "Epoch: [0][170/231]\t lr: 0.00100\tTime 1.049 (1.691)\tData 0.750 (1.404)\tLoss 1.3972 (1.1671)\tPrec@1 53.12500 (67.56213)\tPrec@5 87.50000 (90.71638)\n",
            "Epoch: [0][180/231]\t lr: 0.00100\tTime 1.284 (1.693)\tData 1.014 (1.404)\tLoss 0.7402 (1.1637)\tPrec@1 78.12500 (67.67956)\tPrec@5 93.75000 (90.65953)\n",
            "Epoch: [0][190/231]\t lr: 0.00100\tTime 1.133 (1.692)\tData 0.843 (1.402)\tLoss 0.9963 (1.1668)\tPrec@1 68.75000 (67.62107)\tPrec@5 87.50000 (90.55956)\n",
            "Epoch: [0][200/231]\t lr: 0.00100\tTime 0.439 (1.691)\tData 0.137 (1.401)\tLoss 1.0319 (1.1648)\tPrec@1 71.87500 (67.63059)\tPrec@5 93.75000 (90.51617)\n",
            "Epoch: [0][210/231]\t lr: 0.00100\tTime 0.265 (1.693)\tData 0.000 (1.402)\tLoss 1.2904 (1.1744)\tPrec@1 68.75000 (67.38744)\tPrec@5 87.50000 (90.34361)\n",
            "Epoch: [0][220/231]\t lr: 0.00100\tTime 0.243 (1.698)\tData 0.002 (1.406)\tLoss 1.0534 (1.1753)\tPrec@1 71.87500 (67.40668)\tPrec@5 93.75000 (90.37048)\n",
            "Epoch: [0][230/231]\t lr: 0.00100\tTime 0.068 (1.690)\tData 0.000 (1.399)\tLoss 2.0545 (1.1811)\tPrec@1 66.66666 (67.30926)\tPrec@5 66.66666 (90.30682)\n",
            "validation at epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][1/25]\tTime 2.21053 (2.21053)\tData 1.96228 (1.96228)\tLoss 1.2960 (1.2960)\tPrec@1 68.75000 (68.75000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [0][2/25]\tTime 0.17888 (1.19471)\tData 0.00145 (0.98187)\tLoss 1.7348 (1.5154)\tPrec@1 62.50000 (65.62500)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [0][3/25]\tTime 1.78994 (1.39312)\tData 1.58739 (1.18371)\tLoss 0.9016 (1.3108)\tPrec@1 75.00000 (68.75000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [0][4/25]\tTime 0.19323 (1.09315)\tData 0.00114 (0.88807)\tLoss 0.5851 (1.1294)\tPrec@1 81.25000 (71.87500)\tPrec@5 100.00000 (90.62500)\n",
            "Epoch: [0][5/25]\tTime 1.53290 (1.18110)\tData 1.35941 (0.98234)\tLoss 1.6266 (1.2288)\tPrec@1 62.50000 (70.00000)\tPrec@5 75.00000 (87.50000)\n",
            "Epoch: [0][6/25]\tTime 0.13677 (1.00704)\tData 0.00143 (0.81885)\tLoss 2.1710 (1.3858)\tPrec@1 50.00000 (66.66667)\tPrec@5 75.00000 (85.41667)\n",
            "Epoch: [0][7/25]\tTime 1.56891 (1.08731)\tData 1.46806 (0.91160)\tLoss 1.4517 (1.3952)\tPrec@1 37.50000 (62.50000)\tPrec@5 87.50000 (85.71429)\n",
            "Epoch: [0][8/25]\tTime 0.17089 (0.97276)\tData 0.00137 (0.79782)\tLoss 1.4325 (1.3999)\tPrec@1 56.25000 (61.71875)\tPrec@5 93.75000 (86.71875)\n",
            "Epoch: [0][9/25]\tTime 1.83798 (1.06889)\tData 1.64062 (0.89146)\tLoss 0.7936 (1.3325)\tPrec@1 81.25000 (63.88889)\tPrec@5 87.50000 (86.80556)\n",
            "Epoch: [0][10/25]\tTime 0.22295 (0.98430)\tData 0.00747 (0.80306)\tLoss 0.8495 (1.2842)\tPrec@1 75.00000 (65.00000)\tPrec@5 87.50000 (86.87500)\n",
            "Epoch: [0][11/25]\tTime 1.62510 (1.04255)\tData 1.47752 (0.86438)\tLoss 0.7075 (1.2318)\tPrec@1 81.25000 (66.47727)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [0][12/25]\tTime 0.20812 (0.97302)\tData 0.00163 (0.79248)\tLoss 1.0056 (1.2130)\tPrec@1 68.75000 (66.66667)\tPrec@5 100.00000 (88.54167)\n",
            "Epoch: [0][13/25]\tTime 1.50495 (1.01394)\tData 1.36776 (0.83673)\tLoss 1.0403 (1.1997)\tPrec@1 81.25000 (67.78847)\tPrec@5 100.00000 (89.42308)\n",
            "Epoch: [0][14/25]\tTime 0.18885 (0.95500)\tData 0.00752 (0.77751)\tLoss 1.3576 (1.2110)\tPrec@1 62.50000 (67.41072)\tPrec@5 87.50000 (89.28572)\n",
            "Epoch: [0][15/25]\tTime 1.47905 (0.98994)\tData 1.30397 (0.81260)\tLoss 1.4743 (1.2285)\tPrec@1 62.50000 (67.08334)\tPrec@5 81.25000 (88.75001)\n",
            "Epoch: [0][16/25]\tTime 0.16185 (0.93818)\tData 0.00210 (0.76195)\tLoss 0.9516 (1.2112)\tPrec@1 75.00000 (67.57812)\tPrec@5 93.75000 (89.06250)\n",
            "Epoch: [0][17/25]\tTime 1.63143 (0.97896)\tData 1.44308 (0.80201)\tLoss 1.0891 (1.2040)\tPrec@1 75.00000 (68.01471)\tPrec@5 93.75000 (89.33823)\n",
            "Epoch: [0][18/25]\tTime 0.20090 (0.93574)\tData 0.00197 (0.75757)\tLoss 1.7944 (1.2368)\tPrec@1 56.25000 (67.36111)\tPrec@5 75.00000 (88.54166)\n",
            "Epoch: [0][19/25]\tTime 1.25044 (0.95230)\tData 1.10826 (0.77602)\tLoss 1.7409 (1.2634)\tPrec@1 50.00000 (66.44737)\tPrec@5 87.50000 (88.48684)\n",
            "Epoch: [0][20/25]\tTime 0.18164 (0.91377)\tData 0.00170 (0.73731)\tLoss 0.5900 (1.2297)\tPrec@1 75.00000 (66.87500)\tPrec@5 100.00000 (89.06250)\n",
            "Epoch: [0][21/25]\tTime 1.58897 (0.94592)\tData 1.39252 (0.76851)\tLoss 0.9906 (1.2183)\tPrec@1 68.75000 (66.96429)\tPrec@5 93.75000 (89.28571)\n",
            "Epoch: [0][22/25]\tTime 0.19927 (0.91198)\tData 0.00275 (0.73370)\tLoss 1.3896 (1.2261)\tPrec@1 68.75000 (67.04546)\tPrec@5 81.25000 (88.92046)\n",
            "Epoch: [0][23/25]\tTime 1.17424 (0.92338)\tData 1.02428 (0.74633)\tLoss 1.0958 (1.2204)\tPrec@1 68.75000 (67.11957)\tPrec@5 87.50000 (88.85870)\n",
            "Epoch: [0][24/25]\tTime 0.14179 (0.89082)\tData 0.00105 (0.71528)\tLoss 1.0775 (1.2145)\tPrec@1 62.50000 (66.92709)\tPrec@5 93.75000 (89.06250)\n",
            "Epoch: [0][25/25]\tTime 0.06032 (0.85760)\tData 0.00092 (0.68671)\tLoss 0.9853 (1.2121)\tPrec@1 75.00000 (67.01031)\tPrec@5 100.00000 (89.17525)\n",
            "train at epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/231]\t lr: 0.00100\tTime 4.078 (4.078)\tData 3.681 (3.681)\tLoss 1.0229 (1.0229)\tPrec@1 81.25000 (81.25000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [1][10/231]\t lr: 0.00100\tTime 3.122 (1.964)\tData 2.767 (1.641)\tLoss 1.0358 (1.0436)\tPrec@1 75.00000 (72.44318)\tPrec@5 87.50000 (90.90910)\n",
            "Epoch: [1][20/231]\t lr: 0.00100\tTime 3.314 (1.821)\tData 2.977 (1.510)\tLoss 1.0714 (1.1065)\tPrec@1 71.87500 (69.79167)\tPrec@5 90.62500 (90.02976)\n",
            "Epoch: [1][30/231]\t lr: 0.00100\tTime 2.785 (1.767)\tData 2.451 (1.451)\tLoss 1.1512 (1.1161)\tPrec@1 62.50000 (70.06048)\tPrec@5 90.62500 (90.12096)\n",
            "Epoch: [1][40/231]\t lr: 0.00100\tTime 3.349 (1.767)\tData 3.043 (1.455)\tLoss 1.0335 (1.1183)\tPrec@1 75.00000 (70.12195)\tPrec@5 93.75000 (89.86280)\n",
            "Epoch: [1][50/231]\t lr: 0.00100\tTime 3.171 (1.765)\tData 2.821 (1.453)\tLoss 0.9565 (1.1263)\tPrec@1 75.00000 (69.42402)\tPrec@5 93.75000 (90.44118)\n",
            "Epoch: [1][60/231]\t lr: 0.00100\tTime 2.905 (1.752)\tData 2.503 (1.439)\tLoss 1.0993 (1.1417)\tPrec@1 68.75000 (68.85246)\tPrec@5 93.75000 (90.06147)\n",
            "Epoch: [1][70/231]\t lr: 0.00100\tTime 3.051 (1.752)\tData 2.737 (1.440)\tLoss 1.3610 (1.1533)\tPrec@1 68.75000 (68.48592)\tPrec@5 93.75000 (89.87676)\n",
            "Epoch: [1][80/231]\t lr: 0.00100\tTime 3.166 (1.734)\tData 2.837 (1.425)\tLoss 1.1179 (1.1530)\tPrec@1 68.75000 (68.44136)\tPrec@5 93.75000 (90.20061)\n",
            "Epoch: [1][90/231]\t lr: 0.00100\tTime 2.955 (1.729)\tData 2.629 (1.421)\tLoss 1.0966 (1.1622)\tPrec@1 62.50000 (67.96017)\tPrec@5 93.75000 (90.28159)\n",
            "Epoch: [1][100/231]\t lr: 0.00100\tTime 2.734 (1.727)\tData 2.428 (1.420)\tLoss 0.9881 (1.1599)\tPrec@1 71.87500 (67.91460)\tPrec@5 93.75000 (90.31559)\n",
            "Epoch: [1][110/231]\t lr: 0.00100\tTime 2.902 (1.720)\tData 2.591 (1.413)\tLoss 1.2935 (1.1670)\tPrec@1 59.37500 (67.73649)\tPrec@5 93.75000 (90.31532)\n",
            "Epoch: [1][120/231]\t lr: 0.00100\tTime 2.843 (1.723)\tData 2.494 (1.417)\tLoss 1.2812 (1.1677)\tPrec@1 59.37500 (67.58781)\tPrec@5 90.62500 (90.39256)\n",
            "Epoch: [1][130/231]\t lr: 0.00100\tTime 3.083 (1.722)\tData 2.758 (1.416)\tLoss 1.0367 (1.1665)\tPrec@1 65.62500 (67.65267)\tPrec@5 93.75000 (90.60114)\n",
            "Epoch: [1][140/231]\t lr: 0.00100\tTime 3.059 (1.721)\tData 2.685 (1.416)\tLoss 0.9373 (1.1662)\tPrec@1 71.87500 (67.73049)\tPrec@5 100.00000 (90.62500)\n",
            "Epoch: [1][150/231]\t lr: 0.00100\tTime 3.253 (1.721)\tData 2.875 (1.417)\tLoss 0.9599 (1.1685)\tPrec@1 71.87500 (67.48758)\tPrec@5 93.75000 (90.58361)\n",
            "Epoch: [1][160/231]\t lr: 0.00100\tTime 2.995 (1.720)\tData 2.676 (1.416)\tLoss 1.5328 (1.1665)\tPrec@1 56.25000 (67.62422)\tPrec@5 81.25000 (90.62500)\n",
            "Epoch: [1][170/231]\t lr: 0.00100\tTime 3.387 (1.718)\tData 3.046 (1.414)\tLoss 0.8760 (1.1722)\tPrec@1 78.12500 (67.67178)\tPrec@5 93.75000 (90.46053)\n",
            "Epoch: [1][180/231]\t lr: 0.00100\tTime 2.991 (1.717)\tData 2.667 (1.413)\tLoss 1.0967 (1.1771)\tPrec@1 71.87500 (67.67956)\tPrec@5 90.62500 (90.26244)\n",
            "Epoch: [1][190/231]\t lr: 0.00100\tTime 2.668 (1.714)\tData 2.350 (1.410)\tLoss 1.1332 (1.1735)\tPrec@1 71.87500 (67.81741)\tPrec@5 90.62500 (90.24870)\n",
            "Epoch: [1][200/231]\t lr: 0.00100\tTime 3.049 (1.714)\tData 2.692 (1.410)\tLoss 1.4334 (1.1703)\tPrec@1 59.37500 (67.87935)\tPrec@5 81.25000 (90.31406)\n",
            "Epoch: [1][210/231]\t lr: 0.00100\tTime 2.864 (1.712)\tData 2.522 (1.408)\tLoss 1.2065 (1.1712)\tPrec@1 68.75000 (67.90581)\tPrec@5 93.75000 (90.35841)\n",
            "Epoch: [1][220/231]\t lr: 0.00100\tTime 3.381 (1.711)\tData 3.003 (1.408)\tLoss 1.0875 (1.1753)\tPrec@1 75.00000 (67.84502)\tPrec@5 87.50000 (90.24322)\n",
            "Epoch: [1][230/231]\t lr: 0.00100\tTime 0.065 (1.696)\tData 0.000 (1.395)\tLoss 1.6423 (1.1735)\tPrec@1 66.66666 (67.93375)\tPrec@5 100.00000 (90.36111)\n",
            "validation at epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][1/25]\tTime 2.15757 (2.15757)\tData 1.93384 (1.93384)\tLoss 1.2938 (1.2938)\tPrec@1 62.50000 (62.50000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [1][2/25]\tTime 0.14665 (1.15211)\tData 0.00728 (0.97056)\tLoss 1.2082 (1.2510)\tPrec@1 68.75000 (65.62500)\tPrec@5 81.25000 (84.37500)\n",
            "Epoch: [1][3/25]\tTime 1.75581 (1.35334)\tData 1.56117 (1.16743)\tLoss 0.7542 (1.0854)\tPrec@1 81.25000 (70.83334)\tPrec@5 100.00000 (89.58334)\n",
            "Epoch: [1][4/25]\tTime 0.14067 (1.05018)\tData 0.00842 (0.87768)\tLoss 0.6933 (0.9874)\tPrec@1 75.00000 (71.87500)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [1][5/25]\tTime 1.64580 (1.16930)\tData 1.48748 (0.99964)\tLoss 0.9157 (0.9730)\tPrec@1 81.25000 (73.75000)\tPrec@5 87.50000 (90.00000)\n",
            "Epoch: [1][6/25]\tTime 0.16877 (1.00255)\tData 0.00117 (0.83323)\tLoss 1.4807 (1.0576)\tPrec@1 50.00000 (69.79167)\tPrec@5 81.25000 (88.54167)\n",
            "Epoch: [1][7/25]\tTime 1.59184 (1.08673)\tData 1.46072 (0.92287)\tLoss 1.3995 (1.1065)\tPrec@1 62.50000 (68.75000)\tPrec@5 81.25000 (87.50001)\n",
            "Epoch: [1][8/25]\tTime 0.19865 (0.97572)\tData 0.00840 (0.80856)\tLoss 1.7210 (1.1833)\tPrec@1 56.25000 (67.18750)\tPrec@5 75.00000 (85.93750)\n",
            "Epoch: [1][9/25]\tTime 1.42631 (1.02579)\tData 1.23222 (0.85563)\tLoss 0.9400 (1.1563)\tPrec@1 87.50000 (69.44444)\tPrec@5 87.50000 (86.11111)\n",
            "Epoch: [1][10/25]\tTime 0.14437 (0.93764)\tData 0.00753 (0.77082)\tLoss 1.0691 (1.1476)\tPrec@1 68.75000 (69.37500)\tPrec@5 93.75000 (86.87500)\n",
            "Epoch: [1][11/25]\tTime 1.49787 (0.98857)\tData 1.30751 (0.81961)\tLoss 0.8722 (1.1225)\tPrec@1 75.00000 (69.88637)\tPrec@5 87.50000 (86.93182)\n",
            "Epoch: [1][12/25]\tTime 0.15779 (0.91934)\tData 0.00734 (0.75192)\tLoss 1.3192 (1.1389)\tPrec@1 68.75000 (69.79167)\tPrec@5 75.00000 (85.93750)\n",
            "Epoch: [1][13/25]\tTime 1.77175 (0.98491)\tData 1.56203 (0.81424)\tLoss 0.9198 (1.1221)\tPrec@1 75.00000 (70.19231)\tPrec@5 87.50000 (86.05769)\n",
            "Epoch: [1][14/25]\tTime 0.15331 (0.92551)\tData 0.00673 (0.75656)\tLoss 1.7185 (1.1647)\tPrec@1 75.00000 (70.53572)\tPrec@5 75.00000 (85.26786)\n",
            "Epoch: [1][15/25]\tTime 1.36175 (0.95460)\tData 1.17245 (0.78429)\tLoss 1.9755 (1.2187)\tPrec@1 50.00000 (69.16667)\tPrec@5 87.50000 (85.41667)\n",
            "Epoch: [1][16/25]\tTime 0.15111 (0.90438)\tData 0.00819 (0.73578)\tLoss 2.4322 (1.2946)\tPrec@1 50.00000 (67.96875)\tPrec@5 75.00000 (84.76562)\n",
            "Epoch: [1][17/25]\tTime 1.50099 (0.93947)\tData 1.30812 (0.76945)\tLoss 0.9140 (1.2722)\tPrec@1 75.00000 (68.38235)\tPrec@5 100.00000 (85.66177)\n",
            "Epoch: [1][18/25]\tTime 0.22509 (0.89978)\tData 0.04597 (0.72925)\tLoss 0.6887 (1.2398)\tPrec@1 81.25000 (69.09722)\tPrec@5 100.00000 (86.45834)\n",
            "Epoch: [1][19/25]\tTime 1.55983 (0.93452)\tData 1.37546 (0.76326)\tLoss 1.2701 (1.2414)\tPrec@1 68.75000 (69.07895)\tPrec@5 87.50000 (86.51316)\n",
            "Epoch: [1][20/25]\tTime 0.26795 (0.90119)\tData 0.05266 (0.72773)\tLoss 1.1560 (1.2371)\tPrec@1 81.25000 (69.68750)\tPrec@5 87.50000 (86.56250)\n",
            "Epoch: [1][21/25]\tTime 1.43879 (0.92679)\tData 1.23629 (0.75195)\tLoss 1.2268 (1.2366)\tPrec@1 68.75000 (69.64286)\tPrec@5 93.75000 (86.90476)\n",
            "Epoch: [1][22/25]\tTime 0.19533 (0.89355)\tData 0.00110 (0.71782)\tLoss 1.4092 (1.2444)\tPrec@1 50.00000 (68.75000)\tPrec@5 93.75000 (87.21591)\n",
            "Epoch: [1][23/25]\tTime 1.54928 (0.92206)\tData 1.40834 (0.74784)\tLoss 0.5045 (1.2123)\tPrec@1 81.25000 (69.29348)\tPrec@5 100.00000 (87.77174)\n",
            "Epoch: [1][24/25]\tTime 0.10941 (0.88820)\tData 0.00161 (0.71675)\tLoss 0.5650 (1.1853)\tPrec@1 93.75000 (70.31250)\tPrec@5 93.75000 (88.02084)\n",
            "Epoch: [1][25/25]\tTime 0.12646 (0.85773)\tData 0.06408 (0.69064)\tLoss 0.9112 (1.1825)\tPrec@1 50.00000 (70.10309)\tPrec@5 100.00000 (88.14433)\n",
            "train at epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/231]\t lr: 0.00100\tTime 3.898 (3.898)\tData 3.616 (3.616)\tLoss 1.0687 (1.0687)\tPrec@1 75.00000 (75.00000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [2][10/231]\t lr: 0.00100\tTime 2.237 (1.832)\tData 1.866 (1.535)\tLoss 1.0479 (1.1316)\tPrec@1 68.75000 (71.02273)\tPrec@5 100.00000 (92.04546)\n",
            "Epoch: [2][20/231]\t lr: 0.00100\tTime 3.005 (1.773)\tData 2.654 (1.471)\tLoss 1.1783 (1.2329)\tPrec@1 56.25000 (65.32738)\tPrec@5 90.62500 (91.07143)\n",
            "Epoch: [2][30/231]\t lr: 0.00100\tTime 2.909 (1.749)\tData 2.528 (1.452)\tLoss 0.8622 (1.1758)\tPrec@1 71.87500 (66.53226)\tPrec@5 96.87500 (91.43145)\n",
            "Epoch: [2][40/231]\t lr: 0.00100\tTime 3.079 (1.750)\tData 2.762 (1.451)\tLoss 1.0423 (1.1866)\tPrec@1 68.75000 (66.53963)\tPrec@5 93.75000 (91.08231)\n",
            "Epoch: [2][50/231]\t lr: 0.00100\tTime 3.102 (1.745)\tData 2.734 (1.443)\tLoss 1.3311 (1.1794)\tPrec@1 62.50000 (66.60539)\tPrec@5 93.75000 (91.48285)\n",
            "Epoch: [2][60/231]\t lr: 0.00100\tTime 3.282 (1.731)\tData 2.930 (1.429)\tLoss 1.2346 (1.1805)\tPrec@1 75.00000 (67.21311)\tPrec@5 90.62500 (91.08606)\n",
            "Epoch: [2][70/231]\t lr: 0.00100\tTime 2.983 (1.720)\tData 2.597 (1.415)\tLoss 1.4063 (1.1777)\tPrec@1 53.12500 (66.81338)\tPrec@5 81.25000 (90.88908)\n",
            "Epoch: [2][80/231]\t lr: 0.00100\tTime 2.887 (1.713)\tData 2.519 (1.409)\tLoss 1.0475 (1.1848)\tPrec@1 75.00000 (67.09105)\tPrec@5 90.62500 (90.77932)\n",
            "Epoch: [2][90/231]\t lr: 0.00100\tTime 3.278 (1.710)\tData 2.933 (1.407)\tLoss 1.5485 (1.1903)\tPrec@1 65.62500 (67.10165)\tPrec@5 81.25000 (90.48764)\n",
            "Epoch: [2][100/231]\t lr: 0.00100\tTime 3.145 (1.707)\tData 2.813 (1.405)\tLoss 1.2221 (1.1896)\tPrec@1 59.37500 (67.07921)\tPrec@5 84.37500 (90.34653)\n",
            "Epoch: [2][110/231]\t lr: 0.00100\tTime 3.188 (1.706)\tData 2.850 (1.403)\tLoss 1.1429 (1.1758)\tPrec@1 62.50000 (67.48311)\tPrec@5 90.62500 (90.42793)\n",
            "Epoch: [2][120/231]\t lr: 0.00100\tTime 2.984 (1.699)\tData 2.689 (1.396)\tLoss 1.4539 (1.1811)\tPrec@1 62.50000 (67.25206)\tPrec@5 84.37500 (90.34090)\n",
            "Epoch: [2][130/231]\t lr: 0.00100\tTime 2.929 (1.699)\tData 2.629 (1.397)\tLoss 1.1731 (1.1775)\tPrec@1 65.62500 (67.27100)\tPrec@5 93.75000 (90.33874)\n",
            "Epoch: [2][140/231]\t lr: 0.00100\tTime 2.804 (1.694)\tData 2.421 (1.390)\tLoss 1.0984 (1.1727)\tPrec@1 65.62500 (67.46454)\tPrec@5 90.62500 (90.33688)\n",
            "Epoch: [2][150/231]\t lr: 0.00100\tTime 3.136 (1.696)\tData 2.737 (1.391)\tLoss 0.6015 (1.1719)\tPrec@1 81.25000 (67.52898)\tPrec@5 96.87500 (90.27318)\n",
            "Epoch: [2][160/231]\t lr: 0.00100\tTime 1.820 (1.690)\tData 1.553 (1.385)\tLoss 1.5303 (1.1800)\tPrec@1 53.12500 (67.23602)\tPrec@5 84.37500 (90.15916)\n",
            "Epoch: [2][170/231]\t lr: 0.00100\tTime 2.678 (1.691)\tData 2.358 (1.386)\tLoss 0.9584 (1.1768)\tPrec@1 75.00000 (67.26974)\tPrec@5 90.62500 (90.20468)\n",
            "Epoch: [2][180/231]\t lr: 0.00100\tTime 3.273 (1.694)\tData 2.953 (1.388)\tLoss 1.0351 (1.1781)\tPrec@1 75.00000 (67.28246)\tPrec@5 90.62500 (90.24517)\n",
            "Epoch: [2][190/231]\t lr: 0.00100\tTime 3.342 (1.693)\tData 2.967 (1.387)\tLoss 1.2515 (1.1803)\tPrec@1 65.62500 (67.19568)\tPrec@5 93.75000 (90.18325)\n",
            "Epoch: [2][200/231]\t lr: 0.00100\tTime 3.594 (1.693)\tData 3.249 (1.388)\tLoss 1.2435 (1.1746)\tPrec@1 62.50000 (67.27301)\tPrec@5 93.75000 (90.29851)\n",
            "Epoch: [2][210/231]\t lr: 0.00100\tTime 3.063 (1.693)\tData 2.734 (1.388)\tLoss 1.4210 (1.1786)\tPrec@1 62.50000 (67.13567)\tPrec@5 87.50000 (90.19550)\n",
            "Epoch: [2][220/231]\t lr: 0.00100\tTime 2.837 (1.690)\tData 2.484 (1.385)\tLoss 1.2851 (1.1747)\tPrec@1 59.37500 (67.29356)\tPrec@5 90.62500 (90.29977)\n",
            "Epoch: [2][230/231]\t lr: 0.00100\tTime 0.064 (1.676)\tData 0.000 (1.373)\tLoss 2.3679 (1.1789)\tPrec@1 50.00000 (67.20065)\tPrec@5 50.00000 (90.27966)\n",
            "validation at epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][1/25]\tTime 2.19791 (2.19791)\tData 1.96206 (1.96206)\tLoss 0.8241 (0.8241)\tPrec@1 81.25000 (81.25000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [2][2/25]\tTime 0.17446 (1.18619)\tData 0.00141 (0.98174)\tLoss 1.4767 (1.1504)\tPrec@1 68.75000 (75.00000)\tPrec@5 81.25000 (84.37500)\n",
            "Epoch: [2][3/25]\tTime 1.43383 (1.26873)\tData 1.23618 (1.06655)\tLoss 1.4182 (1.2397)\tPrec@1 68.75000 (72.91667)\tPrec@5 75.00000 (81.25000)\n",
            "Epoch: [2][4/25]\tTime 0.51673 (1.08073)\tData 0.31264 (0.87807)\tLoss 0.8438 (1.1407)\tPrec@1 75.00000 (73.43750)\tPrec@5 100.00000 (85.93750)\n",
            "Epoch: [2][5/25]\tTime 1.30724 (1.12604)\tData 1.10411 (0.92328)\tLoss 1.0544 (1.1234)\tPrec@1 62.50000 (71.25000)\tPrec@5 87.50000 (86.25000)\n",
            "Epoch: [2][6/25]\tTime 0.15828 (0.96474)\tData 0.01411 (0.77175)\tLoss 0.8997 (1.0862)\tPrec@1 75.00000 (71.87500)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [2][7/25]\tTime 1.45499 (1.03478)\tData 1.29110 (0.84594)\tLoss 0.5048 (1.0031)\tPrec@1 81.25000 (73.21429)\tPrec@5 100.00000 (89.28572)\n",
            "Epoch: [2][8/25]\tTime 0.53019 (0.97171)\tData 0.34904 (0.78383)\tLoss 1.5328 (1.0693)\tPrec@1 50.00000 (70.31250)\tPrec@5 93.75000 (89.84375)\n",
            "Epoch: [2][9/25]\tTime 1.21668 (0.99892)\tData 1.03755 (0.81202)\tLoss 1.2827 (1.0930)\tPrec@1 75.00000 (70.83334)\tPrec@5 87.50000 (89.58334)\n",
            "Epoch: [2][10/25]\tTime 0.52755 (0.95179)\tData 0.35393 (0.76621)\tLoss 1.3090 (1.1146)\tPrec@1 56.25000 (69.37500)\tPrec@5 87.50000 (89.37500)\n",
            "Epoch: [2][11/25]\tTime 1.16801 (0.97144)\tData 1.00067 (0.78753)\tLoss 1.4674 (1.1467)\tPrec@1 62.50000 (68.75000)\tPrec@5 87.50000 (89.20455)\n",
            "Epoch: [2][12/25]\tTime 0.45485 (0.92839)\tData 0.26364 (0.74387)\tLoss 1.3859 (1.1666)\tPrec@1 56.25000 (67.70834)\tPrec@5 87.50000 (89.06250)\n",
            "Epoch: [2][13/25]\tTime 1.27069 (0.95472)\tData 1.07524 (0.76936)\tLoss 1.5145 (1.1934)\tPrec@1 62.50000 (67.30769)\tPrec@5 81.25000 (88.46154)\n",
            "Epoch: [2][14/25]\tTime 0.56736 (0.92706)\tData 0.40341 (0.74322)\tLoss 1.4912 (1.2147)\tPrec@1 56.25000 (66.51786)\tPrec@5 75.00000 (87.50001)\n",
            "Epoch: [2][15/25]\tTime 0.98076 (0.93064)\tData 0.81985 (0.74833)\tLoss 0.6854 (1.1794)\tPrec@1 81.25000 (67.50000)\tPrec@5 93.75000 (87.91667)\n",
            "Epoch: [2][16/25]\tTime 0.61701 (0.91103)\tData 0.45378 (0.72992)\tLoss 1.3604 (1.1907)\tPrec@1 62.50000 (67.18750)\tPrec@5 93.75000 (88.28125)\n",
            "Epoch: [2][17/25]\tTime 1.10287 (0.92232)\tData 0.91458 (0.74078)\tLoss 0.8678 (1.1717)\tPrec@1 75.00000 (67.64706)\tPrec@5 100.00000 (88.97059)\n",
            "Epoch: [2][18/25]\tTime 0.62500 (0.90580)\tData 0.44912 (0.72458)\tLoss 1.2064 (1.1736)\tPrec@1 68.75000 (67.70834)\tPrec@5 93.75000 (89.23611)\n",
            "Epoch: [2][19/25]\tTime 1.23083 (0.92291)\tData 1.04722 (0.74156)\tLoss 0.7432 (1.1510)\tPrec@1 81.25000 (68.42105)\tPrec@5 100.00000 (89.80264)\n",
            "Epoch: [2][20/25]\tTime 0.19948 (0.88674)\tData 0.00735 (0.70485)\tLoss 1.6569 (1.1763)\tPrec@1 56.25000 (67.81250)\tPrec@5 68.75000 (88.75000)\n",
            "Epoch: [2][21/25]\tTime 1.39687 (0.91103)\tData 1.19391 (0.72814)\tLoss 1.0774 (1.1716)\tPrec@1 75.00000 (68.15476)\tPrec@5 81.25000 (88.39286)\n",
            "Epoch: [2][22/25]\tTime 0.17386 (0.87752)\tData 0.03128 (0.69646)\tLoss 1.5829 (1.1903)\tPrec@1 68.75000 (68.18182)\tPrec@5 81.25000 (88.06818)\n",
            "Epoch: [2][23/25]\tTime 1.47643 (0.90356)\tData 1.29608 (0.72253)\tLoss 1.9988 (1.2254)\tPrec@1 62.50000 (67.93478)\tPrec@5 68.75000 (87.22826)\n",
            "Epoch: [2][24/25]\tTime 0.44241 (0.88435)\tData 0.32630 (0.70602)\tLoss 0.9440 (1.2137)\tPrec@1 68.75000 (67.96875)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [2][25/25]\tTime 0.06013 (0.85138)\tData 0.00111 (0.67783)\tLoss 2.3710 (1.2256)\tPrec@1 50.00000 (67.78350)\tPrec@5 50.00000 (87.11340)\n",
            "train at epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/231]\t lr: 0.00100\tTime 4.031 (4.031)\tData 3.691 (3.691)\tLoss 1.5238 (1.5238)\tPrec@1 62.50000 (62.50000)\tPrec@5 84.37500 (84.37500)\n",
            "Epoch: [3][10/231]\t lr: 0.00100\tTime 2.902 (1.920)\tData 2.583 (1.621)\tLoss 1.1439 (1.2180)\tPrec@1 65.62500 (65.34091)\tPrec@5 93.75000 (91.47727)\n",
            "Epoch: [3][20/231]\t lr: 0.00100\tTime 3.207 (1.819)\tData 2.804 (1.512)\tLoss 0.5723 (1.1326)\tPrec@1 84.37500 (68.75000)\tPrec@5 96.87500 (91.07143)\n",
            "Epoch: [3][30/231]\t lr: 0.00100\tTime 3.034 (1.802)\tData 2.681 (1.499)\tLoss 1.1502 (1.1077)\tPrec@1 68.75000 (69.55645)\tPrec@5 87.50000 (90.92741)\n",
            "Epoch: [3][40/231]\t lr: 0.00100\tTime 2.960 (1.766)\tData 2.613 (1.465)\tLoss 0.9743 (1.1007)\tPrec@1 65.62500 (69.81707)\tPrec@5 100.00000 (91.15853)\n",
            "Epoch: [3][50/231]\t lr: 0.00100\tTime 3.244 (1.742)\tData 2.902 (1.442)\tLoss 1.5868 (1.1463)\tPrec@1 46.87500 (68.50491)\tPrec@5 93.75000 (90.74755)\n",
            "Epoch: [3][60/231]\t lr: 0.00100\tTime 3.175 (1.731)\tData 2.789 (1.432)\tLoss 1.1237 (1.1519)\tPrec@1 68.75000 (68.44262)\tPrec@5 90.62500 (90.47131)\n",
            "Epoch: [3][70/231]\t lr: 0.00100\tTime 3.138 (1.728)\tData 2.755 (1.429)\tLoss 1.5978 (1.1576)\tPrec@1 53.12500 (68.30986)\tPrec@5 87.50000 (90.58099)\n",
            "Epoch: [3][80/231]\t lr: 0.00100\tTime 3.072 (1.725)\tData 2.716 (1.426)\tLoss 1.1097 (1.1522)\tPrec@1 68.75000 (68.13271)\tPrec@5 84.37500 (90.66358)\n",
            "Epoch: [3][90/231]\t lr: 0.00100\tTime 3.147 (1.725)\tData 2.772 (1.426)\tLoss 1.2082 (1.1524)\tPrec@1 62.50000 (68.06319)\tPrec@5 93.75000 (90.79671)\n",
            "Epoch: [3][100/231]\t lr: 0.00100\tTime 2.947 (1.715)\tData 2.629 (1.417)\tLoss 1.0409 (1.1439)\tPrec@1 65.62500 (68.19307)\tPrec@5 96.87500 (90.93440)\n",
            "Epoch: [3][110/231]\t lr: 0.00100\tTime 3.160 (1.710)\tData 2.797 (1.412)\tLoss 1.1331 (1.1470)\tPrec@1 68.75000 (68.07433)\tPrec@5 96.87500 (90.93468)\n",
            "Epoch: [3][120/231]\t lr: 0.00100\tTime 2.821 (1.705)\tData 2.500 (1.406)\tLoss 0.9798 (1.1458)\tPrec@1 78.12500 (68.07851)\tPrec@5 90.62500 (91.06405)\n",
            "Epoch: [3][130/231]\t lr: 0.00100\tTime 3.212 (1.705)\tData 2.909 (1.407)\tLoss 1.8253 (1.1501)\tPrec@1 43.75000 (67.93893)\tPrec@5 81.25000 (90.93511)\n",
            "Epoch: [3][140/231]\t lr: 0.00100\tTime 2.952 (1.699)\tData 2.627 (1.401)\tLoss 0.9826 (1.1475)\tPrec@1 68.75000 (67.88564)\tPrec@5 100.00000 (91.00177)\n",
            "Epoch: [3][150/231]\t lr: 0.00100\tTime 3.188 (1.699)\tData 2.805 (1.401)\tLoss 0.8248 (1.1550)\tPrec@1 84.37500 (67.75662)\tPrec@5 93.75000 (90.97682)\n",
            "Epoch: [3][160/231]\t lr: 0.00100\tTime 2.737 (1.699)\tData 2.343 (1.401)\tLoss 0.8670 (1.1550)\tPrec@1 81.25000 (67.76009)\tPrec@5 93.75000 (90.95497)\n",
            "Epoch: [3][170/231]\t lr: 0.00100\tTime 3.048 (1.699)\tData 2.663 (1.400)\tLoss 1.2080 (1.1565)\tPrec@1 62.50000 (67.65351)\tPrec@5 93.75000 (90.95395)\n",
            "Epoch: [3][180/231]\t lr: 0.00100\tTime 3.250 (1.696)\tData 2.876 (1.398)\tLoss 1.2648 (1.1564)\tPrec@1 71.87500 (67.74862)\tPrec@5 81.25000 (91.02210)\n",
            "Epoch: [3][190/231]\t lr: 0.00100\tTime 2.547 (1.693)\tData 2.231 (1.394)\tLoss 0.6585 (1.1575)\tPrec@1 90.62500 (67.86649)\tPrec@5 96.87500 (90.98495)\n",
            "Epoch: [3][200/231]\t lr: 0.00100\tTime 1.670 (1.689)\tData 1.436 (1.393)\tLoss 1.6460 (1.1617)\tPrec@1 53.12500 (67.64614)\tPrec@5 87.50000 (90.92039)\n",
            "Epoch: [3][210/231]\t lr: 0.00100\tTime 2.172 (1.691)\tData 1.804 (1.395)\tLoss 1.4529 (1.1609)\tPrec@1 62.50000 (67.77251)\tPrec@5 87.50000 (90.96564)\n",
            "Epoch: [3][220/231]\t lr: 0.00100\tTime 0.292 (1.684)\tData 0.000 (1.388)\tLoss 1.6307 (1.1636)\tPrec@1 56.25000 (67.68948)\tPrec@5 84.37500 (90.97851)\n",
            "Epoch: [3][230/231]\t lr: 0.00100\tTime 0.066 (1.680)\tData 0.000 (1.386)\tLoss 3.1628 (1.1643)\tPrec@1 50.00000 (67.73011)\tPrec@5 50.00000 (90.91773)\n",
            "validation at epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][1/25]\tTime 1.96116 (1.96116)\tData 1.76003 (1.76003)\tLoss 1.3623 (1.3623)\tPrec@1 68.75000 (68.75000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [3][2/25]\tTime 0.18827 (1.07471)\tData 0.00209 (0.88106)\tLoss 1.2326 (1.2975)\tPrec@1 62.50000 (65.62500)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [3][3/25]\tTime 1.64218 (1.26387)\tData 1.50523 (1.08912)\tLoss 2.1915 (1.5955)\tPrec@1 50.00000 (60.41667)\tPrec@5 62.50000 (79.16667)\n",
            "Epoch: [3][4/25]\tTime 0.17056 (0.99054)\tData 0.00174 (0.81727)\tLoss 1.2436 (1.5075)\tPrec@1 68.75000 (62.50000)\tPrec@5 93.75000 (82.81250)\n",
            "Epoch: [3][5/25]\tTime 1.81176 (1.15478)\tData 1.64798 (0.98341)\tLoss 1.7431 (1.5546)\tPrec@1 56.25000 (61.25000)\tPrec@5 75.00000 (81.25000)\n",
            "Epoch: [3][6/25]\tTime 0.17782 (0.99196)\tData 0.00128 (0.81973)\tLoss 0.8841 (1.4429)\tPrec@1 87.50000 (65.62500)\tPrec@5 93.75000 (83.33334)\n",
            "Epoch: [3][7/25]\tTime 1.49972 (1.06450)\tData 1.34243 (0.89440)\tLoss 0.5554 (1.3161)\tPrec@1 93.75000 (69.64286)\tPrec@5 100.00000 (85.71429)\n",
            "Epoch: [3][8/25]\tTime 0.20846 (0.95749)\tData 0.00115 (0.78274)\tLoss 0.9913 (1.2755)\tPrec@1 81.25000 (71.09375)\tPrec@5 93.75000 (86.71875)\n",
            "Epoch: [3][9/25]\tTime 1.66006 (1.03555)\tData 1.50369 (0.86285)\tLoss 1.3446 (1.2832)\tPrec@1 62.50000 (70.13889)\tPrec@5 81.25000 (86.11111)\n",
            "Epoch: [3][10/25]\tTime 0.13696 (0.94569)\tData 0.00156 (0.77672)\tLoss 1.5404 (1.3089)\tPrec@1 68.75000 (70.00000)\tPrec@5 81.25000 (85.62500)\n",
            "Epoch: [3][11/25]\tTime 1.60803 (1.00591)\tData 1.41350 (0.83461)\tLoss 0.4873 (1.2342)\tPrec@1 87.50000 (71.59091)\tPrec@5 100.00000 (86.93182)\n",
            "Epoch: [3][12/25]\tTime 0.17538 (0.93670)\tData 0.00788 (0.76571)\tLoss 1.2463 (1.2352)\tPrec@1 62.50000 (70.83334)\tPrec@5 87.50000 (86.97917)\n",
            "Epoch: [3][13/25]\tTime 1.44356 (0.97569)\tData 1.28553 (0.80570)\tLoss 1.0895 (1.2240)\tPrec@1 62.50000 (70.19231)\tPrec@5 87.50000 (87.01923)\n",
            "Epoch: [3][14/25]\tTime 0.17244 (0.91831)\tData 0.00160 (0.74826)\tLoss 0.7828 (1.1925)\tPrec@1 81.25000 (70.98215)\tPrec@5 100.00000 (87.94643)\n",
            "Epoch: [3][15/25]\tTime 1.42160 (0.95186)\tData 1.23069 (0.78043)\tLoss 1.6663 (1.2241)\tPrec@1 62.50000 (70.41667)\tPrec@5 75.00000 (87.08334)\n",
            "Epoch: [3][16/25]\tTime 0.19305 (0.90444)\tData 0.00324 (0.73185)\tLoss 0.6052 (1.1854)\tPrec@1 81.25000 (71.09375)\tPrec@5 100.00000 (87.89062)\n",
            "Epoch: [3][17/25]\tTime 1.50930 (0.94002)\tData 1.33865 (0.76755)\tLoss 1.6573 (1.2132)\tPrec@1 62.50000 (70.58823)\tPrec@5 75.00000 (87.13235)\n",
            "Epoch: [3][18/25]\tTime 0.15859 (0.89661)\tData 0.00128 (0.72497)\tLoss 1.1953 (1.2122)\tPrec@1 68.75000 (70.48611)\tPrec@5 81.25000 (86.80556)\n",
            "Epoch: [3][19/25]\tTime 1.47437 (0.92701)\tData 1.29774 (0.75512)\tLoss 1.2878 (1.2161)\tPrec@1 68.75000 (70.39474)\tPrec@5 81.25000 (86.51316)\n",
            "Epoch: [3][20/25]\tTime 0.22510 (0.89192)\tData 0.05000 (0.71986)\tLoss 0.8717 (1.1989)\tPrec@1 75.00000 (70.62500)\tPrec@5 100.00000 (87.18750)\n",
            "Epoch: [3][21/25]\tTime 1.39984 (0.91611)\tData 1.21496 (0.74344)\tLoss 0.9028 (1.1848)\tPrec@1 68.75000 (70.53571)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [3][22/25]\tTime 0.49894 (0.89714)\tData 0.31606 (0.72401)\tLoss 1.0056 (1.1767)\tPrec@1 68.75000 (70.45454)\tPrec@5 93.75000 (87.78410)\n",
            "Epoch: [3][23/25]\tTime 1.32226 (0.91563)\tData 1.14772 (0.74244)\tLoss 1.5039 (1.1909)\tPrec@1 56.25000 (69.83696)\tPrec@5 75.00000 (87.22826)\n",
            "Epoch: [3][24/25]\tTime 0.41231 (0.89466)\tData 0.29784 (0.72391)\tLoss 0.9799 (1.1821)\tPrec@1 75.00000 (70.05209)\tPrec@5 100.00000 (87.76042)\n",
            "Epoch: [3][25/25]\tTime 0.05884 (0.86122)\tData 0.00086 (0.69499)\tLoss 2.1701 (1.1923)\tPrec@1 50.00000 (69.84536)\tPrec@5 75.00000 (87.62886)\n",
            "train at epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [4][0/231]\t lr: 0.00100\tTime 4.119 (4.119)\tData 3.803 (3.803)\tLoss 1.3667 (1.3667)\tPrec@1 56.25000 (56.25000)\tPrec@5 84.37500 (84.37500)\n",
            "Epoch: [4][10/231]\t lr: 0.00100\tTime 2.996 (1.892)\tData 2.592 (1.571)\tLoss 1.5762 (1.1863)\tPrec@1 53.12500 (64.20454)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [4][20/231]\t lr: 0.00100\tTime 3.140 (1.788)\tData 2.734 (1.466)\tLoss 0.9996 (1.2391)\tPrec@1 81.25000 (65.47619)\tPrec@5 93.75000 (89.73215)\n",
            "Epoch: [4][30/231]\t lr: 0.00100\tTime 2.979 (1.725)\tData 2.609 (1.407)\tLoss 1.7477 (1.1990)\tPrec@1 56.25000 (67.33871)\tPrec@5 84.37500 (90.52419)\n",
            "Epoch: [4][40/231]\t lr: 0.00100\tTime 3.086 (1.720)\tData 2.781 (1.406)\tLoss 0.8465 (1.1834)\tPrec@1 75.00000 (67.83537)\tPrec@5 93.75000 (90.54877)\n",
            "Epoch: [4][50/231]\t lr: 0.00100\tTime 3.248 (1.712)\tData 2.941 (1.402)\tLoss 1.1133 (1.1637)\tPrec@1 62.50000 (68.38235)\tPrec@5 96.87500 (91.29903)\n",
            "Epoch: [4][60/231]\t lr: 0.00100\tTime 2.884 (1.696)\tData 2.527 (1.385)\tLoss 1.2688 (1.1719)\tPrec@1 71.87500 (68.18647)\tPrec@5 87.50000 (90.98360)\n",
            "Epoch: [4][70/231]\t lr: 0.00100\tTime 3.075 (1.691)\tData 2.759 (1.381)\tLoss 0.8507 (1.1684)\tPrec@1 75.00000 (68.17782)\tPrec@5 93.75000 (90.80106)\n",
            "Epoch: [4][80/231]\t lr: 0.00100\tTime 3.167 (1.695)\tData 2.827 (1.386)\tLoss 1.0571 (1.1763)\tPrec@1 65.62500 (68.28704)\tPrec@5 90.62500 (90.47068)\n",
            "Epoch: [4][90/231]\t lr: 0.00100\tTime 3.073 (1.696)\tData 2.728 (1.388)\tLoss 1.1167 (1.1795)\tPrec@1 71.87500 (68.30357)\tPrec@5 90.62500 (90.41896)\n",
            "Epoch: [4][100/231]\t lr: 0.00100\tTime 3.011 (1.686)\tData 2.718 (1.381)\tLoss 1.8722 (1.1763)\tPrec@1 50.00000 (68.28589)\tPrec@5 81.25000 (90.47030)\n",
            "Epoch: [4][110/231]\t lr: 0.00100\tTime 2.929 (1.686)\tData 2.589 (1.381)\tLoss 0.9351 (1.1734)\tPrec@1 75.00000 (68.32771)\tPrec@5 96.87500 (90.54054)\n",
            "Epoch: [4][120/231]\t lr: 0.00100\tTime 2.835 (1.688)\tData 2.481 (1.383)\tLoss 0.8616 (1.1704)\tPrec@1 78.12500 (68.15599)\tPrec@5 93.75000 (90.72830)\n",
            "Epoch: [4][130/231]\t lr: 0.00100\tTime 3.149 (1.692)\tData 2.802 (1.388)\tLoss 1.2959 (1.1702)\tPrec@1 65.62500 (68.27290)\tPrec@5 78.12500 (90.48187)\n",
            "Epoch: [4][140/231]\t lr: 0.00100\tTime 3.182 (1.697)\tData 2.848 (1.392)\tLoss 0.9287 (1.1685)\tPrec@1 71.87500 (68.24025)\tPrec@5 96.87500 (90.58067)\n",
            "Epoch: [4][150/231]\t lr: 0.00100\tTime 2.740 (1.695)\tData 2.441 (1.390)\tLoss 0.7398 (1.1700)\tPrec@1 71.87500 (68.27401)\tPrec@5 96.87500 (90.45943)\n",
            "Epoch: [4][160/231]\t lr: 0.00100\tTime 2.938 (1.695)\tData 2.578 (1.390)\tLoss 1.1260 (1.1672)\tPrec@1 78.12500 (68.34239)\tPrec@5 93.75000 (90.54736)\n",
            "Epoch: [4][170/231]\t lr: 0.00100\tTime 2.774 (1.692)\tData 2.407 (1.387)\tLoss 1.3294 (1.1693)\tPrec@1 68.75000 (68.27486)\tPrec@5 93.75000 (90.53362)\n",
            "Epoch: [4][180/231]\t lr: 0.00100\tTime 2.886 (1.688)\tData 2.549 (1.383)\tLoss 1.0941 (1.1657)\tPrec@1 71.87500 (68.37017)\tPrec@5 87.50000 (90.53868)\n",
            "Epoch: [4][190/231]\t lr: 0.00100\tTime 2.330 (1.687)\tData 1.989 (1.382)\tLoss 1.2350 (1.1661)\tPrec@1 62.50000 (68.19372)\tPrec@5 90.62500 (90.41231)\n",
            "Epoch: [4][200/231]\t lr: 0.00100\tTime 2.822 (1.687)\tData 2.455 (1.383)\tLoss 1.2545 (1.1697)\tPrec@1 65.62500 (68.00373)\tPrec@5 84.37500 (90.36069)\n",
            "Epoch: [4][210/231]\t lr: 0.00100\tTime 2.692 (1.685)\tData 2.405 (1.381)\tLoss 1.0740 (1.1668)\tPrec@1 71.87500 (68.17239)\tPrec@5 90.62500 (90.40285)\n",
            "Epoch: [4][220/231]\t lr: 0.00100\tTime 2.408 (1.685)\tData 2.079 (1.381)\tLoss 1.5963 (1.1763)\tPrec@1 59.37500 (67.85917)\tPrec@5 75.00000 (90.27150)\n",
            "Epoch: [4][230/231]\t lr: 0.00100\tTime 0.097 (1.673)\tData 0.000 (1.372)\tLoss 2.2565 (1.1732)\tPrec@1 33.33333 (67.92017)\tPrec@5 66.66666 (90.37469)\n",
            "validation at epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [4][1/25]\tTime 1.99526 (1.99526)\tData 1.76924 (1.76924)\tLoss 1.0388 (1.0388)\tPrec@1 68.75000 (68.75000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [4][2/25]\tTime 0.18469 (1.08997)\tData 0.03619 (0.90271)\tLoss 1.0881 (1.0635)\tPrec@1 68.75000 (68.75000)\tPrec@5 81.25000 (84.37500)\n",
            "Epoch: [4][3/25]\tTime 1.50097 (1.22697)\tData 1.29704 (1.03416)\tLoss 1.1963 (1.1077)\tPrec@1 75.00000 (70.83334)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [4][4/25]\tTime 0.39051 (1.01786)\tData 0.21246 (0.82873)\tLoss 1.0197 (1.0857)\tPrec@1 75.00000 (71.87500)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [4][5/25]\tTime 1.44023 (1.10233)\tData 1.23195 (0.90938)\tLoss 1.1119 (1.0910)\tPrec@1 81.25000 (73.75000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [4][6/25]\tTime 0.23977 (0.95857)\tData 0.05384 (0.76679)\tLoss 1.3946 (1.1416)\tPrec@1 68.75000 (72.91667)\tPrec@5 81.25000 (86.45834)\n",
            "Epoch: [4][7/25]\tTime 1.35300 (1.01492)\tData 1.18336 (0.82630)\tLoss 0.5166 (1.0523)\tPrec@1 93.75000 (75.89286)\tPrec@5 93.75000 (87.50001)\n",
            "Epoch: [4][8/25]\tTime 0.24734 (0.91897)\tData 0.08313 (0.73340)\tLoss 1.2406 (1.0758)\tPrec@1 68.75000 (75.00000)\tPrec@5 81.25000 (86.71875)\n",
            "Epoch: [4][9/25]\tTime 1.51050 (0.98470)\tData 1.32176 (0.79877)\tLoss 1.1150 (1.0802)\tPrec@1 81.25000 (75.69444)\tPrec@5 87.50000 (86.80556)\n",
            "Epoch: [4][10/25]\tTime 0.25081 (0.91131)\tData 0.11217 (0.73011)\tLoss 1.2400 (1.0961)\tPrec@1 68.75000 (75.00000)\tPrec@5 87.50000 (86.87500)\n",
            "Epoch: [4][11/25]\tTime 1.41254 (0.95687)\tData 1.27608 (0.77975)\tLoss 0.7846 (1.0678)\tPrec@1 81.25000 (75.56818)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [4][12/25]\tTime 0.42368 (0.91244)\tData 0.27719 (0.73787)\tLoss 1.4143 (1.0967)\tPrec@1 62.50000 (74.47917)\tPrec@5 93.75000 (88.02084)\n",
            "Epoch: [4][13/25]\tTime 1.45624 (0.95427)\tData 1.28824 (0.78020)\tLoss 1.7045 (1.1435)\tPrec@1 56.25000 (73.07693)\tPrec@5 68.75000 (86.53847)\n",
            "Epoch: [4][14/25]\tTime 0.14500 (0.89647)\tData 0.00353 (0.72473)\tLoss 1.1886 (1.1467)\tPrec@1 68.75000 (72.76786)\tPrec@5 87.50000 (86.60715)\n",
            "Epoch: [4][15/25]\tTime 1.46485 (0.93436)\tData 1.27872 (0.76166)\tLoss 1.0695 (1.1415)\tPrec@1 68.75000 (72.50000)\tPrec@5 87.50000 (86.66667)\n",
            "Epoch: [4][16/25]\tTime 0.17219 (0.88672)\tData 0.00118 (0.71413)\tLoss 1.6273 (1.1719)\tPrec@1 50.00000 (71.09375)\tPrec@5 87.50000 (86.71875)\n",
            "Epoch: [4][17/25]\tTime 1.57398 (0.92715)\tData 1.37756 (0.75316)\tLoss 1.4946 (1.1909)\tPrec@1 62.50000 (70.58823)\tPrec@5 81.25000 (86.39706)\n",
            "Epoch: [4][18/25]\tTime 0.19190 (0.88630)\tData 0.00846 (0.71178)\tLoss 1.2934 (1.1966)\tPrec@1 50.00000 (69.44444)\tPrec@5 87.50000 (86.45834)\n",
            "Epoch: [4][19/25]\tTime 1.60347 (0.92405)\tData 1.40012 (0.74801)\tLoss 1.0824 (1.1906)\tPrec@1 75.00000 (69.73684)\tPrec@5 93.75000 (86.84211)\n",
            "Epoch: [4][20/25]\tTime 0.26988 (0.89134)\tData 0.08432 (0.71483)\tLoss 1.4982 (1.2059)\tPrec@1 62.50000 (69.37500)\tPrec@5 87.50000 (86.87500)\n",
            "Epoch: [4][21/25]\tTime 1.26556 (0.90916)\tData 1.06617 (0.73156)\tLoss 0.9365 (1.1931)\tPrec@1 62.50000 (69.04762)\tPrec@5 100.00000 (87.50000)\n",
            "Epoch: [4][22/25]\tTime 0.38582 (0.88537)\tData 0.20626 (0.70768)\tLoss 1.2711 (1.1967)\tPrec@1 62.50000 (68.75000)\tPrec@5 81.25000 (87.21591)\n",
            "Epoch: [4][23/25]\tTime 1.22682 (0.90022)\tData 1.03781 (0.72203)\tLoss 1.1572 (1.1949)\tPrec@1 81.25000 (69.29348)\tPrec@5 87.50000 (87.22826)\n",
            "Epoch: [4][24/25]\tTime 0.39544 (0.87919)\tData 0.27600 (0.70345)\tLoss 0.9021 (1.1827)\tPrec@1 81.25000 (69.79167)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [4][25/25]\tTime 0.05907 (0.84638)\tData 0.00037 (0.67533)\tLoss 2.1096 (1.1923)\tPrec@1 50.00000 (69.58762)\tPrec@5 50.00000 (87.11340)\n",
            "train at epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [5][0/231]\t lr: 0.00100\tTime 3.956 (3.956)\tData 3.565 (3.565)\tLoss 1.0415 (1.0415)\tPrec@1 65.62500 (65.62500)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [5][10/231]\t lr: 0.00100\tTime 3.034 (1.901)\tData 2.660 (1.584)\tLoss 1.1671 (1.1722)\tPrec@1 68.75000 (68.75000)\tPrec@5 90.62500 (90.34091)\n",
            "Epoch: [5][20/231]\t lr: 0.00100\tTime 3.380 (1.826)\tData 3.058 (1.520)\tLoss 1.0030 (1.1930)\tPrec@1 71.87500 (67.70834)\tPrec@5 90.62500 (90.17857)\n",
            "Epoch: [5][30/231]\t lr: 0.00100\tTime 3.135 (1.803)\tData 2.794 (1.496)\tLoss 0.9847 (1.1609)\tPrec@1 81.25000 (68.14516)\tPrec@5 90.62500 (90.52419)\n",
            "Epoch: [5][40/231]\t lr: 0.00100\tTime 3.428 (1.780)\tData 3.124 (1.479)\tLoss 0.8352 (1.1712)\tPrec@1 81.25000 (68.14024)\tPrec@5 96.87500 (90.47256)\n",
            "Epoch: [5][50/231]\t lr: 0.00100\tTime 2.989 (1.764)\tData 2.653 (1.463)\tLoss 1.6525 (1.1976)\tPrec@1 56.25000 (67.03432)\tPrec@5 78.12500 (89.95098)\n",
            "Epoch: [5][60/231]\t lr: 0.00100\tTime 3.074 (1.754)\tData 2.760 (1.455)\tLoss 1.0681 (1.1650)\tPrec@1 68.75000 (67.82787)\tPrec@5 87.50000 (90.36885)\n",
            "Epoch: [5][70/231]\t lr: 0.00100\tTime 3.306 (1.741)\tData 2.944 (1.440)\tLoss 1.4599 (1.1679)\tPrec@1 62.50000 (67.69366)\tPrec@5 84.37500 (90.31690)\n",
            "Epoch: [5][80/231]\t lr: 0.00100\tTime 3.082 (1.740)\tData 2.735 (1.438)\tLoss 0.8390 (1.1497)\tPrec@1 78.12500 (68.28704)\tPrec@5 93.75000 (90.58642)\n",
            "Epoch: [5][90/231]\t lr: 0.00100\tTime 3.065 (1.743)\tData 2.718 (1.442)\tLoss 1.2323 (1.1511)\tPrec@1 65.62500 (68.20055)\tPrec@5 93.75000 (90.83105)\n",
            "Epoch: [5][100/231]\t lr: 0.00100\tTime 3.252 (1.737)\tData 2.906 (1.435)\tLoss 1.2347 (1.1511)\tPrec@1 62.50000 (68.06931)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [5][110/231]\t lr: 0.00100\tTime 3.211 (1.734)\tData 2.834 (1.431)\tLoss 1.4104 (1.1495)\tPrec@1 59.37500 (68.32771)\tPrec@5 93.75000 (90.56870)\n",
            "Epoch: [5][120/231]\t lr: 0.00100\tTime 3.178 (1.723)\tData 2.811 (1.420)\tLoss 1.2586 (1.1559)\tPrec@1 62.50000 (68.18182)\tPrec@5 90.62500 (90.41839)\n",
            "Epoch: [5][130/231]\t lr: 0.00100\tTime 3.077 (1.724)\tData 2.707 (1.421)\tLoss 1.0271 (1.1541)\tPrec@1 75.00000 (68.15363)\tPrec@5 87.50000 (90.52958)\n",
            "Epoch: [5][140/231]\t lr: 0.00100\tTime 2.943 (1.716)\tData 2.629 (1.413)\tLoss 1.5812 (1.1579)\tPrec@1 56.25000 (67.90780)\tPrec@5 78.12500 (90.49202)\n",
            "Epoch: [5][150/231]\t lr: 0.00100\tTime 3.081 (1.715)\tData 2.726 (1.412)\tLoss 0.9704 (1.1605)\tPrec@1 68.75000 (67.67384)\tPrec@5 100.00000 (90.48013)\n",
            "Epoch: [5][160/231]\t lr: 0.00100\tTime 3.082 (1.712)\tData 2.787 (1.408)\tLoss 0.8296 (1.1589)\tPrec@1 78.12500 (67.81832)\tPrec@5 93.75000 (90.41149)\n",
            "Epoch: [5][170/231]\t lr: 0.00100\tTime 2.780 (1.708)\tData 2.469 (1.404)\tLoss 1.1304 (1.1595)\tPrec@1 65.62500 (67.89108)\tPrec@5 93.75000 (90.38743)\n",
            "Epoch: [5][180/231]\t lr: 0.00100\tTime 2.702 (1.706)\tData 2.420 (1.403)\tLoss 0.9954 (1.1620)\tPrec@1 75.00000 (67.88674)\tPrec@5 100.00000 (90.45235)\n",
            "Epoch: [5][190/231]\t lr: 0.00100\tTime 2.929 (1.704)\tData 2.648 (1.402)\tLoss 0.8670 (1.1593)\tPrec@1 71.87500 (67.89922)\tPrec@5 90.62500 (90.47775)\n",
            "Epoch: [5][200/231]\t lr: 0.00100\tTime 2.993 (1.700)\tData 2.672 (1.397)\tLoss 1.2301 (1.1641)\tPrec@1 75.00000 (67.83271)\tPrec@5 84.37500 (90.40733)\n",
            "Epoch: [5][210/231]\t lr: 0.00100\tTime 3.510 (1.697)\tData 3.122 (1.395)\tLoss 1.2693 (1.1646)\tPrec@1 65.62500 (67.78732)\tPrec@5 90.62500 (90.40285)\n",
            "Epoch: [5][220/231]\t lr: 0.00100\tTime 3.036 (1.695)\tData 2.666 (1.392)\tLoss 1.2800 (1.1652)\tPrec@1 59.37500 (67.83089)\tPrec@5 90.62500 (90.38462)\n",
            "Epoch: [5][230/231]\t lr: 0.00100\tTime 0.092 (1.679)\tData 0.027 (1.378)\tLoss 1.2460 (1.1652)\tPrec@1 50.00000 (67.78442)\tPrec@5 100.00000 (90.41542)\n",
            "validation at epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [5][1/25]\tTime 2.03244 (2.03244)\tData 1.83816 (1.83816)\tLoss 1.0908 (1.0908)\tPrec@1 62.50000 (62.50000)\tPrec@5 81.25000 (81.25000)\n",
            "Epoch: [5][2/25]\tTime 0.21552 (1.12398)\tData 0.00828 (0.92322)\tLoss 1.7083 (1.3996)\tPrec@1 56.25000 (59.37500)\tPrec@5 81.25000 (81.25000)\n",
            "Epoch: [5][3/25]\tTime 1.84317 (1.36371)\tData 1.66529 (1.17058)\tLoss 0.6839 (1.1610)\tPrec@1 87.50000 (68.75000)\tPrec@5 93.75000 (85.41667)\n",
            "Epoch: [5][4/25]\tTime 0.18952 (1.07016)\tData 0.00178 (0.87838)\tLoss 1.3523 (1.2088)\tPrec@1 68.75000 (68.75000)\tPrec@5 81.25000 (84.37500)\n",
            "Epoch: [5][5/25]\tTime 1.34827 (1.12578)\tData 1.16968 (0.93664)\tLoss 1.3099 (1.2290)\tPrec@1 62.50000 (67.50000)\tPrec@5 87.50000 (85.00000)\n",
            "Epoch: [5][6/25]\tTime 0.16969 (0.96644)\tData 0.00849 (0.78195)\tLoss 1.4776 (1.2705)\tPrec@1 56.25000 (65.62500)\tPrec@5 87.50000 (85.41667)\n",
            "Epoch: [5][7/25]\tTime 1.38718 (1.02654)\tData 1.20598 (0.84252)\tLoss 0.9071 (1.2186)\tPrec@1 68.75000 (66.07143)\tPrec@5 87.50000 (85.71429)\n",
            "Epoch: [5][8/25]\tTime 0.13538 (0.91515)\tData 0.00152 (0.73740)\tLoss 0.8410 (1.1714)\tPrec@1 81.25000 (67.96875)\tPrec@5 93.75000 (86.71875)\n",
            "Epoch: [5][9/25]\tTime 1.83169 (1.01699)\tData 1.64098 (0.83780)\tLoss 1.8526 (1.2471)\tPrec@1 56.25000 (66.66666)\tPrec@5 75.00000 (85.41666)\n",
            "Epoch: [5][10/25]\tTime 0.18861 (0.93415)\tData 0.00483 (0.75450)\tLoss 1.1634 (1.2387)\tPrec@1 62.50000 (66.25000)\tPrec@5 87.50000 (85.62500)\n",
            "Epoch: [5][11/25]\tTime 1.56602 (0.99159)\tData 1.38582 (0.81189)\tLoss 1.2553 (1.2402)\tPrec@1 62.50000 (65.90910)\tPrec@5 81.25000 (85.22727)\n",
            "Epoch: [5][12/25]\tTime 0.15176 (0.92160)\tData 0.01112 (0.74516)\tLoss 0.7241 (1.1972)\tPrec@1 87.50000 (67.70834)\tPrec@5 93.75000 (85.93750)\n",
            "Epoch: [5][13/25]\tTime 1.73538 (0.98420)\tData 1.56695 (0.80838)\tLoss 1.4173 (1.2141)\tPrec@1 56.25000 (66.82693)\tPrec@5 93.75000 (86.53847)\n",
            "Epoch: [5][14/25]\tTime 0.12908 (0.92312)\tData 0.00151 (0.75074)\tLoss 1.4453 (1.2306)\tPrec@1 68.75000 (66.96429)\tPrec@5 81.25000 (86.16072)\n",
            "Epoch: [5][15/25]\tTime 1.61057 (0.96895)\tData 1.48654 (0.79980)\tLoss 1.1504 (1.2253)\tPrec@1 62.50000 (66.66667)\tPrec@5 87.50000 (86.25001)\n",
            "Epoch: [5][16/25]\tTime 0.12268 (0.91606)\tData 0.00153 (0.74990)\tLoss 0.5550 (1.1834)\tPrec@1 81.25000 (67.57812)\tPrec@5 100.00000 (87.10938)\n",
            "Epoch: [5][17/25]\tTime 1.53584 (0.95252)\tData 1.43891 (0.79043)\tLoss 1.4674 (1.2001)\tPrec@1 62.50000 (67.27941)\tPrec@5 81.25000 (86.76471)\n",
            "Epoch: [5][18/25]\tTime 0.19061 (0.91019)\tData 0.00788 (0.74696)\tLoss 2.2426 (1.2580)\tPrec@1 50.00000 (66.31944)\tPrec@5 68.75000 (85.76389)\n",
            "Epoch: [5][19/25]\tTime 1.45938 (0.93909)\tData 1.32292 (0.77727)\tLoss 0.7265 (1.2300)\tPrec@1 75.00000 (66.77631)\tPrec@5 100.00000 (86.51316)\n",
            "Epoch: [5][20/25]\tTime 0.16436 (0.90036)\tData 0.00148 (0.73848)\tLoss 0.5759 (1.1973)\tPrec@1 87.50000 (67.81250)\tPrec@5 100.00000 (87.18750)\n",
            "Epoch: [5][21/25]\tTime 1.53480 (0.93057)\tData 1.36146 (0.76815)\tLoss 1.7745 (1.2248)\tPrec@1 56.25000 (67.26191)\tPrec@5 75.00000 (86.60715)\n",
            "Epoch: [5][22/25]\tTime 0.16944 (0.89597)\tData 0.00770 (0.73358)\tLoss 0.9999 (1.2146)\tPrec@1 75.00000 (67.61364)\tPrec@5 93.75000 (86.93182)\n",
            "Epoch: [5][23/25]\tTime 1.19920 (0.90916)\tData 1.06597 (0.74803)\tLoss 1.0502 (1.2074)\tPrec@1 75.00000 (67.93478)\tPrec@5 93.75000 (87.22826)\n",
            "Epoch: [5][24/25]\tTime 0.10804 (0.87578)\tData 0.00109 (0.71691)\tLoss 0.9417 (1.1964)\tPrec@1 81.25000 (68.48959)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [5][25/25]\tTime 0.15505 (0.84695)\tData 0.09456 (0.69202)\tLoss 1.1203 (1.1956)\tPrec@1 75.00000 (68.55670)\tPrec@5 75.00000 (87.37113)\n",
            "train at epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [6][0/231]\t lr: 0.00100\tTime 3.708 (3.708)\tData 3.363 (3.363)\tLoss 1.1410 (1.1410)\tPrec@1 62.50000 (62.50000)\tPrec@5 96.87500 (96.87500)\n",
            "Epoch: [6][10/231]\t lr: 0.00100\tTime 3.255 (1.908)\tData 2.934 (1.595)\tLoss 1.1320 (1.1776)\tPrec@1 62.50000 (62.78409)\tPrec@5 93.75000 (90.05682)\n",
            "Epoch: [6][20/231]\t lr: 0.00100\tTime 3.311 (1.830)\tData 2.923 (1.526)\tLoss 1.2479 (1.1521)\tPrec@1 59.37500 (65.02976)\tPrec@5 90.62500 (91.07143)\n",
            "Epoch: [6][30/231]\t lr: 0.00100\tTime 2.909 (1.779)\tData 2.551 (1.472)\tLoss 1.2198 (1.1756)\tPrec@1 62.50000 (65.32258)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [6][40/231]\t lr: 0.00100\tTime 3.186 (1.762)\tData 2.868 (1.457)\tLoss 0.8490 (1.1552)\tPrec@1 78.12500 (65.70122)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [6][50/231]\t lr: 0.00100\tTime 3.029 (1.757)\tData 2.686 (1.457)\tLoss 0.9459 (1.1434)\tPrec@1 84.37500 (66.85049)\tPrec@5 93.75000 (90.93137)\n",
            "Epoch: [6][60/231]\t lr: 0.00100\tTime 3.364 (1.748)\tData 2.975 (1.449)\tLoss 1.3623 (1.1208)\tPrec@1 75.00000 (68.44262)\tPrec@5 84.37500 (91.08606)\n",
            "Epoch: [6][70/231]\t lr: 0.00100\tTime 3.183 (1.739)\tData 2.845 (1.441)\tLoss 1.0341 (1.1242)\tPrec@1 71.87500 (68.44190)\tPrec@5 90.62500 (90.88908)\n",
            "Epoch: [6][80/231]\t lr: 0.00100\tTime 2.677 (1.727)\tData 2.393 (1.429)\tLoss 1.1216 (1.1288)\tPrec@1 68.75000 (68.44136)\tPrec@5 84.37500 (90.74074)\n",
            "Epoch: [6][90/231]\t lr: 0.00100\tTime 3.107 (1.719)\tData 2.761 (1.421)\tLoss 1.1523 (1.1391)\tPrec@1 68.75000 (68.09753)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [6][100/231]\t lr: 0.00100\tTime 3.373 (1.713)\tData 3.028 (1.416)\tLoss 0.9616 (1.1246)\tPrec@1 75.00000 (68.50247)\tPrec@5 100.00000 (90.99628)\n",
            "Epoch: [6][110/231]\t lr: 0.00100\tTime 3.021 (1.711)\tData 2.694 (1.413)\tLoss 1.1323 (1.1215)\tPrec@1 78.12500 (68.77815)\tPrec@5 90.62500 (90.93468)\n",
            "Epoch: [6][120/231]\t lr: 0.00100\tTime 3.010 (1.706)\tData 2.613 (1.407)\tLoss 1.1830 (1.1302)\tPrec@1 62.50000 (68.56921)\tPrec@5 90.62500 (90.85744)\n",
            "Epoch: [6][130/231]\t lr: 0.00100\tTime 3.030 (1.697)\tData 2.663 (1.398)\tLoss 1.3075 (1.1387)\tPrec@1 59.37500 (68.41603)\tPrec@5 87.50000 (90.67271)\n",
            "Epoch: [6][140/231]\t lr: 0.00100\tTime 3.172 (1.698)\tData 2.825 (1.397)\tLoss 1.2708 (1.1497)\tPrec@1 68.75000 (68.24025)\tPrec@5 84.37500 (90.40337)\n",
            "Epoch: [6][150/231]\t lr: 0.00100\tTime 3.000 (1.699)\tData 2.663 (1.398)\tLoss 0.9191 (1.1563)\tPrec@1 78.12500 (68.02567)\tPrec@5 90.62500 (90.31457)\n",
            "Epoch: [6][160/231]\t lr: 0.00100\tTime 3.147 (1.696)\tData 2.773 (1.395)\tLoss 1.3727 (1.1617)\tPrec@1 71.87500 (67.97360)\tPrec@5 84.37500 (90.25621)\n",
            "Epoch: [6][170/231]\t lr: 0.00100\tTime 3.113 (1.698)\tData 2.749 (1.397)\tLoss 1.0072 (1.1612)\tPrec@1 71.87500 (68.05556)\tPrec@5 93.75000 (90.33260)\n",
            "Epoch: [6][180/231]\t lr: 0.00100\tTime 3.329 (1.699)\tData 2.958 (1.397)\tLoss 0.9464 (1.1556)\tPrec@1 71.87500 (68.24931)\tPrec@5 96.87500 (90.45235)\n",
            "Epoch: [6][190/231]\t lr: 0.00100\tTime 3.224 (1.699)\tData 2.922 (1.397)\tLoss 1.2085 (1.1580)\tPrec@1 68.75000 (68.16100)\tPrec@5 90.62500 (90.42867)\n",
            "Epoch: [6][200/231]\t lr: 0.00100\tTime 3.481 (1.702)\tData 3.142 (1.400)\tLoss 1.3657 (1.1605)\tPrec@1 56.25000 (68.03482)\tPrec@5 87.50000 (90.45398)\n",
            "Epoch: [6][210/231]\t lr: 0.00100\tTime 2.583 (1.700)\tData 2.258 (1.399)\tLoss 1.4102 (1.1622)\tPrec@1 65.62500 (68.02429)\tPrec@5 81.25000 (90.29917)\n",
            "Epoch: [6][220/231]\t lr: 0.00100\tTime 3.169 (1.700)\tData 2.777 (1.400)\tLoss 1.3168 (1.1597)\tPrec@1 68.75000 (68.04299)\tPrec@5 84.37500 (90.35634)\n",
            "Epoch: [6][230/231]\t lr: 0.00100\tTime 0.131 (1.682)\tData 0.062 (1.383)\tLoss 1.2167 (1.1589)\tPrec@1 66.66666 (68.09666)\tPrec@5 100.00000 (90.36111)\n",
            "validation at epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [6][1/25]\tTime 2.27981 (2.27981)\tData 2.04585 (2.04585)\tLoss 1.2531 (1.2531)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [6][2/25]\tTime 0.17053 (1.22517)\tData 0.00139 (1.02362)\tLoss 1.2020 (1.2276)\tPrec@1 68.75000 (68.75000)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [6][3/25]\tTime 1.61179 (1.35405)\tData 1.42170 (1.15631)\tLoss 0.5226 (0.9926)\tPrec@1 87.50000 (75.00000)\tPrec@5 100.00000 (93.75000)\n",
            "Epoch: [6][4/25]\tTime 0.13178 (1.04848)\tData 0.00534 (0.86857)\tLoss 1.1608 (1.0346)\tPrec@1 68.75000 (73.43750)\tPrec@5 87.50000 (92.18750)\n",
            "Epoch: [6][5/25]\tTime 1.55936 (1.15066)\tData 1.41229 (0.97731)\tLoss 1.5589 (1.1395)\tPrec@1 50.00000 (68.75000)\tPrec@5 93.75000 (92.50000)\n",
            "Epoch: [6][6/25]\tTime 0.20428 (0.99293)\tData 0.00599 (0.81543)\tLoss 1.4823 (1.1966)\tPrec@1 56.25000 (66.66667)\tPrec@5 81.25000 (90.62500)\n",
            "Epoch: [6][7/25]\tTime 1.65025 (1.08683)\tData 1.45522 (0.90683)\tLoss 1.2244 (1.2006)\tPrec@1 75.00000 (67.85715)\tPrec@5 87.50000 (90.17857)\n",
            "Epoch: [6][8/25]\tTime 0.14319 (0.96888)\tData 0.00654 (0.79429)\tLoss 0.9578 (1.1702)\tPrec@1 81.25000 (69.53125)\tPrec@5 87.50000 (89.84375)\n",
            "Epoch: [6][9/25]\tTime 1.42207 (1.01923)\tData 1.24220 (0.84406)\tLoss 0.8942 (1.1395)\tPrec@1 75.00000 (70.13889)\tPrec@5 100.00000 (90.97222)\n",
            "Epoch: [6][10/25]\tTime 0.16098 (0.93341)\tData 0.00174 (0.75983)\tLoss 1.1984 (1.1454)\tPrec@1 75.00000 (70.62500)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [6][11/25]\tTime 1.45411 (0.98074)\tData 1.25263 (0.80463)\tLoss 1.2606 (1.1559)\tPrec@1 56.25000 (69.31818)\tPrec@5 75.00000 (89.20455)\n",
            "Epoch: [6][12/25]\tTime 0.14151 (0.91081)\tData 0.00118 (0.73767)\tLoss 0.7986 (1.1261)\tPrec@1 75.00000 (69.79167)\tPrec@5 93.75000 (89.58334)\n",
            "Epoch: [6][13/25]\tTime 1.67043 (0.96924)\tData 1.47291 (0.79423)\tLoss 0.8474 (1.1047)\tPrec@1 87.50000 (71.15385)\tPrec@5 93.75000 (89.90385)\n",
            "Epoch: [6][14/25]\tTime 0.12800 (0.90915)\tData 0.00111 (0.73758)\tLoss 2.1376 (1.1785)\tPrec@1 56.25000 (70.08929)\tPrec@5 68.75000 (88.39286)\n",
            "Epoch: [6][15/25]\tTime 1.39292 (0.94140)\tData 1.22406 (0.77001)\tLoss 0.5730 (1.1381)\tPrec@1 87.50000 (71.25000)\tPrec@5 100.00000 (89.16667)\n",
            "Epoch: [6][16/25]\tTime 0.19189 (0.89456)\tData 0.00589 (0.72225)\tLoss 1.5809 (1.1658)\tPrec@1 56.25000 (70.31250)\tPrec@5 81.25000 (88.67188)\n",
            "Epoch: [6][17/25]\tTime 1.55805 (0.93359)\tData 1.39071 (0.76157)\tLoss 2.0224 (1.2162)\tPrec@1 56.25000 (69.48530)\tPrec@5 62.50000 (87.13235)\n",
            "Epoch: [6][18/25]\tTime 0.16061 (0.89064)\tData 0.00149 (0.71935)\tLoss 0.7532 (1.1905)\tPrec@1 75.00000 (69.79166)\tPrec@5 100.00000 (87.84722)\n",
            "Epoch: [6][19/25]\tTime 1.75110 (0.93593)\tData 1.56397 (0.76380)\tLoss 1.4478 (1.2040)\tPrec@1 62.50000 (69.40790)\tPrec@5 68.75000 (86.84211)\n",
            "Epoch: [6][20/25]\tTime 0.18556 (0.89841)\tData 0.00499 (0.72586)\tLoss 1.6047 (1.2240)\tPrec@1 62.50000 (69.06250)\tPrec@5 75.00000 (86.25000)\n",
            "Epoch: [6][21/25]\tTime 1.59043 (0.93136)\tData 1.40223 (0.75807)\tLoss 0.9835 (1.2126)\tPrec@1 75.00000 (69.34524)\tPrec@5 93.75000 (86.60715)\n",
            "Epoch: [6][22/25]\tTime 0.16922 (0.89672)\tData 0.00688 (0.72392)\tLoss 1.0189 (1.2038)\tPrec@1 75.00000 (69.60227)\tPrec@5 93.75000 (86.93182)\n",
            "Epoch: [6][23/25]\tTime 1.25909 (0.91248)\tData 1.12388 (0.74131)\tLoss 1.2804 (1.2071)\tPrec@1 56.25000 (69.02174)\tPrec@5 93.75000 (87.22826)\n",
            "Epoch: [6][24/25]\tTime 0.13211 (0.87996)\tData 0.00113 (0.71047)\tLoss 1.5306 (1.2206)\tPrec@1 68.75000 (69.01042)\tPrec@5 81.25000 (86.97917)\n",
            "Epoch: [6][25/25]\tTime 0.13972 (0.85035)\tData 0.07669 (0.68512)\tLoss 1.3973 (1.2224)\tPrec@1 50.00000 (68.81443)\tPrec@5 75.00000 (86.85567)\n",
            "train at epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [7][0/231]\t lr: 0.00100\tTime 4.119 (4.119)\tData 3.748 (3.748)\tLoss 1.0294 (1.0294)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [7][10/231]\t lr: 0.00100\tTime 2.942 (1.920)\tData 2.599 (1.617)\tLoss 0.8561 (1.1236)\tPrec@1 81.25000 (67.32954)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [7][20/231]\t lr: 0.00100\tTime 3.297 (1.810)\tData 3.013 (1.518)\tLoss 1.0298 (1.1299)\tPrec@1 78.12500 (68.00595)\tPrec@5 90.62500 (90.92262)\n",
            "Epoch: [7][30/231]\t lr: 0.00100\tTime 3.242 (1.784)\tData 2.861 (1.490)\tLoss 1.0600 (1.1018)\tPrec@1 81.25000 (68.95161)\tPrec@5 93.75000 (91.93548)\n",
            "Epoch: [7][40/231]\t lr: 0.00100\tTime 3.160 (1.770)\tData 2.778 (1.476)\tLoss 1.1676 (1.1120)\tPrec@1 59.37500 (68.75000)\tPrec@5 90.62500 (91.76829)\n",
            "Epoch: [7][50/231]\t lr: 0.00100\tTime 3.328 (1.762)\tData 3.026 (1.466)\tLoss 1.0181 (1.1075)\tPrec@1 75.00000 (69.11765)\tPrec@5 90.62500 (91.54412)\n",
            "Epoch: [7][60/231]\t lr: 0.00100\tTime 3.089 (1.745)\tData 2.762 (1.449)\tLoss 1.3632 (1.1114)\tPrec@1 68.75000 (69.21106)\tPrec@5 87.50000 (91.49590)\n",
            "Epoch: [7][70/231]\t lr: 0.00100\tTime 3.028 (1.736)\tData 2.669 (1.439)\tLoss 0.9945 (1.1332)\tPrec@1 75.00000 (68.75000)\tPrec@5 93.75000 (90.93310)\n",
            "Epoch: [7][80/231]\t lr: 0.00100\tTime 3.320 (1.732)\tData 2.922 (1.435)\tLoss 0.7243 (1.1504)\tPrec@1 84.37500 (68.01698)\tPrec@5 96.87500 (90.77932)\n",
            "Epoch: [7][90/231]\t lr: 0.00100\tTime 3.051 (1.730)\tData 2.699 (1.435)\tLoss 1.1121 (1.1429)\tPrec@1 75.00000 (68.09753)\tPrec@5 90.62500 (91.10577)\n",
            "Epoch: [7][100/231]\t lr: 0.00100\tTime 3.257 (1.722)\tData 2.886 (1.425)\tLoss 1.2195 (1.1577)\tPrec@1 59.37500 (67.79084)\tPrec@5 87.50000 (90.77970)\n",
            "Epoch: [7][110/231]\t lr: 0.00100\tTime 3.076 (1.721)\tData 2.792 (1.425)\tLoss 1.2741 (1.1540)\tPrec@1 56.25000 (67.73649)\tPrec@5 90.62500 (90.87838)\n",
            "Epoch: [7][120/231]\t lr: 0.00100\tTime 2.870 (1.718)\tData 2.504 (1.421)\tLoss 1.0306 (1.1622)\tPrec@1 71.87500 (67.40702)\tPrec@5 96.87500 (90.88326)\n",
            "Epoch: [7][130/231]\t lr: 0.00100\tTime 2.941 (1.713)\tData 2.605 (1.416)\tLoss 0.9836 (1.1579)\tPrec@1 68.75000 (67.43798)\tPrec@5 96.87500 (91.00668)\n",
            "Epoch: [7][140/231]\t lr: 0.00100\tTime 3.166 (1.709)\tData 2.805 (1.413)\tLoss 1.2001 (1.1551)\tPrec@1 71.87500 (67.46454)\tPrec@5 100.00000 (91.13475)\n",
            "Epoch: [7][150/231]\t lr: 0.00100\tTime 2.793 (1.708)\tData 2.425 (1.410)\tLoss 1.2174 (1.1560)\tPrec@1 68.75000 (67.40480)\tPrec@5 90.62500 (91.05960)\n",
            "Epoch: [7][160/231]\t lr: 0.00100\tTime 3.032 (1.701)\tData 2.729 (1.404)\tLoss 1.2034 (1.1570)\tPrec@1 68.75000 (67.52718)\tPrec@5 87.50000 (90.97438)\n",
            "Epoch: [7][170/231]\t lr: 0.00100\tTime 3.285 (1.702)\tData 2.946 (1.406)\tLoss 1.3476 (1.1642)\tPrec@1 68.75000 (67.39766)\tPrec@5 87.50000 (90.75292)\n",
            "Epoch: [7][180/231]\t lr: 0.00100\tTime 3.196 (1.702)\tData 2.851 (1.405)\tLoss 1.3993 (1.1631)\tPrec@1 56.25000 (67.40332)\tPrec@5 87.50000 (90.81492)\n",
            "Epoch: [7][190/231]\t lr: 0.00100\tTime 2.460 (1.699)\tData 2.127 (1.403)\tLoss 1.0515 (1.1623)\tPrec@1 68.75000 (67.52290)\tPrec@5 90.62500 (90.82133)\n",
            "Epoch: [7][200/231]\t lr: 0.00100\tTime 3.118 (1.700)\tData 2.784 (1.403)\tLoss 1.4413 (1.1625)\tPrec@1 56.25000 (67.47512)\tPrec@5 90.62500 (90.87376)\n",
            "Epoch: [7][210/231]\t lr: 0.00100\tTime 3.303 (1.700)\tData 2.920 (1.403)\tLoss 1.3696 (1.1679)\tPrec@1 65.62500 (67.32820)\tPrec@5 90.62500 (90.77311)\n",
            "Epoch: [7][220/231]\t lr: 0.00100\tTime 2.757 (1.697)\tData 2.454 (1.401)\tLoss 1.0129 (1.1677)\tPrec@1 68.75000 (67.27941)\tPrec@5 93.75000 (90.69570)\n",
            "Epoch: [7][230/231]\t lr: 0.00100\tTime 0.065 (1.682)\tData 0.000 (1.387)\tLoss 1.8594 (1.1677)\tPrec@1 50.00000 (67.24138)\tPrec@5 83.33333 (90.72767)\n",
            "validation at epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [7][1/25]\tTime 2.12854 (2.12854)\tData 1.88155 (1.88155)\tLoss 0.7848 (0.7848)\tPrec@1 75.00000 (75.00000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [7][2/25]\tTime 0.16398 (1.14626)\tData 0.00818 (0.94487)\tLoss 1.2462 (1.0155)\tPrec@1 68.75000 (71.87500)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [7][3/25]\tTime 1.73604 (1.34285)\tData 1.54908 (1.14627)\tLoss 1.2634 (1.0981)\tPrec@1 75.00000 (72.91667)\tPrec@5 81.25000 (87.50000)\n",
            "Epoch: [7][4/25]\tTime 0.18998 (1.05463)\tData 0.00758 (0.86160)\tLoss 0.6946 (0.9973)\tPrec@1 75.00000 (73.43750)\tPrec@5 93.75000 (89.06250)\n",
            "Epoch: [7][5/25]\tTime 1.67665 (1.17904)\tData 1.54790 (0.99886)\tLoss 1.8209 (1.1620)\tPrec@1 50.00000 (68.75000)\tPrec@5 81.25000 (87.50000)\n",
            "Epoch: [7][6/25]\tTime 0.12683 (1.00367)\tData 0.00132 (0.83260)\tLoss 1.5174 (1.2212)\tPrec@1 43.75000 (64.58334)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [7][7/25]\tTime 1.52306 (1.07787)\tData 1.39603 (0.91309)\tLoss 1.3697 (1.2424)\tPrec@1 56.25000 (63.39286)\tPrec@5 100.00000 (89.28572)\n",
            "Epoch: [7][8/25]\tTime 0.13415 (0.95990)\tData 0.00133 (0.79912)\tLoss 1.5624 (1.2824)\tPrec@1 50.00000 (61.71875)\tPrec@5 81.25000 (88.28125)\n",
            "Epoch: [7][9/25]\tTime 1.43245 (1.01241)\tData 1.23740 (0.84782)\tLoss 1.0993 (1.2621)\tPrec@1 62.50000 (61.80556)\tPrec@5 93.75000 (88.88889)\n",
            "Epoch: [7][10/25]\tTime 0.14554 (0.92572)\tData 0.00126 (0.76316)\tLoss 1.3726 (1.2731)\tPrec@1 50.00000 (60.62500)\tPrec@5 87.50000 (88.75000)\n",
            "Epoch: [7][11/25]\tTime 1.57674 (0.98491)\tData 1.36486 (0.81786)\tLoss 1.0449 (1.2524)\tPrec@1 68.75000 (61.36364)\tPrec@5 81.25000 (88.06818)\n",
            "Epoch: [7][12/25]\tTime 0.18630 (0.91836)\tData 0.00131 (0.74982)\tLoss 1.5340 (1.2759)\tPrec@1 68.75000 (61.97917)\tPrec@5 87.50000 (88.02084)\n",
            "Epoch: [7][13/25]\tTime 1.50335 (0.96336)\tData 1.31981 (0.79366)\tLoss 1.3351 (1.2804)\tPrec@1 68.75000 (62.50000)\tPrec@5 87.50000 (87.98077)\n",
            "Epoch: [7][14/25]\tTime 0.13205 (0.90398)\tData 0.00419 (0.73727)\tLoss 1.2762 (1.2801)\tPrec@1 75.00000 (63.39286)\tPrec@5 81.25000 (87.50001)\n",
            "Epoch: [7][15/25]\tTime 1.28780 (0.92956)\tData 1.12659 (0.76323)\tLoss 0.9868 (1.2606)\tPrec@1 75.00000 (64.16667)\tPrec@5 87.50000 (87.50001)\n",
            "Epoch: [7][16/25]\tTime 0.14924 (0.88079)\tData 0.00826 (0.71604)\tLoss 1.3899 (1.2686)\tPrec@1 68.75000 (64.45312)\tPrec@5 75.00000 (86.71875)\n",
            "Epoch: [7][17/25]\tTime 1.64889 (0.92598)\tData 1.45420 (0.75946)\tLoss 0.5456 (1.2261)\tPrec@1 100.00000 (66.54412)\tPrec@5 100.00000 (87.50000)\n",
            "Epoch: [7][18/25]\tTime 0.23682 (0.88769)\tData 0.00801 (0.71771)\tLoss 1.0220 (1.2148)\tPrec@1 75.00000 (67.01389)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [7][19/25]\tTime 1.52281 (0.92112)\tData 1.34084 (0.75051)\tLoss 0.6169 (1.1833)\tPrec@1 87.50000 (68.09210)\tPrec@5 100.00000 (88.15790)\n",
            "Epoch: [7][20/25]\tTime 0.15699 (0.88291)\tData 0.00156 (0.71306)\tLoss 1.1784 (1.1831)\tPrec@1 68.75000 (68.12500)\tPrec@5 93.75000 (88.43750)\n",
            "Epoch: [7][21/25]\tTime 1.47203 (0.91096)\tData 1.28394 (0.74025)\tLoss 1.0781 (1.1781)\tPrec@1 68.75000 (68.15476)\tPrec@5 87.50000 (88.39286)\n",
            "Epoch: [7][22/25]\tTime 0.21036 (0.87912)\tData 0.00424 (0.70679)\tLoss 1.3301 (1.1850)\tPrec@1 68.75000 (68.18182)\tPrec@5 81.25000 (88.06818)\n",
            "Epoch: [7][23/25]\tTime 1.29522 (0.89721)\tData 1.18159 (0.72744)\tLoss 1.3790 (1.1934)\tPrec@1 68.75000 (68.20652)\tPrec@5 87.50000 (88.04348)\n",
            "Epoch: [7][24/25]\tTime 0.13467 (0.86544)\tData 0.00113 (0.69717)\tLoss 1.4918 (1.2058)\tPrec@1 62.50000 (67.96875)\tPrec@5 87.50000 (88.02084)\n",
            "Epoch: [7][25/25]\tTime 0.18247 (0.83812)\tData 0.12145 (0.67414)\tLoss 0.0581 (1.1940)\tPrec@1 100.00000 (68.29897)\tPrec@5 100.00000 (88.14433)\n",
            "train at epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [8][0/231]\t lr: 0.00100\tTime 3.780 (3.780)\tData 3.442 (3.442)\tLoss 0.8213 (0.8213)\tPrec@1 78.12500 (78.12500)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [8][10/231]\t lr: 0.00100\tTime 3.177 (1.917)\tData 2.815 (1.613)\tLoss 1.1225 (1.0968)\tPrec@1 68.75000 (68.75000)\tPrec@5 90.62500 (92.04546)\n",
            "Epoch: [8][20/231]\t lr: 0.00100\tTime 3.257 (1.793)\tData 2.909 (1.499)\tLoss 1.0267 (1.1102)\tPrec@1 71.87500 (68.60119)\tPrec@5 93.75000 (91.36905)\n",
            "Epoch: [8][30/231]\t lr: 0.00100\tTime 3.169 (1.785)\tData 2.801 (1.492)\tLoss 1.4998 (1.1166)\tPrec@1 62.50000 (68.24596)\tPrec@5 84.37500 (91.53226)\n",
            "Epoch: [8][40/231]\t lr: 0.00100\tTime 3.053 (1.744)\tData 2.669 (1.446)\tLoss 1.1394 (1.1603)\tPrec@1 62.50000 (67.14939)\tPrec@5 93.75000 (90.92988)\n",
            "Epoch: [8][50/231]\t lr: 0.00100\tTime 2.777 (1.723)\tData 2.422 (1.426)\tLoss 1.3846 (1.1839)\tPrec@1 62.50000 (66.66667)\tPrec@5 87.50000 (90.37991)\n",
            "Epoch: [8][60/231]\t lr: 0.00100\tTime 2.855 (1.708)\tData 2.529 (1.412)\tLoss 1.0888 (1.1810)\tPrec@1 62.50000 (66.80328)\tPrec@5 96.87500 (90.16393)\n",
            "Epoch: [8][70/231]\t lr: 0.00100\tTime 2.410 (1.705)\tData 2.077 (1.409)\tLoss 1.2745 (1.1663)\tPrec@1 59.37500 (66.94542)\tPrec@5 90.62500 (90.53697)\n",
            "Epoch: [8][80/231]\t lr: 0.00100\tTime 3.000 (1.698)\tData 2.687 (1.401)\tLoss 0.8220 (1.1796)\tPrec@1 75.00000 (66.66666)\tPrec@5 96.87500 (90.50926)\n",
            "Epoch: [8][90/231]\t lr: 0.00100\tTime 3.197 (1.693)\tData 2.818 (1.397)\tLoss 1.4348 (1.1665)\tPrec@1 59.37500 (67.23901)\tPrec@5 84.37500 (90.65934)\n",
            "Epoch: [8][100/231]\t lr: 0.00100\tTime 3.212 (1.693)\tData 2.869 (1.396)\tLoss 1.3994 (1.1722)\tPrec@1 56.25000 (67.11015)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [8][110/231]\t lr: 0.00100\tTime 3.014 (1.692)\tData 2.706 (1.394)\tLoss 1.3302 (1.1625)\tPrec@1 65.62500 (67.37050)\tPrec@5 78.12500 (90.73762)\n",
            "Epoch: [8][120/231]\t lr: 0.00100\tTime 3.074 (1.693)\tData 2.752 (1.397)\tLoss 1.3973 (1.1617)\tPrec@1 59.37500 (67.51033)\tPrec@5 84.37500 (90.72830)\n",
            "Epoch: [8][130/231]\t lr: 0.00100\tTime 3.452 (1.695)\tData 3.118 (1.398)\tLoss 1.0331 (1.1593)\tPrec@1 71.87500 (67.81966)\tPrec@5 90.62500 (90.79198)\n",
            "Epoch: [8][140/231]\t lr: 0.00100\tTime 2.855 (1.690)\tData 2.519 (1.393)\tLoss 1.3575 (1.1596)\tPrec@1 59.37500 (67.61968)\tPrec@5 93.75000 (90.86879)\n",
            "Epoch: [8][150/231]\t lr: 0.00100\tTime 3.467 (1.693)\tData 3.125 (1.396)\tLoss 1.1164 (1.1595)\tPrec@1 68.75000 (67.88080)\tPrec@5 93.75000 (90.81126)\n",
            "Epoch: [8][160/231]\t lr: 0.00100\tTime 2.976 (1.691)\tData 2.613 (1.394)\tLoss 1.3420 (1.1614)\tPrec@1 65.62500 (67.89597)\tPrec@5 81.25000 (90.64441)\n",
            "Epoch: [8][170/231]\t lr: 0.00100\tTime 2.993 (1.691)\tData 2.668 (1.394)\tLoss 0.8130 (1.1609)\tPrec@1 78.12500 (67.85453)\tPrec@5 100.00000 (90.60673)\n",
            "Epoch: [8][180/231]\t lr: 0.00100\tTime 3.218 (1.690)\tData 2.916 (1.394)\tLoss 0.6765 (1.1547)\tPrec@1 84.37500 (68.09393)\tPrec@5 100.00000 (90.65953)\n",
            "Epoch: [8][190/231]\t lr: 0.00100\tTime 3.120 (1.689)\tData 2.771 (1.392)\tLoss 1.0336 (1.1593)\tPrec@1 75.00000 (67.83377)\tPrec@5 90.62500 (90.64137)\n",
            "Epoch: [8][200/231]\t lr: 0.00100\tTime 2.861 (1.685)\tData 2.539 (1.388)\tLoss 0.8542 (1.1565)\tPrec@1 68.75000 (67.81716)\tPrec@5 93.75000 (90.64055)\n",
            "Epoch: [8][210/231]\t lr: 0.00100\tTime 3.205 (1.685)\tData 2.840 (1.387)\tLoss 1.1780 (1.1559)\tPrec@1 68.75000 (67.87619)\tPrec@5 87.50000 (90.63982)\n",
            "Epoch: [8][220/231]\t lr: 0.00100\tTime 2.953 (1.684)\tData 2.579 (1.387)\tLoss 1.1209 (1.1541)\tPrec@1 65.62500 (67.95815)\tPrec@5 90.62500 (90.68156)\n",
            "Epoch: [8][230/231]\t lr: 0.00100\tTime 0.063 (1.669)\tData 0.000 (1.373)\tLoss 1.9186 (1.1460)\tPrec@1 16.66667 (68.24599)\tPrec@5 100.00000 (90.82270)\n",
            "validation at epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [8][1/25]\tTime 2.00153 (2.00153)\tData 1.80607 (1.80607)\tLoss 1.0154 (1.0154)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [8][2/25]\tTime 0.15271 (1.07712)\tData 0.00676 (0.90642)\tLoss 0.7595 (0.8875)\tPrec@1 68.75000 (68.75000)\tPrec@5 100.00000 (96.87500)\n",
            "Epoch: [8][3/25]\tTime 1.77016 (1.30814)\tData 1.57476 (1.12920)\tLoss 0.4074 (0.7274)\tPrec@1 87.50000 (75.00000)\tPrec@5 100.00000 (97.91667)\n",
            "Epoch: [8][4/25]\tTime 0.13783 (1.01556)\tData 0.00112 (0.84718)\tLoss 1.4633 (0.9114)\tPrec@1 56.25000 (70.31250)\tPrec@5 87.50000 (95.31250)\n",
            "Epoch: [8][5/25]\tTime 1.51037 (1.11452)\tData 1.38218 (0.95418)\tLoss 1.7440 (1.0779)\tPrec@1 50.00000 (66.25000)\tPrec@5 81.25000 (92.50000)\n",
            "Epoch: [8][6/25]\tTime 0.14947 (0.95368)\tData 0.00136 (0.79538)\tLoss 1.1809 (1.0951)\tPrec@1 56.25000 (64.58334)\tPrec@5 87.50000 (91.66667)\n",
            "Epoch: [8][7/25]\tTime 1.81708 (1.07702)\tData 1.63637 (0.91552)\tLoss 0.6118 (1.0260)\tPrec@1 87.50000 (67.85715)\tPrec@5 100.00000 (92.85715)\n",
            "Epoch: [8][8/25]\tTime 0.18102 (0.96502)\tData 0.00991 (0.80232)\tLoss 1.3194 (1.0627)\tPrec@1 62.50000 (67.18750)\tPrec@5 87.50000 (92.18750)\n",
            "Epoch: [8][9/25]\tTime 1.58443 (1.03385)\tData 1.40630 (0.86943)\tLoss 1.4274 (1.1032)\tPrec@1 75.00000 (68.05556)\tPrec@5 87.50000 (91.66666)\n",
            "Epoch: [8][10/25]\tTime 0.17518 (0.94798)\tData 0.00470 (0.78295)\tLoss 1.8031 (1.1732)\tPrec@1 62.50000 (67.50000)\tPrec@5 68.75000 (89.37500)\n",
            "Epoch: [8][11/25]\tTime 1.38256 (0.98749)\tData 1.20647 (0.82145)\tLoss 0.3670 (1.0999)\tPrec@1 100.00000 (70.45454)\tPrec@5 100.00000 (90.34091)\n",
            "Epoch: [8][12/25]\tTime 0.14825 (0.91755)\tData 0.00425 (0.75335)\tLoss 0.9094 (1.0841)\tPrec@1 75.00000 (70.83334)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [8][13/25]\tTime 1.67960 (0.97617)\tData 1.49325 (0.81027)\tLoss 2.1404 (1.1653)\tPrec@1 43.75000 (68.75000)\tPrec@5 75.00000 (89.42308)\n",
            "Epoch: [8][14/25]\tTime 0.16907 (0.91852)\tData 0.00146 (0.75250)\tLoss 0.6141 (1.1259)\tPrec@1 81.25000 (69.64286)\tPrec@5 100.00000 (90.17857)\n",
            "Epoch: [8][15/25]\tTime 1.37800 (0.94915)\tData 1.19307 (0.78187)\tLoss 1.2026 (1.1311)\tPrec@1 68.75000 (69.58334)\tPrec@5 93.75000 (90.41667)\n",
            "Epoch: [8][16/25]\tTime 0.14332 (0.89879)\tData 0.00139 (0.73309)\tLoss 0.8936 (1.1162)\tPrec@1 81.25000 (70.31250)\tPrec@5 100.00000 (91.01562)\n",
            "Epoch: [8][17/25]\tTime 1.34411 (0.92498)\tData 1.21691 (0.76155)\tLoss 1.9581 (1.1657)\tPrec@1 43.75000 (68.75000)\tPrec@5 75.00000 (90.07353)\n",
            "Epoch: [8][18/25]\tTime 0.20692 (0.88509)\tData 0.00134 (0.71932)\tLoss 1.3595 (1.1765)\tPrec@1 50.00000 (67.70834)\tPrec@5 93.75000 (90.27778)\n",
            "Epoch: [8][19/25]\tTime 1.64213 (0.92494)\tData 1.48373 (0.75955)\tLoss 1.6311 (1.2004)\tPrec@1 56.25000 (67.10526)\tPrec@5 75.00000 (89.47369)\n",
            "Epoch: [8][20/25]\tTime 0.20075 (0.88873)\tData 0.00120 (0.72163)\tLoss 1.4321 (1.2120)\tPrec@1 75.00000 (67.50000)\tPrec@5 81.25000 (89.06250)\n",
            "Epoch: [8][21/25]\tTime 1.33617 (0.91003)\tData 1.15290 (0.74217)\tLoss 0.8694 (1.1957)\tPrec@1 68.75000 (67.55952)\tPrec@5 93.75000 (89.28571)\n",
            "Epoch: [8][22/25]\tTime 0.12866 (0.87452)\tData 0.00108 (0.70848)\tLoss 0.8022 (1.1778)\tPrec@1 75.00000 (67.89773)\tPrec@5 100.00000 (89.77273)\n",
            "Epoch: [8][23/25]\tTime 1.36630 (0.89590)\tData 1.23764 (0.73149)\tLoss 1.1257 (1.1755)\tPrec@1 68.75000 (67.93478)\tPrec@5 81.25000 (89.40218)\n",
            "Epoch: [8][24/25]\tTime 0.13671 (0.86426)\tData 0.00130 (0.70106)\tLoss 0.6501 (1.1537)\tPrec@1 81.25000 (68.48959)\tPrec@5 93.75000 (89.58334)\n",
            "Epoch: [8][25/25]\tTime 0.20948 (0.83807)\tData 0.14782 (0.67893)\tLoss 1.2922 (1.1551)\tPrec@1 50.00000 (68.29897)\tPrec@5 100.00000 (89.69072)\n",
            "train at epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [9][0/231]\t lr: 0.00100\tTime 4.007 (4.007)\tData 3.656 (3.656)\tLoss 0.9239 (0.9239)\tPrec@1 75.00000 (75.00000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [9][10/231]\t lr: 0.00100\tTime 2.468 (1.847)\tData 2.167 (1.541)\tLoss 0.8199 (1.0824)\tPrec@1 81.25000 (68.18182)\tPrec@5 96.87500 (92.04546)\n",
            "Epoch: [9][20/231]\t lr: 0.00100\tTime 2.989 (1.770)\tData 2.638 (1.469)\tLoss 1.3907 (1.1070)\tPrec@1 62.50000 (68.60119)\tPrec@5 87.50000 (91.07143)\n",
            "Epoch: [9][30/231]\t lr: 0.00100\tTime 2.890 (1.745)\tData 2.505 (1.446)\tLoss 1.3133 (1.1164)\tPrec@1 65.62500 (70.66532)\tPrec@5 90.62500 (91.02822)\n",
            "Epoch: [9][40/231]\t lr: 0.00100\tTime 3.129 (1.727)\tData 2.805 (1.429)\tLoss 1.0073 (1.1205)\tPrec@1 62.50000 (69.74085)\tPrec@5 96.87500 (91.15853)\n",
            "Epoch: [9][50/231]\t lr: 0.00100\tTime 2.660 (1.715)\tData 2.303 (1.418)\tLoss 0.6915 (1.1235)\tPrec@1 81.25000 (69.42402)\tPrec@5 96.87500 (91.11520)\n",
            "Epoch: [9][60/231]\t lr: 0.00100\tTime 3.031 (1.718)\tData 2.625 (1.418)\tLoss 0.5421 (1.1218)\tPrec@1 90.62500 (69.21106)\tPrec@5 100.00000 (90.88114)\n",
            "Epoch: [9][70/231]\t lr: 0.00100\tTime 3.121 (1.707)\tData 2.787 (1.408)\tLoss 0.9609 (1.1127)\tPrec@1 68.75000 (69.19014)\tPrec@5 96.87500 (90.80106)\n",
            "Epoch: [9][80/231]\t lr: 0.00100\tTime 2.820 (1.701)\tData 2.514 (1.402)\tLoss 1.0270 (1.1197)\tPrec@1 68.75000 (68.78858)\tPrec@5 93.75000 (90.66358)\n",
            "Epoch: [9][90/231]\t lr: 0.00100\tTime 3.186 (1.700)\tData 2.874 (1.401)\tLoss 1.5621 (1.1293)\tPrec@1 56.25000 (68.47527)\tPrec@5 90.62500 (90.45330)\n",
            "Epoch: [9][100/231]\t lr: 0.00100\tTime 3.221 (1.703)\tData 2.852 (1.404)\tLoss 1.1713 (1.1366)\tPrec@1 71.87500 (68.37872)\tPrec@5 90.62500 (90.37747)\n",
            "Epoch: [9][110/231]\t lr: 0.00100\tTime 3.160 (1.697)\tData 2.824 (1.398)\tLoss 1.0691 (1.1314)\tPrec@1 65.62500 (68.49662)\tPrec@5 90.62500 (90.39978)\n",
            "Epoch: [9][120/231]\t lr: 0.00100\tTime 2.485 (1.691)\tData 2.132 (1.393)\tLoss 1.2331 (1.1348)\tPrec@1 62.50000 (68.28512)\tPrec@5 87.50000 (90.34090)\n",
            "Epoch: [9][130/231]\t lr: 0.00100\tTime 3.166 (1.691)\tData 2.816 (1.392)\tLoss 1.6454 (1.1362)\tPrec@1 62.50000 (68.29675)\tPrec@5 75.00000 (90.38645)\n",
            "Epoch: [9][140/231]\t lr: 0.00100\tTime 2.472 (1.687)\tData 2.148 (1.389)\tLoss 1.3205 (1.1453)\tPrec@1 65.62500 (68.08511)\tPrec@5 78.12500 (90.20390)\n",
            "Epoch: [9][150/231]\t lr: 0.00100\tTime 2.933 (1.689)\tData 2.564 (1.391)\tLoss 1.4729 (1.1412)\tPrec@1 53.12500 (68.17053)\tPrec@5 93.75000 (90.37666)\n",
            "Epoch: [9][160/231]\t lr: 0.00100\tTime 2.603 (1.688)\tData 2.268 (1.390)\tLoss 1.0528 (1.1443)\tPrec@1 65.62500 (68.03183)\tPrec@5 93.75000 (90.43090)\n",
            "Epoch: [9][170/231]\t lr: 0.00100\tTime 3.056 (1.694)\tData 2.682 (1.395)\tLoss 1.1869 (1.1474)\tPrec@1 68.75000 (68.00073)\tPrec@5 93.75000 (90.55190)\n",
            "Epoch: [9][180/231]\t lr: 0.00100\tTime 2.929 (1.698)\tData 2.617 (1.398)\tLoss 1.3140 (1.1540)\tPrec@1 65.62500 (67.81768)\tPrec@5 84.37500 (90.45235)\n",
            "Epoch: [9][190/231]\t lr: 0.00100\tTime 3.223 (1.697)\tData 2.850 (1.397)\tLoss 0.7518 (1.1465)\tPrec@1 81.25000 (68.11191)\tPrec@5 100.00000 (90.65772)\n",
            "Epoch: [9][200/231]\t lr: 0.00100\tTime 2.646 (1.694)\tData 2.275 (1.395)\tLoss 1.4311 (1.1518)\tPrec@1 65.62500 (67.95708)\tPrec@5 75.00000 (90.48507)\n",
            "Epoch: [9][210/231]\t lr: 0.00100\tTime 2.913 (1.694)\tData 2.577 (1.394)\tLoss 1.0341 (1.1515)\tPrec@1 68.75000 (67.92062)\tPrec@5 90.62500 (90.47690)\n",
            "Epoch: [9][220/231]\t lr: 0.00100\tTime 3.018 (1.697)\tData 2.652 (1.397)\tLoss 0.9479 (1.1467)\tPrec@1 68.75000 (67.94401)\tPrec@5 90.62500 (90.62501)\n",
            "Epoch: [9][230/231]\t lr: 0.00100\tTime 0.064 (1.683)\tData 0.000 (1.386)\tLoss 2.1971 (1.1463)\tPrec@1 50.00000 (67.92017)\tPrec@5 66.66666 (90.61906)\n",
            "validation at epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [9][1/25]\tTime 1.95738 (1.95738)\tData 1.76692 (1.76692)\tLoss 0.5280 (0.5280)\tPrec@1 87.50000 (87.50000)\tPrec@5 100.00000 (100.00000)\n",
            "Epoch: [9][2/25]\tTime 0.17564 (1.06651)\tData 0.00108 (0.88400)\tLoss 1.0964 (0.8122)\tPrec@1 68.75000 (78.12500)\tPrec@5 93.75000 (96.87500)\n",
            "Epoch: [9][3/25]\tTime 1.54530 (1.22611)\tData 1.40777 (1.05859)\tLoss 1.0407 (0.8884)\tPrec@1 62.50000 (72.91667)\tPrec@5 87.50000 (93.75000)\n",
            "Epoch: [9][4/25]\tTime 0.14267 (0.95525)\tData 0.01176 (0.79688)\tLoss 1.2610 (0.9815)\tPrec@1 68.75000 (71.87500)\tPrec@5 87.50000 (92.18750)\n",
            "Epoch: [9][5/25]\tTime 1.68373 (1.10094)\tData 1.47951 (0.93341)\tLoss 1.1506 (1.0153)\tPrec@1 50.00000 (67.50000)\tPrec@5 93.75000 (92.50000)\n",
            "Epoch: [9][6/25]\tTime 0.19206 (0.94946)\tData 0.00499 (0.77867)\tLoss 0.7963 (0.9788)\tPrec@1 75.00000 (68.75000)\tPrec@5 100.00000 (93.75000)\n",
            "Epoch: [9][7/25]\tTime 1.76214 (1.06556)\tData 1.61931 (0.89876)\tLoss 0.6668 (0.9343)\tPrec@1 81.25000 (70.53572)\tPrec@5 100.00000 (94.64286)\n",
            "Epoch: [9][8/25]\tTime 0.19992 (0.95735)\tData 0.00183 (0.78665)\tLoss 1.0368 (0.9471)\tPrec@1 68.75000 (70.31250)\tPrec@5 93.75000 (94.53125)\n",
            "Epoch: [9][9/25]\tTime 1.69336 (1.03913)\tData 1.50726 (0.86671)\tLoss 1.1980 (0.9750)\tPrec@1 62.50000 (69.44444)\tPrec@5 93.75000 (94.44444)\n",
            "Epoch: [9][10/25]\tTime 0.16272 (0.95149)\tData 0.00518 (0.78056)\tLoss 1.0502 (0.9825)\tPrec@1 81.25000 (70.62500)\tPrec@5 87.50000 (93.75000)\n",
            "Epoch: [9][11/25]\tTime 1.23408 (0.97718)\tData 1.06093 (0.80605)\tLoss 0.7587 (0.9621)\tPrec@1 81.25000 (71.59091)\tPrec@5 100.00000 (94.31818)\n",
            "Epoch: [9][12/25]\tTime 0.20383 (0.91274)\tData 0.00883 (0.73961)\tLoss 1.2890 (0.9894)\tPrec@1 56.25000 (70.31250)\tPrec@5 81.25000 (93.22917)\n",
            "Epoch: [9][13/25]\tTime 1.29177 (0.94189)\tData 1.11629 (0.76859)\tLoss 1.7100 (1.0448)\tPrec@1 50.00000 (68.75000)\tPrec@5 75.00000 (91.82693)\n",
            "Epoch: [9][14/25]\tTime 0.15721 (0.88584)\tData 0.01748 (0.71494)\tLoss 1.6979 (1.0915)\tPrec@1 50.00000 (67.41072)\tPrec@5 87.50000 (91.51786)\n",
            "Epoch: [9][15/25]\tTime 1.38487 (0.91911)\tData 1.20296 (0.74747)\tLoss 1.4051 (1.1124)\tPrec@1 62.50000 (67.08334)\tPrec@5 87.50000 (91.25001)\n",
            "Epoch: [9][16/25]\tTime 0.33957 (0.88289)\tData 0.13402 (0.70913)\tLoss 1.7361 (1.1513)\tPrec@1 50.00000 (66.01562)\tPrec@5 75.00000 (90.23438)\n",
            "Epoch: [9][17/25]\tTime 1.23265 (0.90347)\tData 1.06736 (0.73021)\tLoss 1.3990 (1.1659)\tPrec@1 62.50000 (65.80882)\tPrec@5 81.25000 (89.70588)\n",
            "Epoch: [9][18/25]\tTime 0.55601 (0.88416)\tData 0.37334 (0.71038)\tLoss 0.7287 (1.1416)\tPrec@1 81.25000 (66.66666)\tPrec@5 93.75000 (89.93056)\n",
            "Epoch: [9][19/25]\tTime 1.23014 (0.90237)\tData 1.06919 (0.72926)\tLoss 1.5677 (1.1641)\tPrec@1 50.00000 (65.78947)\tPrec@5 81.25000 (89.47369)\n",
            "Epoch: [9][20/25]\tTime 0.45738 (0.88012)\tData 0.25280 (0.70544)\tLoss 1.0527 (1.1585)\tPrec@1 81.25000 (66.56250)\tPrec@5 93.75000 (89.68750)\n",
            "Epoch: [9][21/25]\tTime 1.17704 (0.89426)\tData 0.97326 (0.71819)\tLoss 1.6425 (1.1815)\tPrec@1 62.50000 (66.36905)\tPrec@5 68.75000 (88.69048)\n",
            "Epoch: [9][22/25]\tTime 0.37991 (0.87088)\tData 0.18647 (0.69403)\tLoss 1.4099 (1.1919)\tPrec@1 75.00000 (66.76137)\tPrec@5 87.50000 (88.63637)\n",
            "Epoch: [9][23/25]\tTime 1.30929 (0.88994)\tData 1.11815 (0.71247)\tLoss 1.1112 (1.1884)\tPrec@1 68.75000 (66.84782)\tPrec@5 87.50000 (88.58696)\n",
            "Epoch: [9][24/25]\tTime 0.37812 (0.86862)\tData 0.26847 (0.69397)\tLoss 1.5102 (1.2018)\tPrec@1 62.50000 (66.66667)\tPrec@5 81.25000 (88.28125)\n",
            "Epoch: [9][25/25]\tTime 0.06026 (0.83628)\tData 0.00107 (0.66625)\tLoss 1.3008 (1.2028)\tPrec@1 50.00000 (66.49484)\tPrec@5 75.00000 (88.14433)\n",
            "train at epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [10][0/231]\t lr: 0.00100\tTime 3.526 (3.526)\tData 3.240 (3.240)\tLoss 0.9973 (0.9973)\tPrec@1 71.87500 (71.87500)\tPrec@5 90.62500 (90.62500)\n",
            "Epoch: [10][10/231]\t lr: 0.00100\tTime 3.298 (1.903)\tData 2.954 (1.613)\tLoss 1.2336 (1.0793)\tPrec@1 56.25000 (69.31818)\tPrec@5 90.62500 (90.34091)\n",
            "Epoch: [10][20/231]\t lr: 0.00100\tTime 2.759 (1.810)\tData 2.445 (1.516)\tLoss 0.9705 (1.1053)\tPrec@1 78.12500 (69.79167)\tPrec@5 90.62500 (89.88095)\n",
            "Epoch: [10][30/231]\t lr: 0.00100\tTime 3.203 (1.781)\tData 2.875 (1.487)\tLoss 1.3486 (1.1295)\tPrec@1 56.25000 (68.64919)\tPrec@5 87.50000 (90.32258)\n",
            "Epoch: [10][40/231]\t lr: 0.00100\tTime 2.827 (1.755)\tData 2.501 (1.459)\tLoss 1.1526 (1.1128)\tPrec@1 68.75000 (68.59756)\tPrec@5 87.50000 (90.54877)\n",
            "Epoch: [10][50/231]\t lr: 0.00100\tTime 3.271 (1.747)\tData 2.898 (1.451)\tLoss 1.0617 (1.1014)\tPrec@1 78.12500 (69.24020)\tPrec@5 90.62500 (90.99265)\n",
            "Epoch: [10][60/231]\t lr: 0.00100\tTime 3.408 (1.749)\tData 3.044 (1.453)\tLoss 0.6710 (1.0952)\tPrec@1 87.50000 (69.56967)\tPrec@5 100.00000 (91.23975)\n",
            "Epoch: [10][70/231]\t lr: 0.00100\tTime 3.362 (1.744)\tData 3.047 (1.447)\tLoss 1.1828 (1.0949)\tPrec@1 71.87500 (69.71831)\tPrec@5 87.50000 (91.28521)\n",
            "Epoch: [10][80/231]\t lr: 0.00100\tTime 3.029 (1.729)\tData 2.717 (1.431)\tLoss 1.1585 (1.0999)\tPrec@1 65.62500 (69.32870)\tPrec@5 87.50000 (91.20370)\n",
            "Epoch: [10][90/231]\t lr: 0.00100\tTime 2.701 (1.723)\tData 2.341 (1.424)\tLoss 1.0691 (1.1224)\tPrec@1 75.00000 (68.92171)\tPrec@5 93.75000 (90.83105)\n",
            "Epoch: [10][100/231]\t lr: 0.00100\tTime 3.308 (1.718)\tData 2.973 (1.421)\tLoss 1.0901 (1.1235)\tPrec@1 68.75000 (68.87376)\tPrec@5 87.50000 (90.87252)\n",
            "Epoch: [10][110/231]\t lr: 0.00100\tTime 3.217 (1.715)\tData 2.849 (1.417)\tLoss 1.0352 (1.1295)\tPrec@1 68.75000 (68.58109)\tPrec@5 93.75000 (90.59685)\n",
            "Epoch: [10][120/231]\t lr: 0.00100\tTime 3.197 (1.712)\tData 2.868 (1.415)\tLoss 1.3153 (1.1325)\tPrec@1 68.75000 (68.59504)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [10][130/231]\t lr: 0.00100\tTime 2.567 (1.701)\tData 2.236 (1.403)\tLoss 0.9983 (1.1314)\tPrec@1 75.00000 (68.58302)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [10][140/231]\t lr: 0.00100\tTime 3.189 (1.702)\tData 2.821 (1.404)\tLoss 0.9771 (1.1291)\tPrec@1 71.87500 (68.77216)\tPrec@5 90.62500 (90.55851)\n",
            "Epoch: [10][150/231]\t lr: 0.00100\tTime 3.455 (1.707)\tData 3.079 (1.410)\tLoss 1.7825 (1.1359)\tPrec@1 53.12500 (68.58443)\tPrec@5 84.37500 (90.50082)\n",
            "Epoch: [10][160/231]\t lr: 0.00100\tTime 3.069 (1.702)\tData 2.723 (1.406)\tLoss 1.3441 (1.1327)\tPrec@1 59.37500 (68.63354)\tPrec@5 84.37500 (90.50854)\n",
            "Epoch: [10][170/231]\t lr: 0.00100\tTime 3.361 (1.704)\tData 2.999 (1.407)\tLoss 1.3009 (1.1367)\tPrec@1 59.37500 (68.64035)\tPrec@5 96.87500 (90.51535)\n",
            "Epoch: [10][180/231]\t lr: 0.00100\tTime 2.658 (1.700)\tData 2.286 (1.403)\tLoss 1.2191 (1.1391)\tPrec@1 68.75000 (68.66367)\tPrec@5 87.50000 (90.34876)\n",
            "Epoch: [10][190/231]\t lr: 0.00100\tTime 2.968 (1.695)\tData 2.588 (1.398)\tLoss 0.8628 (1.1388)\tPrec@1 84.37500 (68.58639)\tPrec@5 87.50000 (90.28142)\n",
            "Epoch: [10][200/231]\t lr: 0.00100\tTime 2.837 (1.692)\tData 2.498 (1.394)\tLoss 0.7696 (1.1393)\tPrec@1 81.25000 (68.47015)\tPrec@5 96.87500 (90.39179)\n",
            "Epoch: [10][210/231]\t lr: 0.00100\tTime 3.158 (1.695)\tData 2.768 (1.397)\tLoss 1.1575 (1.1380)\tPrec@1 71.87500 (68.43898)\tPrec@5 90.62500 (90.49171)\n",
            "Epoch: [10][220/231]\t lr: 0.00100\tTime 3.163 (1.694)\tData 2.882 (1.398)\tLoss 1.3142 (1.1410)\tPrec@1 56.25000 (68.28337)\tPrec@5 78.12500 (90.49774)\n",
            "Epoch: [10][230/231]\t lr: 0.00100\tTime 0.064 (1.678)\tData 0.000 (1.383)\tLoss 1.0603 (1.1371)\tPrec@1 100.00000 (68.47678)\tPrec@5 100.00000 (90.59191)\n",
            "validation at epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [10][1/25]\tTime 1.99784 (1.99784)\tData 1.75140 (1.75140)\tLoss 1.2073 (1.2073)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [10][2/25]\tTime 0.23086 (1.11435)\tData 0.01406 (0.88273)\tLoss 0.9635 (1.0854)\tPrec@1 75.00000 (71.87500)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [10][3/25]\tTime 1.50435 (1.24435)\tData 1.35577 (1.04041)\tLoss 1.2611 (1.1440)\tPrec@1 62.50000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [10][4/25]\tTime 0.15188 (0.97123)\tData 0.00709 (0.78208)\tLoss 1.4817 (1.2284)\tPrec@1 68.75000 (68.75000)\tPrec@5 87.50000 (92.18750)\n",
            "Epoch: [10][5/25]\tTime 1.60585 (1.09816)\tData 1.49145 (0.92396)\tLoss 1.4886 (1.2805)\tPrec@1 62.50000 (67.50000)\tPrec@5 75.00000 (88.75000)\n",
            "Epoch: [10][6/25]\tTime 0.25483 (0.95760)\tData 0.06431 (0.78068)\tLoss 1.5166 (1.3198)\tPrec@1 56.25000 (65.62500)\tPrec@5 81.25000 (87.50000)\n",
            "Epoch: [10][7/25]\tTime 1.67991 (1.06079)\tData 1.52296 (0.88672)\tLoss 0.9119 (1.2615)\tPrec@1 68.75000 (66.07143)\tPrec@5 93.75000 (88.39286)\n",
            "Epoch: [10][8/25]\tTime 0.17222 (0.94972)\tData 0.00695 (0.77675)\tLoss 1.3971 (1.2785)\tPrec@1 62.50000 (65.62500)\tPrec@5 81.25000 (87.50000)\n",
            "Epoch: [10][9/25]\tTime 1.51980 (1.01306)\tData 1.35904 (0.84145)\tLoss 1.1881 (1.2684)\tPrec@1 62.50000 (65.27778)\tPrec@5 81.25000 (86.80556)\n",
            "Epoch: [10][10/25]\tTime 0.18617 (0.93037)\tData 0.00472 (0.75778)\tLoss 0.8661 (1.2282)\tPrec@1 75.00000 (66.25000)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [10][11/25]\tTime 1.47684 (0.98005)\tData 1.27870 (0.80513)\tLoss 2.0438 (1.3024)\tPrec@1 37.50000 (63.63636)\tPrec@5 75.00000 (86.36364)\n",
            "Epoch: [10][12/25]\tTime 0.14196 (0.91021)\tData 0.00123 (0.73814)\tLoss 1.0002 (1.2772)\tPrec@1 68.75000 (64.06250)\tPrec@5 93.75000 (86.97917)\n",
            "Epoch: [10][13/25]\tTime 1.58496 (0.96211)\tData 1.39382 (0.78858)\tLoss 0.6623 (1.2299)\tPrec@1 81.25000 (65.38462)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [10][14/25]\tTime 0.18188 (0.90638)\tData 0.00592 (0.73267)\tLoss 1.1065 (1.2211)\tPrec@1 75.00000 (66.07143)\tPrec@5 87.50000 (87.50001)\n",
            "Epoch: [10][15/25]\tTime 1.22422 (0.92757)\tData 1.08779 (0.75635)\tLoss 1.4161 (1.2341)\tPrec@1 62.50000 (65.83334)\tPrec@5 81.25000 (87.08334)\n",
            "Epoch: [10][16/25]\tTime 0.55321 (0.90417)\tData 0.37261 (0.73236)\tLoss 1.1472 (1.2286)\tPrec@1 56.25000 (65.23438)\tPrec@5 93.75000 (87.50000)\n",
            "Epoch: [10][17/25]\tTime 1.36432 (0.93124)\tData 1.16591 (0.75787)\tLoss 1.2172 (1.2280)\tPrec@1 81.25000 (66.17647)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [10][18/25]\tTime 0.28589 (0.89539)\tData 0.09448 (0.72101)\tLoss 0.4182 (1.1830)\tPrec@1 93.75000 (67.70834)\tPrec@5 100.00000 (88.19444)\n",
            "Epoch: [10][19/25]\tTime 1.63813 (0.93448)\tData 1.44459 (0.75910)\tLoss 1.1573 (1.1816)\tPrec@1 68.75000 (67.76316)\tPrec@5 93.75000 (88.48684)\n",
            "Epoch: [10][20/25]\tTime 0.13429 (0.89447)\tData 0.00799 (0.72154)\tLoss 1.7059 (1.2078)\tPrec@1 43.75000 (66.56250)\tPrec@5 81.25000 (88.12500)\n",
            "Epoch: [10][21/25]\tTime 1.18567 (0.90834)\tData 1.02254 (0.73587)\tLoss 1.0833 (1.2019)\tPrec@1 62.50000 (66.36905)\tPrec@5 93.75000 (88.39286)\n",
            "Epoch: [10][22/25]\tTime 0.22044 (0.87707)\tData 0.05896 (0.70510)\tLoss 1.0888 (1.1968)\tPrec@1 81.25000 (67.04546)\tPrec@5 87.50000 (88.35227)\n",
            "Epoch: [10][23/25]\tTime 1.60055 (0.90852)\tData 1.47299 (0.73849)\tLoss 0.8784 (1.1829)\tPrec@1 75.00000 (67.39130)\tPrec@5 93.75000 (88.58696)\n",
            "Epoch: [10][24/25]\tTime 0.12936 (0.87606)\tData 0.00128 (0.70777)\tLoss 0.9440 (1.1730)\tPrec@1 68.75000 (67.44792)\tPrec@5 93.75000 (88.80209)\n",
            "Epoch: [10][25/25]\tTime 0.13257 (0.84632)\tData 0.06885 (0.68222)\tLoss 1.3245 (1.1745)\tPrec@1 50.00000 (67.26804)\tPrec@5 100.00000 (88.91753)\n",
            "train at epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [11][0/231]\t lr: 0.00100\tTime 3.835 (3.835)\tData 3.437 (3.437)\tLoss 1.0943 (1.0943)\tPrec@1 65.62500 (65.62500)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [11][10/231]\t lr: 0.00100\tTime 2.885 (1.850)\tData 2.552 (1.537)\tLoss 0.9334 (1.0418)\tPrec@1 68.75000 (70.73864)\tPrec@5 93.75000 (92.89773)\n",
            "Epoch: [11][20/231]\t lr: 0.00100\tTime 2.634 (1.773)\tData 2.312 (1.469)\tLoss 0.8890 (1.0663)\tPrec@1 78.12500 (70.08929)\tPrec@5 90.62500 (91.81548)\n",
            "Epoch: [11][30/231]\t lr: 0.00100\tTime 3.276 (1.774)\tData 2.929 (1.466)\tLoss 0.8080 (1.0527)\tPrec@1 78.12500 (71.06854)\tPrec@5 96.87500 (91.83467)\n",
            "Epoch: [11][40/231]\t lr: 0.00100\tTime 2.824 (1.739)\tData 2.502 (1.438)\tLoss 1.2693 (1.0790)\tPrec@1 65.62500 (70.04573)\tPrec@5 87.50000 (91.31097)\n",
            "Epoch: [11][50/231]\t lr: 0.00100\tTime 3.207 (1.732)\tData 2.848 (1.427)\tLoss 0.9695 (1.0924)\tPrec@1 78.12500 (69.36275)\tPrec@5 90.62500 (91.17648)\n",
            "Epoch: [11][60/231]\t lr: 0.00100\tTime 3.106 (1.721)\tData 2.727 (1.417)\tLoss 0.7908 (1.0943)\tPrec@1 81.25000 (69.15984)\tPrec@5 96.87500 (91.34221)\n",
            "Epoch: [11][70/231]\t lr: 0.00100\tTime 2.704 (1.709)\tData 2.412 (1.405)\tLoss 1.2786 (1.1005)\tPrec@1 59.37500 (69.05810)\tPrec@5 87.50000 (91.24120)\n",
            "Epoch: [11][80/231]\t lr: 0.00100\tTime 3.142 (1.703)\tData 2.870 (1.402)\tLoss 0.8932 (1.1045)\tPrec@1 78.12500 (69.21297)\tPrec@5 93.75000 (91.20370)\n",
            "Epoch: [11][90/231]\t lr: 0.00100\tTime 3.208 (1.704)\tData 2.844 (1.405)\tLoss 1.0820 (1.0996)\tPrec@1 71.87500 (69.36813)\tPrec@5 90.62500 (91.34615)\n",
            "Epoch: [11][100/231]\t lr: 0.00100\tTime 2.640 (1.694)\tData 2.405 (1.396)\tLoss 1.3633 (1.1101)\tPrec@1 53.12500 (69.05940)\tPrec@5 87.50000 (91.12005)\n",
            "Epoch: [11][110/231]\t lr: 0.00100\tTime 2.950 (1.688)\tData 2.609 (1.391)\tLoss 1.1421 (1.1157)\tPrec@1 65.62500 (68.75000)\tPrec@5 96.87500 (91.01915)\n",
            "Epoch: [11][120/231]\t lr: 0.00100\tTime 3.574 (1.689)\tData 3.225 (1.392)\tLoss 0.9854 (1.1227)\tPrec@1 78.12500 (68.56921)\tPrec@5 90.62500 (90.90909)\n",
            "Epoch: [11][130/231]\t lr: 0.00100\tTime 2.889 (1.687)\tData 2.551 (1.390)\tLoss 1.1364 (1.1234)\tPrec@1 68.75000 (68.63072)\tPrec@5 84.37500 (90.88741)\n",
            "Epoch: [11][140/231]\t lr: 0.00100\tTime 3.252 (1.689)\tData 2.883 (1.391)\tLoss 1.1351 (1.1238)\tPrec@1 62.50000 (68.59486)\tPrec@5 93.75000 (90.89095)\n",
            "Epoch: [11][150/231]\t lr: 0.00100\tTime 3.188 (1.691)\tData 2.897 (1.394)\tLoss 1.3075 (1.1286)\tPrec@1 71.87500 (68.62582)\tPrec@5 87.50000 (90.81126)\n",
            "Epoch: [11][160/231]\t lr: 0.00100\tTime 3.028 (1.693)\tData 2.689 (1.395)\tLoss 1.2915 (1.1312)\tPrec@1 59.37500 (68.53649)\tPrec@5 90.62500 (90.78028)\n",
            "Epoch: [11][170/231]\t lr: 0.00100\tTime 2.957 (1.691)\tData 2.617 (1.394)\tLoss 1.0905 (1.1361)\tPrec@1 68.75000 (68.38451)\tPrec@5 93.75000 (90.71638)\n",
            "Epoch: [11][180/231]\t lr: 0.00100\tTime 3.010 (1.690)\tData 2.649 (1.393)\tLoss 1.0729 (1.1337)\tPrec@1 68.75000 (68.59461)\tPrec@5 93.75000 (90.69406)\n",
            "Epoch: [11][190/231]\t lr: 0.00100\tTime 2.695 (1.689)\tData 2.366 (1.391)\tLoss 1.4801 (1.1365)\tPrec@1 56.25000 (68.50459)\tPrec@5 87.50000 (90.54320)\n",
            "Epoch: [11][200/231]\t lr: 0.00100\tTime 2.782 (1.690)\tData 2.471 (1.393)\tLoss 0.9137 (1.1389)\tPrec@1 84.37500 (68.42351)\tPrec@5 93.75000 (90.54726)\n",
            "Epoch: [11][210/231]\t lr: 0.00100\tTime 2.930 (1.691)\tData 2.527 (1.394)\tLoss 1.2120 (1.1455)\tPrec@1 65.62500 (68.26126)\tPrec@5 90.62500 (90.40285)\n",
            "Epoch: [11][220/231]\t lr: 0.00100\tTime 3.172 (1.692)\tData 2.849 (1.395)\tLoss 1.1030 (1.1485)\tPrec@1 78.12500 (68.24095)\tPrec@5 93.75000 (90.37048)\n",
            "Epoch: [11][230/231]\t lr: 0.00100\tTime 0.062 (1.673)\tData 0.000 (1.378)\tLoss 2.5753 (1.1484)\tPrec@1 50.00000 (68.31387)\tPrec@5 50.00000 (90.44257)\n",
            "validation at epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [11][1/25]\tTime 1.94657 (1.94657)\tData 1.74833 (1.74833)\tLoss 1.3985 (1.3985)\tPrec@1 56.25000 (56.25000)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [11][2/25]\tTime 0.14028 (1.04342)\tData 0.00594 (0.87713)\tLoss 0.9000 (1.1493)\tPrec@1 75.00000 (65.62500)\tPrec@5 93.75000 (90.62500)\n",
            "Epoch: [11][3/25]\tTime 1.31651 (1.13445)\tData 1.12825 (0.96084)\tLoss 0.6574 (0.9853)\tPrec@1 75.00000 (68.75000)\tPrec@5 100.00000 (93.75000)\n",
            "Epoch: [11][4/25]\tTime 0.50347 (0.97671)\tData 0.29807 (0.79515)\tLoss 1.5249 (1.1202)\tPrec@1 62.50000 (67.18750)\tPrec@5 75.00000 (89.06250)\n",
            "Epoch: [11][5/25]\tTime 1.28983 (1.03933)\tData 1.10765 (0.85765)\tLoss 0.5533 (1.0068)\tPrec@1 87.50000 (71.25000)\tPrec@5 93.75000 (90.00000)\n",
            "Epoch: [11][6/25]\tTime 0.28675 (0.91390)\tData 0.09652 (0.73079)\tLoss 1.4216 (1.0760)\tPrec@1 56.25000 (68.75000)\tPrec@5 87.50000 (89.58334)\n",
            "Epoch: [11][7/25]\tTime 1.47390 (0.99390)\tData 1.28076 (0.80936)\tLoss 1.1427 (1.0855)\tPrec@1 75.00000 (69.64286)\tPrec@5 93.75000 (90.17857)\n",
            "Epoch: [11][8/25]\tTime 0.32346 (0.91010)\tData 0.14176 (0.72591)\tLoss 1.0680 (1.0833)\tPrec@1 81.25000 (71.09375)\tPrec@5 87.50000 (89.84375)\n",
            "Epoch: [11][9/25]\tTime 1.58581 (0.98518)\tData 1.40079 (0.80090)\tLoss 0.5346 (1.0223)\tPrec@1 87.50000 (72.91666)\tPrec@5 100.00000 (90.97222)\n",
            "Epoch: [11][10/25]\tTime 0.18292 (0.90495)\tData 0.00131 (0.72094)\tLoss 1.3712 (1.0572)\tPrec@1 75.00000 (73.12500)\tPrec@5 81.25000 (90.00000)\n",
            "Epoch: [11][11/25]\tTime 1.49985 (0.95903)\tData 1.32923 (0.77624)\tLoss 1.1731 (1.0678)\tPrec@1 62.50000 (72.15910)\tPrec@5 93.75000 (90.34091)\n",
            "Epoch: [11][12/25]\tTime 0.18626 (0.89463)\tData 0.00140 (0.71167)\tLoss 1.4586 (1.1003)\tPrec@1 62.50000 (71.35417)\tPrec@5 87.50000 (90.10417)\n",
            "Epoch: [11][13/25]\tTime 1.49850 (0.94109)\tData 1.30070 (0.75698)\tLoss 0.6334 (1.0644)\tPrec@1 81.25000 (72.11539)\tPrec@5 93.75000 (90.38462)\n",
            "Epoch: [11][14/25]\tTime 0.42424 (0.90417)\tData 0.27945 (0.72287)\tLoss 0.9909 (1.0592)\tPrec@1 75.00000 (72.32143)\tPrec@5 93.75000 (90.62501)\n",
            "Epoch: [11][15/25]\tTime 1.03164 (0.91267)\tData 0.85250 (0.73151)\tLoss 1.1083 (1.0624)\tPrec@1 75.00000 (72.50000)\tPrec@5 87.50000 (90.41667)\n",
            "Epoch: [11][16/25]\tTime 0.62111 (0.89444)\tData 0.44046 (0.71332)\tLoss 1.2349 (1.0732)\tPrec@1 68.75000 (72.26562)\tPrec@5 81.25000 (89.84375)\n",
            "Epoch: [11][17/25]\tTime 1.07786 (0.90523)\tData 0.88887 (0.72365)\tLoss 1.4417 (1.0949)\tPrec@1 56.25000 (71.32353)\tPrec@5 87.50000 (89.70588)\n",
            "Epoch: [11][18/25]\tTime 0.74302 (0.89622)\tData 0.58461 (0.71592)\tLoss 1.6871 (1.1278)\tPrec@1 50.00000 (70.13889)\tPrec@5 81.25000 (89.23611)\n",
            "Epoch: [11][19/25]\tTime 1.05856 (0.90477)\tData 0.88937 (0.72505)\tLoss 1.1301 (1.1279)\tPrec@1 68.75000 (70.06579)\tPrec@5 81.25000 (88.81579)\n",
            "Epoch: [11][20/25]\tTime 0.68436 (0.89375)\tData 0.52891 (0.71524)\tLoss 1.0019 (1.1216)\tPrec@1 75.00000 (70.31250)\tPrec@5 93.75000 (89.06250)\n",
            "Epoch: [11][21/25]\tTime 0.82006 (0.89024)\tData 0.64004 (0.71166)\tLoss 1.6411 (1.1463)\tPrec@1 62.50000 (69.94048)\tPrec@5 87.50000 (88.98810)\n",
            "Epoch: [11][22/25]\tTime 0.78523 (0.88546)\tData 0.59904 (0.70654)\tLoss 1.0974 (1.1441)\tPrec@1 68.75000 (69.88637)\tPrec@5 87.50000 (88.92046)\n",
            "Epoch: [11][23/25]\tTime 0.98612 (0.88984)\tData 0.80683 (0.71090)\tLoss 1.5225 (1.1606)\tPrec@1 56.25000 (69.29348)\tPrec@5 75.00000 (88.31522)\n",
            "Epoch: [11][24/25]\tTime 0.46861 (0.87229)\tData 0.37132 (0.69676)\tLoss 1.0595 (1.1564)\tPrec@1 68.75000 (69.27084)\tPrec@5 87.50000 (88.28125)\n",
            "Epoch: [11][25/25]\tTime 0.05844 (0.83974)\tData 0.00108 (0.66893)\tLoss 2.1890 (1.1670)\tPrec@1 50.00000 (69.07217)\tPrec@5 50.00000 (87.88660)\n",
            "train at epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [12][0/231]\t lr: 0.00100\tTime 3.859 (3.859)\tData 3.509 (3.509)\tLoss 0.9095 (0.9095)\tPrec@1 75.00000 (75.00000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [12][10/231]\t lr: 0.00100\tTime 2.938 (1.856)\tData 2.587 (1.567)\tLoss 1.1382 (1.2371)\tPrec@1 75.00000 (66.47727)\tPrec@5 87.50000 (88.06818)\n",
            "Epoch: [12][20/231]\t lr: 0.00100\tTime 2.233 (1.758)\tData 1.880 (1.459)\tLoss 0.8898 (1.1598)\tPrec@1 78.12500 (68.89881)\tPrec@5 93.75000 (88.98810)\n",
            "Epoch: [12][30/231]\t lr: 0.00100\tTime 2.625 (1.752)\tData 2.274 (1.456)\tLoss 1.4315 (1.1909)\tPrec@1 56.25000 (67.33871)\tPrec@5 90.62500 (89.31451)\n",
            "Epoch: [12][40/231]\t lr: 0.00100\tTime 1.834 (1.719)\tData 1.598 (1.430)\tLoss 1.2309 (1.1541)\tPrec@1 65.62500 (68.52134)\tPrec@5 87.50000 (89.93902)\n",
            "Epoch: [12][50/231]\t lr: 0.00100\tTime 0.998 (1.698)\tData 0.766 (1.413)\tLoss 1.0717 (1.1553)\tPrec@1 62.50000 (67.95343)\tPrec@5 96.87500 (90.01226)\n",
            "Epoch: [12][60/231]\t lr: 0.00100\tTime 0.828 (1.695)\tData 0.619 (1.408)\tLoss 1.3737 (1.1551)\tPrec@1 68.75000 (67.98155)\tPrec@5 87.50000 (89.85655)\n",
            "Epoch: [12][70/231]\t lr: 0.00100\tTime 1.054 (1.693)\tData 0.822 (1.404)\tLoss 1.3012 (1.1430)\tPrec@1 59.37500 (68.66197)\tPrec@5 90.62500 (90.05282)\n",
            "Epoch: [12][80/231]\t lr: 0.00100\tTime 1.305 (1.693)\tData 1.084 (1.404)\tLoss 1.0861 (1.1384)\tPrec@1 68.75000 (68.75000)\tPrec@5 90.62500 (90.20061)\n",
            "Epoch: [12][90/231]\t lr: 0.00100\tTime 2.072 (1.698)\tData 1.711 (1.407)\tLoss 1.1603 (1.1488)\tPrec@1 62.50000 (68.23489)\tPrec@5 90.62500 (90.00687)\n",
            "Epoch: [12][100/231]\t lr: 0.00100\tTime 2.336 (1.699)\tData 1.993 (1.410)\tLoss 0.7129 (1.1441)\tPrec@1 71.87500 (68.25495)\tPrec@5 96.87500 (90.31559)\n",
            "Epoch: [12][110/231]\t lr: 0.00100\tTime 2.719 (1.697)\tData 2.402 (1.407)\tLoss 1.4944 (1.1534)\tPrec@1 56.25000 (67.82095)\tPrec@5 81.25000 (90.17455)\n",
            "Epoch: [12][120/231]\t lr: 0.00100\tTime 2.697 (1.699)\tData 2.381 (1.408)\tLoss 1.5101 (1.1559)\tPrec@1 65.62500 (68.00103)\tPrec@5 84.37500 (90.10847)\n",
            "Epoch: [12][130/231]\t lr: 0.00100\tTime 2.817 (1.696)\tData 2.482 (1.404)\tLoss 0.7010 (1.1543)\tPrec@1 78.12500 (68.08206)\tPrec@5 90.62500 (90.07634)\n",
            "Epoch: [12][140/231]\t lr: 0.00100\tTime 3.010 (1.698)\tData 2.683 (1.406)\tLoss 1.3877 (1.1560)\tPrec@1 62.50000 (67.97429)\tPrec@5 84.37500 (90.09308)\n",
            "Epoch: [12][150/231]\t lr: 0.00100\tTime 2.889 (1.693)\tData 2.552 (1.400)\tLoss 1.5011 (1.1542)\tPrec@1 46.87500 (67.86010)\tPrec@5 90.62500 (90.16970)\n",
            "Epoch: [12][160/231]\t lr: 0.00100\tTime 3.603 (1.693)\tData 3.230 (1.401)\tLoss 1.2304 (1.1515)\tPrec@1 59.37500 (67.91537)\tPrec@5 90.62500 (90.19798)\n",
            "Epoch: [12][170/231]\t lr: 0.00100\tTime 2.970 (1.693)\tData 2.654 (1.401)\tLoss 1.2496 (1.1504)\tPrec@1 68.75000 (67.89108)\tPrec@5 87.50000 (90.29605)\n",
            "Epoch: [12][180/231]\t lr: 0.00100\tTime 3.206 (1.696)\tData 2.851 (1.404)\tLoss 1.6751 (1.1509)\tPrec@1 71.87500 (68.07666)\tPrec@5 90.62500 (90.29697)\n",
            "Epoch: [12][190/231]\t lr: 0.00100\tTime 2.890 (1.695)\tData 2.605 (1.403)\tLoss 1.5841 (1.1591)\tPrec@1 50.00000 (67.80105)\tPrec@5 84.37500 (90.16689)\n",
            "Epoch: [12][200/231]\t lr: 0.00100\tTime 2.891 (1.696)\tData 2.526 (1.405)\tLoss 1.3922 (1.1561)\tPrec@1 56.25000 (67.87935)\tPrec@5 90.62500 (90.29851)\n",
            "Epoch: [12][210/231]\t lr: 0.00100\tTime 3.126 (1.698)\tData 2.821 (1.407)\tLoss 1.7724 (1.1657)\tPrec@1 53.12500 (67.62441)\tPrec@5 78.12500 (90.16588)\n",
            "Epoch: [12][220/231]\t lr: 0.00100\tTime 3.204 (1.698)\tData 2.880 (1.407)\tLoss 0.6882 (1.1672)\tPrec@1 84.37500 (67.51980)\tPrec@5 100.00000 (90.13010)\n",
            "Epoch: [12][230/231]\t lr: 0.00100\tTime 0.071 (1.678)\tData 0.000 (1.389)\tLoss 2.6924 (1.1671)\tPrec@1 16.66667 (67.47217)\tPrec@5 66.66666 (90.04887)\n",
            "validation at epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [12][1/25]\tTime 2.18399 (2.18399)\tData 1.99388 (1.99388)\tLoss 1.0105 (1.0105)\tPrec@1 68.75000 (68.75000)\tPrec@5 93.75000 (93.75000)\n",
            "Epoch: [12][2/25]\tTime 0.19580 (1.18990)\tData 0.00163 (0.99775)\tLoss 1.1943 (1.1024)\tPrec@1 62.50000 (65.62500)\tPrec@5 87.50000 (90.62500)\n",
            "Epoch: [12][3/25]\tTime 1.73769 (1.37249)\tData 1.54061 (1.17871)\tLoss 0.6737 (0.9595)\tPrec@1 87.50000 (72.91667)\tPrec@5 93.75000 (91.66667)\n",
            "Epoch: [12][4/25]\tTime 0.11713 (1.05865)\tData 0.00950 (0.88640)\tLoss 0.7851 (0.9159)\tPrec@1 75.00000 (73.43750)\tPrec@5 100.00000 (93.75000)\n",
            "Epoch: [12][5/25]\tTime 1.78956 (1.20483)\tData 1.58373 (1.02587)\tLoss 1.3813 (1.0090)\tPrec@1 68.75000 (72.50000)\tPrec@5 81.25000 (91.25000)\n",
            "Epoch: [12][6/25]\tTime 0.16018 (1.03073)\tData 0.00130 (0.85511)\tLoss 0.7966 (0.9736)\tPrec@1 87.50000 (75.00000)\tPrec@5 93.75000 (91.66667)\n",
            "Epoch: [12][7/25]\tTime 1.57091 (1.10790)\tData 1.39194 (0.93180)\tLoss 0.7335 (0.9393)\tPrec@1 81.25000 (75.89286)\tPrec@5 93.75000 (91.96429)\n",
            "Epoch: [12][8/25]\tTime 0.19798 (0.99416)\tData 0.00454 (0.81589)\tLoss 1.0136 (0.9486)\tPrec@1 68.75000 (75.00000)\tPrec@5 87.50000 (91.40625)\n",
            "Epoch: [12][9/25]\tTime 1.63480 (1.06534)\tData 1.48114 (0.88981)\tLoss 1.5054 (1.0105)\tPrec@1 62.50000 (73.61111)\tPrec@5 81.25000 (90.27778)\n",
            "Epoch: [12][10/25]\tTime 0.13597 (0.97240)\tData 0.00134 (0.80096)\tLoss 0.9600 (1.0054)\tPrec@1 75.00000 (73.75000)\tPrec@5 87.50000 (90.00000)\n",
            "Epoch: [12][11/25]\tTime 1.45985 (1.01671)\tData 1.25916 (0.84262)\tLoss 0.7830 (0.9852)\tPrec@1 81.25000 (74.43182)\tPrec@5 93.75000 (90.34091)\n",
            "Epoch: [12][12/25]\tTime 0.18890 (0.94773)\tData 0.00747 (0.77302)\tLoss 1.3110 (1.0123)\tPrec@1 56.25000 (72.91667)\tPrec@5 87.50000 (90.10417)\n",
            "Epoch: [12][13/25]\tTime 1.45866 (0.98703)\tData 1.30052 (0.81360)\tLoss 1.3215 (1.0361)\tPrec@1 62.50000 (72.11539)\tPrec@5 75.00000 (88.94231)\n",
            "Epoch: [12][14/25]\tTime 0.20046 (0.93085)\tData 0.00587 (0.75590)\tLoss 1.7814 (1.0894)\tPrec@1 62.50000 (71.42857)\tPrec@5 75.00000 (87.94643)\n",
            "Epoch: [12][15/25]\tTime 1.60965 (0.97610)\tData 1.43126 (0.80093)\tLoss 0.8700 (1.0747)\tPrec@1 93.75000 (72.91667)\tPrec@5 93.75000 (88.33334)\n",
            "Epoch: [12][16/25]\tTime 0.13297 (0.92341)\tData 0.00678 (0.75129)\tLoss 1.1067 (1.0767)\tPrec@1 68.75000 (72.65625)\tPrec@5 87.50000 (88.28125)\n",
            "Epoch: [12][17/25]\tTime 1.84583 (0.97767)\tData 1.64881 (0.80409)\tLoss 1.4414 (1.0982)\tPrec@1 62.50000 (72.05882)\tPrec@5 81.25000 (87.86765)\n",
            "Epoch: [12][18/25]\tTime 0.21661 (0.93539)\tData 0.00695 (0.75980)\tLoss 1.4098 (1.1155)\tPrec@1 62.50000 (71.52778)\tPrec@5 87.50000 (87.84722)\n",
            "Epoch: [12][19/25]\tTime 1.60161 (0.97045)\tData 1.41002 (0.79402)\tLoss 0.6439 (1.0907)\tPrec@1 87.50000 (72.36842)\tPrec@5 100.00000 (88.48684)\n",
            "Epoch: [12][20/25]\tTime 0.18444 (0.93115)\tData 0.00853 (0.75475)\tLoss 1.3334 (1.1028)\tPrec@1 62.50000 (71.87500)\tPrec@5 87.50000 (88.43750)\n",
            "Epoch: [12][21/25]\tTime 1.51520 (0.95896)\tData 1.32883 (0.78209)\tLoss 0.9889 (1.0974)\tPrec@1 75.00000 (72.02381)\tPrec@5 87.50000 (88.39286)\n",
            "Epoch: [12][22/25]\tTime 0.19317 (0.92415)\tData 0.00692 (0.74685)\tLoss 1.0329 (1.0945)\tPrec@1 68.75000 (71.87500)\tPrec@5 87.50000 (88.35227)\n",
            "Epoch: [12][23/25]\tTime 1.22445 (0.93721)\tData 1.09852 (0.76214)\tLoss 2.0410 (1.1356)\tPrec@1 50.00000 (70.92391)\tPrec@5 68.75000 (87.50000)\n",
            "Epoch: [12][24/25]\tTime 0.12089 (0.90320)\tData 0.00108 (0.73043)\tLoss 1.7309 (1.1604)\tPrec@1 50.00000 (70.05209)\tPrec@5 93.75000 (87.76042)\n",
            "Epoch: [12][25/25]\tTime 0.12218 (0.87196)\tData 0.05798 (0.70353)\tLoss 3.6178 (1.1857)\tPrec@1 25.00000 (69.58762)\tPrec@5 50.00000 (87.37113)\n",
            "train at epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [13][0/231]\t lr: 0.00100\tTime 3.470 (3.470)\tData 3.121 (3.121)\tLoss 1.2517 (1.2517)\tPrec@1 59.37500 (59.37500)\tPrec@5 87.50000 (87.50000)\n",
            "Epoch: [13][10/231]\t lr: 0.00100\tTime 2.660 (1.845)\tData 2.261 (1.551)\tLoss 1.3593 (1.2386)\tPrec@1 59.37500 (66.19318)\tPrec@5 84.37500 (88.35227)\n",
            "Epoch: [13][20/231]\t lr: 0.00100\tTime 2.710 (1.772)\tData 2.322 (1.470)\tLoss 1.4534 (1.2031)\tPrec@1 65.62500 (66.66666)\tPrec@5 87.50000 (89.58334)\n",
            "Epoch: [13][30/231]\t lr: 0.00100\tTime 2.187 (1.721)\tData 1.833 (1.425)\tLoss 1.3210 (1.1985)\tPrec@1 62.50000 (67.43951)\tPrec@5 87.50000 (89.31451)\n",
            "Epoch: [13][40/231]\t lr: 0.00100\tTime 1.733 (1.702)\tData 1.480 (1.414)\tLoss 0.9369 (1.1755)\tPrec@1 78.12500 (67.75914)\tPrec@5 93.75000 (89.40549)\n",
            "Epoch: [13][50/231]\t lr: 0.00100\tTime 3.029 (1.712)\tData 2.707 (1.420)\tLoss 1.0578 (1.1827)\tPrec@1 71.87500 (67.03432)\tPrec@5 87.50000 (89.52206)\n",
            "Epoch: [13][60/231]\t lr: 0.00100\tTime 2.503 (1.696)\tData 2.186 (1.402)\tLoss 1.1544 (1.1785)\tPrec@1 81.25000 (67.62295)\tPrec@5 87.50000 (89.60040)\n",
            "Epoch: [13][70/231]\t lr: 0.00100\tTime 3.178 (1.695)\tData 2.818 (1.402)\tLoss 0.8971 (1.1719)\tPrec@1 68.75000 (67.86972)\tPrec@5 100.00000 (89.70070)\n",
            "Epoch: [13][80/231]\t lr: 0.00100\tTime 2.350 (1.683)\tData 1.968 (1.391)\tLoss 1.2009 (1.1801)\tPrec@1 75.00000 (67.47685)\tPrec@5 84.37500 (89.69907)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiQIMP1UPFgh",
        "outputId": "dc302bc6-0d9a-4d97-85d3-e0342841db19"
      },
      "source": [
        "test(test_loader, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/203]\tTime 2.09938 (2.09938)\tData 1.84501 (1.84501)\tLoss 0.1146 (0.1146)\tPrec@1 100.00000 (100.00000)\tPrec@5 100.00000 (100.00000)\n",
            "[2/203]\tTime 0.20091 (1.15014)\tData 0.01170 (0.92835)\tLoss 0.7601 (0.4373)\tPrec@1 93.75000 (96.87500)\tPrec@5 100.00000 (100.00000)\n",
            "[3/203]\tTime 1.35848 (1.21959)\tData 1.16585 (1.00752)\tLoss 1.4729 (0.7825)\tPrec@1 62.50000 (85.41667)\tPrec@5 68.75000 (89.58334)\n",
            "[4/203]\tTime 0.14888 (0.95191)\tData 0.00148 (0.75601)\tLoss 4.2379 (1.6464)\tPrec@1 18.75000 (68.75000)\tPrec@5 25.00000 (73.43750)\n",
            "[5/203]\tTime 1.49552 (1.06063)\tData 1.31444 (0.86769)\tLoss 3.3013 (1.9774)\tPrec@1 37.50000 (62.50000)\tPrec@5 37.50000 (66.25000)\n",
            "[6/203]\tTime 0.19410 (0.91621)\tData 0.00146 (0.72332)\tLoss 2.1286 (2.0026)\tPrec@1 50.00000 (60.41667)\tPrec@5 68.75000 (66.66667)\n",
            "[7/203]\tTime 1.69205 (1.02704)\tData 1.54209 (0.84029)\tLoss 6.4670 (2.6403)\tPrec@1 12.50000 (53.57143)\tPrec@5 12.50000 (58.92857)\n",
            "[8/203]\tTime 0.19977 (0.92364)\tData 0.00840 (0.73630)\tLoss 5.4991 (2.9977)\tPrec@1 0.00000 (46.87500)\tPrec@5 25.00000 (54.68750)\n",
            "[9/203]\tTime 1.44931 (0.98204)\tData 1.27467 (0.79612)\tLoss 1.2657 (2.8052)\tPrec@1 50.00000 (47.22222)\tPrec@5 93.75000 (59.02778)\n",
            "[10/203]\tTime 0.20025 (0.90386)\tData 0.00297 (0.71681)\tLoss 0.7235 (2.5971)\tPrec@1 81.25000 (50.62500)\tPrec@5 93.75000 (62.50000)\n",
            "[11/203]\tTime 1.24878 (0.93522)\tData 1.06559 (0.74851)\tLoss 1.3839 (2.4868)\tPrec@1 50.00000 (50.56818)\tPrec@5 87.50000 (64.77273)\n",
            "[12/203]\tTime 0.16520 (0.87105)\tData 0.00136 (0.68625)\tLoss 2.1510 (2.4588)\tPrec@1 18.75000 (47.91667)\tPrec@5 87.50000 (66.66667)\n",
            "[13/203]\tTime 1.07531 (0.88676)\tData 0.94539 (0.70619)\tLoss 1.6240 (2.3946)\tPrec@1 37.50000 (47.11539)\tPrec@5 87.50000 (68.26923)\n",
            "[14/203]\tTime 0.13828 (0.83330)\tData 0.00134 (0.65584)\tLoss 2.0179 (2.3677)\tPrec@1 50.00000 (47.32143)\tPrec@5 75.00000 (68.75000)\n",
            "[15/203]\tTime 0.87496 (0.83608)\tData 0.71682 (0.65990)\tLoss 1.2664 (2.2943)\tPrec@1 68.75000 (48.75000)\tPrec@5 93.75000 (70.41667)\n",
            "[16/203]\tTime 0.16765 (0.79430)\tData 0.00134 (0.61874)\tLoss 2.0901 (2.2815)\tPrec@1 25.00000 (47.26562)\tPrec@5 93.75000 (71.87500)\n",
            "[17/203]\tTime 0.96866 (0.80456)\tData 0.81305 (0.63017)\tLoss 1.7675 (2.2513)\tPrec@1 37.50000 (46.69118)\tPrec@5 75.00000 (72.05882)\n",
            "[18/203]\tTime 0.20560 (0.77128)\tData 0.00124 (0.59523)\tLoss 1.7842 (2.2253)\tPrec@1 43.75000 (46.52778)\tPrec@5 81.25000 (72.56944)\n",
            "[19/203]\tTime 1.25917 (0.79696)\tData 1.07278 (0.62037)\tLoss 1.9664 (2.2117)\tPrec@1 50.00000 (46.71053)\tPrec@5 68.75000 (72.36842)\n",
            "[20/203]\tTime 0.18512 (0.76637)\tData 0.00911 (0.58980)\tLoss 1.5522 (2.1787)\tPrec@1 25.00000 (45.62500)\tPrec@5 100.00000 (73.75000)\n",
            "[21/203]\tTime 1.01523 (0.77822)\tData 0.84053 (0.60174)\tLoss 1.7693 (2.1592)\tPrec@1 43.75000 (45.53572)\tPrec@5 93.75000 (74.70238)\n",
            "[22/203]\tTime 0.17618 (0.75085)\tData 0.00163 (0.57447)\tLoss 2.3897 (2.1697)\tPrec@1 12.50000 (44.03409)\tPrec@5 81.25000 (75.00000)\n",
            "[23/203]\tTime 0.99300 (0.76138)\tData 0.84458 (0.58621)\tLoss 2.9853 (2.2052)\tPrec@1 12.50000 (42.66304)\tPrec@5 62.50000 (74.45652)\n",
            "[24/203]\tTime 0.12078 (0.73469)\tData 0.00133 (0.56184)\tLoss 2.6875 (2.2253)\tPrec@1 31.25000 (42.18750)\tPrec@5 75.00000 (74.47917)\n",
            "[25/203]\tTime 1.27974 (0.75649)\tData 1.10921 (0.58373)\tLoss 1.3193 (2.1890)\tPrec@1 68.75000 (43.25000)\tPrec@5 75.00000 (74.50000)\n",
            "[26/203]\tTime 0.14681 (0.73304)\tData 0.01138 (0.56172)\tLoss 0.6073 (2.1282)\tPrec@1 87.50000 (44.95192)\tPrec@5 100.00000 (75.48077)\n",
            "[27/203]\tTime 1.24039 (0.75183)\tData 1.03717 (0.57933)\tLoss 1.2332 (2.0950)\tPrec@1 68.75000 (45.83333)\tPrec@5 81.25000 (75.69444)\n",
            "[28/203]\tTime 0.18609 (0.73163)\tData 0.00141 (0.55869)\tLoss 1.7577 (2.0830)\tPrec@1 56.25000 (46.20536)\tPrec@5 81.25000 (75.89286)\n",
            "[29/203]\tTime 1.42694 (0.75560)\tData 1.25914 (0.58284)\tLoss 4.7239 (2.1741)\tPrec@1 0.00000 (44.61207)\tPrec@5 31.25000 (74.35345)\n",
            "[30/203]\tTime 0.17548 (0.73627)\tData 0.00207 (0.56348)\tLoss 2.3669 (2.1805)\tPrec@1 18.75000 (43.75000)\tPrec@5 81.25000 (74.58334)\n",
            "[31/203]\tTime 1.02841 (0.74569)\tData 0.83023 (0.57209)\tLoss 1.1040 (2.1458)\tPrec@1 68.75000 (44.55645)\tPrec@5 93.75000 (75.20161)\n",
            "[32/203]\tTime 0.19380 (0.72844)\tData 0.00147 (0.55426)\tLoss 1.8610 (2.1369)\tPrec@1 50.00000 (44.72656)\tPrec@5 81.25000 (75.39062)\n",
            "[33/203]\tTime 1.05433 (0.73832)\tData 0.91520 (0.56520)\tLoss 2.3456 (2.1432)\tPrec@1 43.75000 (44.69697)\tPrec@5 62.50000 (75.00000)\n",
            "[34/203]\tTime 0.15898 (0.72128)\tData 0.00783 (0.54880)\tLoss 2.5983 (2.1566)\tPrec@1 25.00000 (44.11765)\tPrec@5 56.25000 (74.44853)\n",
            "[35/203]\tTime 1.04734 (0.73060)\tData 0.83592 (0.55701)\tLoss 3.2118 (2.1867)\tPrec@1 18.75000 (43.39286)\tPrec@5 68.75000 (74.28571)\n",
            "[36/203]\tTime 0.16103 (0.71478)\tData 0.00125 (0.54157)\tLoss 3.7872 (2.2312)\tPrec@1 12.50000 (42.53472)\tPrec@5 43.75000 (73.43750)\n",
            "[37/203]\tTime 1.05513 (0.72397)\tData 0.91928 (0.55178)\tLoss 2.7977 (2.2465)\tPrec@1 31.25000 (42.22973)\tPrec@5 56.25000 (72.97298)\n",
            "[38/203]\tTime 0.23412 (0.71108)\tData 0.00125 (0.53729)\tLoss 2.0841 (2.2422)\tPrec@1 25.00000 (41.77632)\tPrec@5 87.50000 (73.35526)\n",
            "[39/203]\tTime 1.07176 (0.72033)\tData 0.88099 (0.54610)\tLoss 3.0954 (2.2641)\tPrec@1 6.25000 (40.86539)\tPrec@5 81.25000 (73.55769)\n",
            "[40/203]\tTime 0.21759 (0.70776)\tData 0.00135 (0.53248)\tLoss 3.1422 (2.2860)\tPrec@1 25.00000 (40.46875)\tPrec@5 56.25000 (73.12500)\n",
            "[41/203]\tTime 0.75128 (0.70882)\tData 0.55246 (0.53297)\tLoss 2.7212 (2.2967)\tPrec@1 37.50000 (40.39634)\tPrec@5 50.00000 (72.56097)\n",
            "[42/203]\tTime 0.18557 (0.69637)\tData 0.00783 (0.52047)\tLoss 0.5146 (2.2542)\tPrec@1 81.25000 (41.36905)\tPrec@5 87.50000 (72.91667)\n",
            "[43/203]\tTime 1.20670 (0.70823)\tData 1.01311 (0.53192)\tLoss 0.4138 (2.2114)\tPrec@1 93.75000 (42.58721)\tPrec@5 93.75000 (73.40116)\n",
            "[44/203]\tTime 0.16654 (0.69592)\tData 0.00141 (0.51987)\tLoss 1.1268 (2.1868)\tPrec@1 62.50000 (43.03978)\tPrec@5 93.75000 (73.86364)\n",
            "[45/203]\tTime 0.95728 (0.70173)\tData 0.80274 (0.52615)\tLoss 1.2807 (2.1666)\tPrec@1 68.75000 (43.61111)\tPrec@5 93.75000 (74.30556)\n",
            "[46/203]\tTime 0.13748 (0.68946)\tData 0.00177 (0.51475)\tLoss 2.5967 (2.1760)\tPrec@1 6.25000 (42.79891)\tPrec@5 75.00000 (74.32066)\n",
            "[47/203]\tTime 1.34217 (0.70335)\tData 1.13793 (0.52801)\tLoss 3.3503 (2.2010)\tPrec@1 0.00000 (41.88830)\tPrec@5 56.25000 (73.93616)\n",
            "[48/203]\tTime 0.18099 (0.69247)\tData 0.00599 (0.51714)\tLoss 2.1955 (2.2009)\tPrec@1 12.50000 (41.27604)\tPrec@5 93.75000 (74.34896)\n",
            "[49/203]\tTime 1.23502 (0.70354)\tData 1.02326 (0.52747)\tLoss 2.5056 (2.2071)\tPrec@1 18.75000 (40.81633)\tPrec@5 68.75000 (74.23470)\n",
            "[50/203]\tTime 0.23598 (0.69419)\tData 0.00885 (0.51709)\tLoss 2.3351 (2.2096)\tPrec@1 31.25000 (40.62500)\tPrec@5 68.75000 (74.12500)\n",
            "[51/203]\tTime 1.17855 (0.70369)\tData 0.99815 (0.52653)\tLoss 2.1366 (2.2082)\tPrec@1 37.50000 (40.56373)\tPrec@5 75.00000 (74.14216)\n",
            "[52/203]\tTime 0.18490 (0.69371)\tData 0.00143 (0.51643)\tLoss 2.0408 (2.2050)\tPrec@1 25.00000 (40.26442)\tPrec@5 81.25000 (74.27885)\n",
            "[53/203]\tTime 1.24019 (0.70402)\tData 1.09558 (0.52736)\tLoss 2.2134 (2.2052)\tPrec@1 25.00000 (39.97642)\tPrec@5 68.75000 (74.17453)\n",
            "[54/203]\tTime 0.12759 (0.69335)\tData 0.00136 (0.51761)\tLoss 3.8522 (2.2357)\tPrec@1 6.25000 (39.35185)\tPrec@5 25.00000 (73.26389)\n",
            "[55/203]\tTime 1.04759 (0.69979)\tData 0.94550 (0.52539)\tLoss 3.7205 (2.2626)\tPrec@1 6.25000 (38.75000)\tPrec@5 25.00000 (72.38636)\n",
            "[56/203]\tTime 0.16489 (0.69024)\tData 0.00147 (0.51604)\tLoss 1.7864 (2.2541)\tPrec@1 56.25000 (39.06250)\tPrec@5 75.00000 (72.43304)\n",
            "[57/203]\tTime 1.09295 (0.69730)\tData 0.95321 (0.52371)\tLoss 3.8135 (2.2815)\tPrec@1 18.75000 (38.70614)\tPrec@5 43.75000 (71.92982)\n",
            "[58/203]\tTime 0.20833 (0.68887)\tData 0.00912 (0.51484)\tLoss 2.2026 (2.2801)\tPrec@1 43.75000 (38.79310)\tPrec@5 62.50000 (71.76724)\n",
            "[59/203]\tTime 0.95135 (0.69332)\tData 0.76590 (0.51909)\tLoss 1.6714 (2.2698)\tPrec@1 37.50000 (38.77119)\tPrec@5 87.50000 (72.03390)\n",
            "[60/203]\tTime 0.18588 (0.68486)\tData 0.00135 (0.51046)\tLoss 1.6533 (2.2595)\tPrec@1 43.75000 (38.85417)\tPrec@5 81.25000 (72.18750)\n",
            "[61/203]\tTime 0.80834 (0.68689)\tData 0.63827 (0.51256)\tLoss 1.5354 (2.2477)\tPrec@1 43.75000 (38.93443)\tPrec@5 93.75000 (72.54098)\n",
            "[62/203]\tTime 0.21725 (0.67931)\tData 0.00135 (0.50431)\tLoss 1.1209 (2.2295)\tPrec@1 75.00000 (39.51613)\tPrec@5 93.75000 (72.88306)\n",
            "[63/203]\tTime 1.17866 (0.68724)\tData 0.99238 (0.51206)\tLoss 0.3790 (2.2001)\tPrec@1 87.50000 (40.27778)\tPrec@5 100.00000 (73.31350)\n",
            "[64/203]\tTime 0.18725 (0.67943)\tData 0.00116 (0.50408)\tLoss 0.1744 (2.1685)\tPrec@1 93.75000 (41.11328)\tPrec@5 100.00000 (73.73047)\n",
            "[65/203]\tTime 0.89608 (0.68276)\tData 0.70378 (0.50715)\tLoss 2.6083 (2.1752)\tPrec@1 12.50000 (40.67308)\tPrec@5 75.00000 (73.75000)\n",
            "[66/203]\tTime 0.17407 (0.67505)\tData 0.00155 (0.49949)\tLoss 2.0986 (2.1741)\tPrec@1 31.25000 (40.53030)\tPrec@5 93.75000 (74.05303)\n",
            "[67/203]\tTime 1.11265 (0.68158)\tData 0.96641 (0.50646)\tLoss 1.3322 (2.1615)\tPrec@1 50.00000 (40.67164)\tPrec@5 100.00000 (74.44030)\n",
            "[68/203]\tTime 0.14631 (0.67371)\tData 0.00142 (0.49903)\tLoss 2.0552 (2.1600)\tPrec@1 25.00000 (40.44118)\tPrec@5 81.25000 (74.54044)\n",
            "[69/203]\tTime 0.97217 (0.67804)\tData 0.81653 (0.50363)\tLoss 2.7968 (2.1692)\tPrec@1 25.00000 (40.21739)\tPrec@5 50.00000 (74.18478)\n",
            "[70/203]\tTime 0.19264 (0.67110)\tData 0.00170 (0.49646)\tLoss 4.0136 (2.1955)\tPrec@1 0.00000 (39.64286)\tPrec@5 25.00000 (73.48214)\n",
            "[71/203]\tTime 0.98155 (0.67547)\tData 0.78333 (0.50050)\tLoss 4.5764 (2.2291)\tPrec@1 0.00000 (39.08451)\tPrec@5 12.50000 (72.62324)\n",
            "[72/203]\tTime 0.23445 (0.66935)\tData 0.00866 (0.49367)\tLoss 1.8301 (2.2235)\tPrec@1 62.50000 (39.40972)\tPrec@5 87.50000 (72.82986)\n",
            "[73/203]\tTime 0.86798 (0.67207)\tData 0.70500 (0.49657)\tLoss 0.6887 (2.2025)\tPrec@1 81.25000 (39.98288)\tPrec@5 87.50000 (73.03082)\n",
            "[74/203]\tTime 0.17998 (0.66542)\tData 0.00166 (0.48988)\tLoss 4.0915 (2.2280)\tPrec@1 12.50000 (39.61149)\tPrec@5 37.50000 (72.55067)\n",
            "[75/203]\tTime 0.82124 (0.66750)\tData 0.65989 (0.49214)\tLoss 2.5082 (2.2318)\tPrec@1 25.00000 (39.41667)\tPrec@5 75.00000 (72.58334)\n",
            "[76/203]\tTime 0.21095 (0.66149)\tData 0.00139 (0.48569)\tLoss 3.8587 (2.2532)\tPrec@1 0.00000 (38.89803)\tPrec@5 43.75000 (72.20395)\n",
            "[77/203]\tTime 0.87517 (0.66427)\tData 0.66970 (0.48808)\tLoss 3.7785 (2.2730)\tPrec@1 18.75000 (38.63636)\tPrec@5 37.50000 (71.75325)\n",
            "[78/203]\tTime 0.19070 (0.65819)\tData 0.00833 (0.48193)\tLoss 2.2915 (2.2732)\tPrec@1 43.75000 (38.70192)\tPrec@5 68.75000 (71.71474)\n",
            "[79/203]\tTime 1.02472 (0.66283)\tData 0.87394 (0.48689)\tLoss 3.9684 (2.2947)\tPrec@1 18.75000 (38.44937)\tPrec@5 50.00000 (71.43987)\n",
            "[80/203]\tTime 0.12589 (0.65612)\tData 0.00136 (0.48082)\tLoss 0.9673 (2.2781)\tPrec@1 68.75000 (38.82812)\tPrec@5 93.75000 (71.71875)\n",
            "[81/203]\tTime 1.14457 (0.66215)\tData 0.93771 (0.48646)\tLoss 1.0560 (2.2630)\tPrec@1 62.50000 (39.12037)\tPrec@5 100.00000 (72.06790)\n",
            "[82/203]\tTime 0.19411 (0.65644)\tData 0.00706 (0.48061)\tLoss 1.8862 (2.2584)\tPrec@1 37.50000 (39.10061)\tPrec@5 81.25000 (72.17988)\n",
            "[83/203]\tTime 1.42796 (0.66574)\tData 1.23281 (0.48968)\tLoss 3.6669 (2.2754)\tPrec@1 18.75000 (38.85542)\tPrec@5 43.75000 (71.83735)\n",
            "[84/203]\tTime 0.21161 (0.66033)\tData 0.00161 (0.48387)\tLoss 2.1358 (2.2737)\tPrec@1 56.25000 (39.06250)\tPrec@5 68.75000 (71.80060)\n",
            "[85/203]\tTime 1.45657 (0.66970)\tData 1.31517 (0.49365)\tLoss 1.0626 (2.2595)\tPrec@1 75.00000 (39.48529)\tPrec@5 100.00000 (72.13235)\n",
            "[86/203]\tTime 0.21544 (0.66442)\tData 0.00211 (0.48793)\tLoss 1.5381 (2.2511)\tPrec@1 68.75000 (39.82558)\tPrec@5 93.75000 (72.38372)\n",
            "[87/203]\tTime 1.14718 (0.66997)\tData 0.93848 (0.49311)\tLoss 1.8144 (2.2461)\tPrec@1 56.25000 (40.01437)\tPrec@5 75.00000 (72.41380)\n",
            "[88/203]\tTime 0.11939 (0.66371)\tData 0.00138 (0.48752)\tLoss 3.8710 (2.2645)\tPrec@1 6.25000 (39.63068)\tPrec@5 37.50000 (72.01704)\n",
            "[89/203]\tTime 1.45994 (0.67266)\tData 1.23923 (0.49597)\tLoss 2.0427 (2.2620)\tPrec@1 0.00000 (39.18539)\tPrec@5 93.75000 (72.26124)\n",
            "[90/203]\tTime 0.23948 (0.66784)\tData 0.00137 (0.49047)\tLoss 0.8733 (2.2466)\tPrec@1 68.75000 (39.51389)\tPrec@5 100.00000 (72.56944)\n",
            "[91/203]\tTime 0.96344 (0.67109)\tData 0.81115 (0.49400)\tLoss 2.4451 (2.2488)\tPrec@1 31.25000 (39.42308)\tPrec@5 75.00000 (72.59615)\n",
            "[92/203]\tTime 0.15377 (0.66547)\tData 0.00136 (0.48864)\tLoss 0.7457 (2.2324)\tPrec@1 75.00000 (39.80978)\tPrec@5 100.00000 (72.89402)\n",
            "[93/203]\tTime 1.21153 (0.67134)\tData 1.07106 (0.49490)\tLoss 0.3817 (2.2125)\tPrec@1 93.75000 (40.38979)\tPrec@5 100.00000 (73.18549)\n",
            "[94/203]\tTime 0.15318 (0.66583)\tData 0.00181 (0.48966)\tLoss 1.3548 (2.2034)\tPrec@1 62.50000 (40.62500)\tPrec@5 81.25000 (73.27127)\n",
            "[95/203]\tTime 1.35139 (0.67305)\tData 1.16839 (0.49680)\tLoss 2.4029 (2.2055)\tPrec@1 12.50000 (40.32895)\tPrec@5 68.75000 (73.22369)\n",
            "[96/203]\tTime 0.23295 (0.66846)\tData 0.00172 (0.49165)\tLoss 3.3873 (2.2178)\tPrec@1 12.50000 (40.03906)\tPrec@5 81.25000 (73.30730)\n",
            "[97/203]\tTime 1.01821 (0.67207)\tData 0.82734 (0.49511)\tLoss 4.0199 (2.2364)\tPrec@1 6.25000 (39.69072)\tPrec@5 37.50000 (72.93814)\n",
            "[98/203]\tTime 0.19394 (0.66719)\tData 0.00883 (0.49014)\tLoss 3.8180 (2.2525)\tPrec@1 0.00000 (39.28571)\tPrec@5 50.00000 (72.70408)\n",
            "[99/203]\tTime 1.09332 (0.67149)\tData 0.92702 (0.49456)\tLoss 1.8508 (2.2485)\tPrec@1 37.50000 (39.26768)\tPrec@5 87.50000 (72.85354)\n",
            "[100/203]\tTime 0.12925 (0.66607)\tData 0.00149 (0.48963)\tLoss 1.4764 (2.2408)\tPrec@1 68.75000 (39.56250)\tPrec@5 75.00000 (72.87500)\n",
            "[101/203]\tTime 1.27698 (0.67212)\tData 1.07704 (0.49544)\tLoss 0.0800 (2.2194)\tPrec@1 100.00000 (40.16089)\tPrec@5 100.00000 (73.14356)\n",
            "[102/203]\tTime 0.17533 (0.66725)\tData 0.00482 (0.49063)\tLoss 1.4511 (2.2118)\tPrec@1 62.50000 (40.37990)\tPrec@5 81.25000 (73.22305)\n",
            "[103/203]\tTime 1.26479 (0.67305)\tData 1.12021 (0.49674)\tLoss 7.6888 (2.2650)\tPrec@1 0.00000 (39.98787)\tPrec@5 0.00000 (72.51214)\n",
            "[104/203]\tTime 0.19113 (0.66842)\tData 0.00158 (0.49198)\tLoss 3.5339 (2.2772)\tPrec@1 50.00000 (40.08414)\tPrec@5 56.25000 (72.35577)\n",
            "[105/203]\tTime 1.10843 (0.67261)\tData 0.97113 (0.49655)\tLoss 1.4187 (2.2690)\tPrec@1 56.25000 (40.23810)\tPrec@5 93.75000 (72.55952)\n",
            "[106/203]\tTime 0.16172 (0.66779)\tData 0.00743 (0.49193)\tLoss 0.3522 (2.2510)\tPrec@1 93.75000 (40.74292)\tPrec@5 100.00000 (72.81840)\n",
            "[107/203]\tTime 0.94981 (0.67042)\tData 0.80525 (0.49486)\tLoss 0.1182 (2.2310)\tPrec@1 93.75000 (41.23832)\tPrec@5 100.00000 (73.07243)\n",
            "[108/203]\tTime 0.18923 (0.66597)\tData 0.00790 (0.49035)\tLoss 0.4558 (2.2146)\tPrec@1 87.50000 (41.66667)\tPrec@5 100.00000 (73.32176)\n",
            "[109/203]\tTime 1.10058 (0.66995)\tData 0.89013 (0.49402)\tLoss 0.1357 (2.1955)\tPrec@1 100.00000 (42.20183)\tPrec@5 100.00000 (73.56651)\n",
            "[110/203]\tTime 0.19991 (0.66568)\tData 0.00804 (0.48960)\tLoss 2.3397 (2.1968)\tPrec@1 37.50000 (42.15909)\tPrec@5 75.00000 (73.57954)\n",
            "[111/203]\tTime 0.92695 (0.66803)\tData 0.73653 (0.49183)\tLoss 3.8912 (2.2121)\tPrec@1 18.75000 (41.94820)\tPrec@5 50.00000 (73.36712)\n",
            "[112/203]\tTime 0.18999 (0.66377)\tData 0.00138 (0.48745)\tLoss 3.9950 (2.2280)\tPrec@1 25.00000 (41.79688)\tPrec@5 43.75000 (73.10268)\n",
            "[113/203]\tTime 1.05351 (0.66722)\tData 0.84510 (0.49061)\tLoss 2.1122 (2.2270)\tPrec@1 43.75000 (41.81416)\tPrec@5 75.00000 (73.11947)\n",
            "[114/203]\tTime 0.20480 (0.66316)\tData 0.00698 (0.48637)\tLoss 1.1562 (2.2176)\tPrec@1 75.00000 (42.10526)\tPrec@5 93.75000 (73.30044)\n",
            "[115/203]\tTime 0.99305 (0.66603)\tData 0.78838 (0.48900)\tLoss 0.6039 (2.2036)\tPrec@1 87.50000 (42.50000)\tPrec@5 100.00000 (73.53261)\n",
            "[116/203]\tTime 0.20918 (0.66209)\tData 0.00321 (0.48481)\tLoss 0.0528 (2.1850)\tPrec@1 100.00000 (42.99569)\tPrec@5 100.00000 (73.76077)\n",
            "[117/203]\tTime 0.95579 (0.66460)\tData 0.76707 (0.48722)\tLoss 1.2756 (2.1772)\tPrec@1 75.00000 (43.26923)\tPrec@5 81.25000 (73.82479)\n",
            "[118/203]\tTime 0.18008 (0.66049)\tData 0.00645 (0.48315)\tLoss 0.4365 (2.1625)\tPrec@1 93.75000 (43.69703)\tPrec@5 93.75000 (73.99364)\n",
            "[119/203]\tTime 1.03363 (0.66363)\tData 0.82520 (0.48602)\tLoss 0.2890 (2.1467)\tPrec@1 93.75000 (44.11765)\tPrec@5 100.00000 (74.21219)\n",
            "[120/203]\tTime 0.14016 (0.65927)\tData 0.00559 (0.48202)\tLoss 0.7799 (2.1354)\tPrec@1 75.00000 (44.37500)\tPrec@5 93.75000 (74.37501)\n",
            "[121/203]\tTime 1.00000 (0.66208)\tData 0.85503 (0.48510)\tLoss 0.0387 (2.1180)\tPrec@1 100.00000 (44.83471)\tPrec@5 100.00000 (74.58678)\n",
            "[122/203]\tTime 0.17675 (0.65810)\tData 0.00126 (0.48113)\tLoss 0.3324 (2.1034)\tPrec@1 93.75000 (45.23565)\tPrec@5 93.75000 (74.74385)\n",
            "[123/203]\tTime 1.12502 (0.66190)\tData 0.93155 (0.48480)\tLoss 0.2078 (2.0880)\tPrec@1 100.00000 (45.68089)\tPrec@5 100.00000 (74.94918)\n",
            "[124/203]\tTime 0.15490 (0.65781)\tData 0.00845 (0.48095)\tLoss 0.9875 (2.0791)\tPrec@1 81.25000 (45.96774)\tPrec@5 93.75000 (75.10081)\n",
            "[125/203]\tTime 1.07331 (0.66114)\tData 0.90817 (0.48437)\tLoss 1.0615 (2.0710)\tPrec@1 62.50000 (46.10000)\tPrec@5 87.50000 (75.20000)\n",
            "[126/203]\tTime 0.16941 (0.65723)\tData 0.00125 (0.48054)\tLoss 0.8284 (2.0611)\tPrec@1 68.75000 (46.27977)\tPrec@5 100.00000 (75.39683)\n",
            "[127/203]\tTime 1.29990 (0.66229)\tData 1.11169 (0.48551)\tLoss 1.9057 (2.0599)\tPrec@1 37.50000 (46.21063)\tPrec@5 68.75000 (75.34449)\n",
            "[128/203]\tTime 0.19131 (0.65861)\tData 0.00110 (0.48172)\tLoss 0.9262 (2.0510)\tPrec@1 75.00000 (46.43555)\tPrec@5 87.50000 (75.43945)\n",
            "[129/203]\tTime 1.06611 (0.66177)\tData 0.93864 (0.48526)\tLoss 1.7631 (2.0488)\tPrec@1 56.25000 (46.51163)\tPrec@5 75.00000 (75.43604)\n",
            "[130/203]\tTime 0.15198 (0.65785)\tData 0.00789 (0.48159)\tLoss 2.1061 (2.0492)\tPrec@1 50.00000 (46.53846)\tPrec@5 75.00000 (75.43269)\n",
            "[131/203]\tTime 1.10735 (0.66128)\tData 0.89497 (0.48475)\tLoss 2.4433 (2.0522)\tPrec@1 18.75000 (46.32634)\tPrec@5 62.50000 (75.33397)\n",
            "[132/203]\tTime 0.12712 (0.65724)\tData 0.00461 (0.48111)\tLoss 2.5415 (2.0559)\tPrec@1 18.75000 (46.11742)\tPrec@5 68.75000 (75.28410)\n",
            "[133/203]\tTime 1.12716 (0.66077)\tData 0.94037 (0.48456)\tLoss 0.7886 (2.0464)\tPrec@1 75.00000 (46.33459)\tPrec@5 93.75000 (75.42294)\n",
            "[134/203]\tTime 0.18505 (0.65722)\tData 0.00174 (0.48096)\tLoss 1.3791 (2.0414)\tPrec@1 75.00000 (46.54851)\tPrec@5 75.00000 (75.41978)\n",
            "[135/203]\tTime 1.02387 (0.65994)\tData 0.88732 (0.48397)\tLoss 2.0276 (2.0413)\tPrec@1 50.00000 (46.57407)\tPrec@5 68.75000 (75.37037)\n",
            "[136/203]\tTime 0.17887 (0.65640)\tData 0.01043 (0.48049)\tLoss 1.1648 (2.0349)\tPrec@1 62.50000 (46.69118)\tPrec@5 100.00000 (75.55147)\n",
            "[137/203]\tTime 1.32615 (0.66129)\tData 1.13514 (0.48527)\tLoss 3.7373 (2.0473)\tPrec@1 25.00000 (46.53284)\tPrec@5 50.00000 (75.36496)\n",
            "[138/203]\tTime 0.23635 (0.65821)\tData 0.00887 (0.48182)\tLoss 1.7869 (2.0454)\tPrec@1 37.50000 (46.46739)\tPrec@5 87.50000 (75.45290)\n",
            "[139/203]\tTime 0.93001 (0.66016)\tData 0.76854 (0.48388)\tLoss 1.1415 (2.0389)\tPrec@1 68.75000 (46.62770)\tPrec@5 93.75000 (75.58453)\n",
            "[140/203]\tTime 0.21663 (0.65699)\tData 0.00847 (0.48048)\tLoss 1.3037 (2.0337)\tPrec@1 56.25000 (46.69643)\tPrec@5 87.50000 (75.66964)\n",
            "[141/203]\tTime 1.14108 (0.66043)\tData 0.93213 (0.48369)\tLoss 0.1861 (2.0206)\tPrec@1 93.75000 (47.03014)\tPrec@5 100.00000 (75.84219)\n",
            "[142/203]\tTime 0.20105 (0.65719)\tData 0.00852 (0.48034)\tLoss 0.0945 (2.0070)\tPrec@1 100.00000 (47.40317)\tPrec@5 100.00000 (76.01232)\n",
            "[143/203]\tTime 1.45455 (0.66277)\tData 1.27974 (0.48593)\tLoss 0.3247 (1.9952)\tPrec@1 93.75000 (47.72727)\tPrec@5 100.00000 (76.18007)\n",
            "[144/203]\tTime 0.15997 (0.65928)\tData 0.00728 (0.48261)\tLoss 0.8174 (1.9871)\tPrec@1 81.25000 (47.96007)\tPrec@5 93.75000 (76.30209)\n",
            "[145/203]\tTime 1.25674 (0.66340)\tData 1.07255 (0.48667)\tLoss 1.2641 (1.9821)\tPrec@1 62.50000 (48.06034)\tPrec@5 93.75000 (76.42242)\n",
            "[146/203]\tTime 0.18141 (0.66010)\tData 0.00839 (0.48340)\tLoss 1.9816 (1.9821)\tPrec@1 56.25000 (48.11644)\tPrec@5 68.75000 (76.36987)\n",
            "[147/203]\tTime 1.00913 (0.66247)\tData 0.81412 (0.48565)\tLoss 1.3983 (1.9781)\tPrec@1 62.50000 (48.21428)\tPrec@5 100.00000 (76.53061)\n",
            "[148/203]\tTime 0.17014 (0.65914)\tData 0.00858 (0.48242)\tLoss 2.3560 (1.9807)\tPrec@1 43.75000 (48.18412)\tPrec@5 75.00000 (76.52027)\n",
            "[149/203]\tTime 1.02622 (0.66161)\tData 0.84222 (0.48484)\tLoss 4.6393 (1.9985)\tPrec@1 6.25000 (47.90268)\tPrec@5 12.50000 (76.09061)\n",
            "[150/203]\tTime 0.15698 (0.65824)\tData 0.01052 (0.48168)\tLoss 2.1635 (1.9996)\tPrec@1 31.25000 (47.79167)\tPrec@5 75.00000 (76.08334)\n",
            "[151/203]\tTime 1.00156 (0.66052)\tData 0.85754 (0.48417)\tLoss 2.7627 (2.0047)\tPrec@1 12.50000 (47.55795)\tPrec@5 68.75000 (76.03477)\n",
            "[152/203]\tTime 0.17859 (0.65735)\tData 0.00120 (0.48099)\tLoss 2.8752 (2.0104)\tPrec@1 0.00000 (47.24507)\tPrec@5 62.50000 (75.94572)\n",
            "[153/203]\tTime 1.12780 (0.66042)\tData 0.95386 (0.48408)\tLoss 2.1542 (2.0113)\tPrec@1 43.75000 (47.22222)\tPrec@5 75.00000 (75.93954)\n",
            "[154/203]\tTime 0.19680 (0.65741)\tData 0.00921 (0.48100)\tLoss 1.2929 (2.0067)\tPrec@1 50.00000 (47.24026)\tPrec@5 93.75000 (76.05519)\n",
            "[155/203]\tTime 0.88335 (0.65887)\tData 0.73168 (0.48261)\tLoss 2.1518 (2.0076)\tPrec@1 31.25000 (47.13710)\tPrec@5 81.25000 (76.08871)\n",
            "[156/203]\tTime 0.12415 (0.65544)\tData 0.00141 (0.47953)\tLoss 0.7793 (1.9997)\tPrec@1 75.00000 (47.31570)\tPrec@5 100.00000 (76.24199)\n",
            "[157/203]\tTime 1.16792 (0.65871)\tData 0.97011 (0.48265)\tLoss 1.9080 (1.9991)\tPrec@1 50.00000 (47.33280)\tPrec@5 75.00000 (76.23408)\n",
            "[158/203]\tTime 0.19750 (0.65579)\tData 0.01237 (0.47968)\tLoss 4.7187 (2.0163)\tPrec@1 0.00000 (47.03323)\tPrec@5 31.25000 (75.94937)\n",
            "[159/203]\tTime 1.01676 (0.65806)\tData 0.84257 (0.48196)\tLoss 3.6600 (2.0267)\tPrec@1 6.25000 (46.77673)\tPrec@5 37.50000 (75.70754)\n",
            "[160/203]\tTime 0.18937 (0.65513)\tData 0.00143 (0.47896)\tLoss 3.2361 (2.0342)\tPrec@1 25.00000 (46.64062)\tPrec@5 56.25000 (75.58594)\n",
            "[161/203]\tTime 1.10250 (0.65791)\tData 0.88898 (0.48150)\tLoss 3.4032 (2.0427)\tPrec@1 18.75000 (46.46739)\tPrec@5 56.25000 (75.46584)\n",
            "[162/203]\tTime 0.20642 (0.65512)\tData 0.00118 (0.47854)\tLoss 1.6724 (2.0405)\tPrec@1 31.25000 (46.37346)\tPrec@5 100.00000 (75.61729)\n",
            "[163/203]\tTime 1.26727 (0.65887)\tData 1.06220 (0.48212)\tLoss 2.2795 (2.0419)\tPrec@1 25.00000 (46.24233)\tPrec@5 81.25000 (75.65184)\n",
            "[164/203]\tTime 0.17608 (0.65593)\tData 0.00758 (0.47922)\tLoss 0.4498 (2.0322)\tPrec@1 93.75000 (46.53201)\tPrec@5 100.00000 (75.80030)\n",
            "[165/203]\tTime 1.39322 (0.66040)\tData 1.19639 (0.48357)\tLoss 0.7368 (2.0244)\tPrec@1 81.25000 (46.74242)\tPrec@5 100.00000 (75.94697)\n",
            "[166/203]\tTime 0.16008 (0.65739)\tData 0.00520 (0.48069)\tLoss 2.0657 (2.0246)\tPrec@1 25.00000 (46.61144)\tPrec@5 100.00000 (76.09187)\n",
            "[167/203]\tTime 1.02129 (0.65956)\tData 0.84039 (0.48284)\tLoss 1.8610 (2.0236)\tPrec@1 43.75000 (46.59431)\tPrec@5 75.00000 (76.08533)\n",
            "[168/203]\tTime 0.15529 (0.65656)\tData 0.01184 (0.48004)\tLoss 1.4816 (2.0204)\tPrec@1 68.75000 (46.72619)\tPrec@5 87.50000 (76.15327)\n",
            "[169/203]\tTime 1.15786 (0.65953)\tData 0.96095 (0.48289)\tLoss 1.9150 (2.0198)\tPrec@1 50.00000 (46.74556)\tPrec@5 68.75000 (76.10947)\n",
            "[170/203]\tTime 0.14455 (0.65650)\tData 0.00429 (0.48007)\tLoss 3.0618 (2.0259)\tPrec@1 0.00000 (46.47059)\tPrec@5 50.00000 (75.95589)\n",
            "[171/203]\tTime 1.13703 (0.65931)\tData 0.95598 (0.48285)\tLoss 3.0495 (2.0319)\tPrec@1 6.25000 (46.23538)\tPrec@5 37.50000 (75.73100)\n",
            "[172/203]\tTime 0.16725 (0.65645)\tData 0.00752 (0.48009)\tLoss 3.1394 (2.0383)\tPrec@1 6.25000 (46.00291)\tPrec@5 50.00000 (75.58140)\n",
            "[173/203]\tTime 1.13935 (0.65924)\tData 0.96181 (0.48287)\tLoss 4.3459 (2.0517)\tPrec@1 25.00000 (45.88150)\tPrec@5 37.50000 (75.36127)\n",
            "[174/203]\tTime 0.19213 (0.65656)\tData 0.00127 (0.48011)\tLoss 4.0601 (2.0632)\tPrec@1 25.00000 (45.76149)\tPrec@5 43.75000 (75.17960)\n",
            "[175/203]\tTime 1.01988 (0.65863)\tData 0.87065 (0.48234)\tLoss 2.5566 (2.0660)\tPrec@1 31.25000 (45.67857)\tPrec@5 68.75000 (75.14285)\n",
            "[176/203]\tTime 0.17630 (0.65589)\tData 0.00139 (0.47961)\tLoss 2.5398 (2.0687)\tPrec@1 37.50000 (45.63210)\tPrec@5 75.00000 (75.14204)\n",
            "[177/203]\tTime 1.04666 (0.65810)\tData 0.88881 (0.48192)\tLoss 3.6838 (2.0779)\tPrec@1 6.25000 (45.40960)\tPrec@5 43.75000 (74.96469)\n",
            "[178/203]\tTime 0.15555 (0.65528)\tData 0.00144 (0.47922)\tLoss 3.9309 (2.0883)\tPrec@1 12.50000 (45.22472)\tPrec@5 56.25000 (74.85955)\n",
            "[179/203]\tTime 1.41664 (0.65953)\tData 1.20192 (0.48326)\tLoss 3.6707 (2.0971)\tPrec@1 6.25000 (45.00698)\tPrec@5 50.00000 (74.72066)\n",
            "[180/203]\tTime 0.21091 (0.65704)\tData 0.00127 (0.48058)\tLoss 2.9855 (2.1020)\tPrec@1 25.00000 (44.89584)\tPrec@5 62.50000 (74.65278)\n",
            "[181/203]\tTime 0.96403 (0.65873)\tData 0.77375 (0.48220)\tLoss 1.7680 (2.1002)\tPrec@1 25.00000 (44.78591)\tPrec@5 93.75000 (74.75829)\n",
            "[182/203]\tTime 0.19117 (0.65616)\tData 0.00784 (0.47959)\tLoss 1.5935 (2.0974)\tPrec@1 31.25000 (44.71154)\tPrec@5 100.00000 (74.89698)\n",
            "[183/203]\tTime 1.16581 (0.65895)\tData 0.97020 (0.48227)\tLoss 1.8118 (2.0959)\tPrec@1 37.50000 (44.67213)\tPrec@5 100.00000 (75.03415)\n",
            "[184/203]\tTime 0.22294 (0.65658)\tData 0.00126 (0.47966)\tLoss 1.6754 (2.0936)\tPrec@1 43.75000 (44.66712)\tPrec@5 100.00000 (75.16984)\n",
            "[185/203]\tTime 1.02472 (0.65857)\tData 0.83331 (0.48157)\tLoss 1.5402 (2.0906)\tPrec@1 43.75000 (44.66216)\tPrec@5 100.00000 (75.30405)\n",
            "[186/203]\tTime 0.16463 (0.65591)\tData 0.00152 (0.47899)\tLoss 1.6167 (2.0880)\tPrec@1 50.00000 (44.69086)\tPrec@5 93.75000 (75.40323)\n",
            "[187/203]\tTime 1.02340 (0.65788)\tData 0.82114 (0.48082)\tLoss 1.1183 (2.0828)\tPrec@1 75.00000 (44.85294)\tPrec@5 93.75000 (75.50134)\n",
            "[188/203]\tTime 0.22209 (0.65556)\tData 0.00147 (0.47827)\tLoss 4.6696 (2.0966)\tPrec@1 0.00000 (44.61436)\tPrec@5 12.50000 (75.16622)\n",
            "[189/203]\tTime 1.11524 (0.65799)\tData 0.92857 (0.48065)\tLoss 4.4842 (2.1092)\tPrec@1 0.00000 (44.37831)\tPrec@5 37.50000 (74.96693)\n",
            "[190/203]\tTime 0.22135 (0.65569)\tData 0.00659 (0.47816)\tLoss 4.6235 (2.1225)\tPrec@1 0.00000 (44.14474)\tPrec@5 0.00000 (74.57237)\n",
            "[191/203]\tTime 1.02859 (0.65765)\tData 0.88509 (0.48029)\tLoss 3.9584 (2.1321)\tPrec@1 0.00000 (43.91361)\tPrec@5 12.50000 (74.24738)\n",
            "[192/203]\tTime 0.17948 (0.65516)\tData 0.00150 (0.47779)\tLoss 3.8524 (2.1410)\tPrec@1 0.00000 (43.68490)\tPrec@5 37.50000 (74.05599)\n",
            "[193/203]\tTime 1.16666 (0.65781)\tData 1.00739 (0.48054)\tLoss 2.6215 (2.1435)\tPrec@1 12.50000 (43.52332)\tPrec@5 62.50000 (73.99611)\n",
            "[194/203]\tTime 0.19412 (0.65542)\tData 0.00141 (0.47807)\tLoss 3.0625 (2.1483)\tPrec@1 12.50000 (43.36340)\tPrec@5 62.50000 (73.93685)\n",
            "[195/203]\tTime 1.11001 (0.65775)\tData 0.89583 (0.48021)\tLoss 3.0528 (2.1529)\tPrec@1 12.50000 (43.20513)\tPrec@5 56.25000 (73.84615)\n",
            "[196/203]\tTime 0.20430 (0.65543)\tData 0.00767 (0.47780)\tLoss 2.2205 (2.1533)\tPrec@1 18.75000 (43.08036)\tPrec@5 81.25000 (73.88393)\n",
            "[197/203]\tTime 1.25476 (0.65848)\tData 1.08443 (0.48088)\tLoss 2.4981 (2.1550)\tPrec@1 43.75000 (43.08376)\tPrec@5 62.50000 (73.82614)\n",
            "[198/203]\tTime 0.18692 (0.65610)\tData 0.00147 (0.47846)\tLoss 1.8935 (2.1537)\tPrec@1 43.75000 (43.08712)\tPrec@5 87.50000 (73.89520)\n",
            "[199/203]\tTime 1.36708 (0.65967)\tData 1.23219 (0.48224)\tLoss 2.5501 (2.1557)\tPrec@1 18.75000 (42.96482)\tPrec@5 68.75000 (73.86935)\n",
            "[200/203]\tTime 0.19380 (0.65734)\tData 0.00126 (0.47984)\tLoss 3.4362 (2.1621)\tPrec@1 0.00000 (42.75000)\tPrec@5 50.00000 (73.75000)\n",
            "[201/203]\tTime 0.80477 (0.65807)\tData 0.68096 (0.48084)\tLoss 3.3334 (2.1679)\tPrec@1 0.00000 (42.53731)\tPrec@5 37.50000 (73.56965)\n",
            "[202/203]\tTime 0.11528 (0.65538)\tData 0.00112 (0.47847)\tLoss 3.9950 (2.1769)\tPrec@1 0.00000 (42.32673)\tPrec@5 25.00000 (73.32921)\n",
            "[203/203]\tTime 0.05880 (0.65245)\tData 0.00094 (0.47611)\tLoss 3.1762 (2.1776)\tPrec@1 0.00000 (42.30056)\tPrec@5 0.00000 (73.28386)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNkTtXP3hZzn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}